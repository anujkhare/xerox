{
 "metadata": {
  "name": "",
  "signature": "sha256:dd0f47c64e71fcd328b4a7d36cb2891f68bb05e298312819cdceb5f1dd1a37e8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext vimception\n",
      "%reload_ext vimception\n",
      "%vimception"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "%reset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "col_labs =[\n",
      "\"Systolic Blood Pressure in mmHg\",\n",
      "\"Diastolic Blood Pressure in mmHg\", \n",
      "\"Heart Rate in bpm\", \n",
      "\"Respiration Rate in bpm\",\n",
      "\"Oxygen Saturation in %\",\n",
      "\"Temperature in Celsius\",\n",
      "\"Arterial blood PH in ph\",\n",
      "\"Partial Pressure of Carbon dioxide (PaCO2) in mmHg\",\n",
      "\"Partial Pressure of Oxygen (PaO2) in mmHg\",\n",
      "\"Sodium in mmol/L\",\n",
      "\"Potassium in mmol/L\",\n",
      "\"Bicarbonate in mmol/L\",\n",
      "\"Blood Urea Nitrogen in mg/dL\",\n",
      "\"Serum Creatinine in mg/dL\",\n",
      "\"WBC Count in x 103/\u00b5L\",\n",
      "\"Hematocrit %\",\n",
      "\"Platelet Count in x 103/\u00b5L\",\n",
      "\"Bilirubin in mg/dL\",\n",
      "\"Urine Output in ml\",\n",
      "\"LDL Cholesterol in mg/dL\",\n",
      "\"Lactic Acid in mmol/L\",\n",
      "\"Troponin I in ng/ml\",\n",
      "\"Troponin T in ng/ml\",\n",
      "\"Random Blood Glucose in mg/dL\",\n",
      "\"Fasting Blood Glucose in mg/dL\",\n",
      "\"Fraction of Inspired Oxygen (FiO2) in %\",\n",
      "\"Albumin in g/dl\",\n",
      "\"Alkaline Phosphatase in IU/L\",\n",
      "\"Alanine in IU/L\",\n",
      "\"HDL Cholesterol in mg/dL\",\n",
      "\"Magnesium in mg/dL\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pysal\n",
      "from pysal import *\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import svm\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from math import *\n",
      "from scipy.stats import *\n",
      "import re\n",
      "import pandas\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import Series, DataFrame\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.stats import norm\n",
      "from sklearn.linear_model import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(precision=5, suppress=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_age = pd.read_csv('data_train/id_age_train.csv')\n",
      "df_labels = pd.read_csv('data_train/id_label_train.csv')\n",
      "df_vitals = pd.read_csv('data_train/id_time_vitals_train.csv')\n",
      "df_labs = pd.read_csv('data_train/id_time_labs_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_df_combined(df_vitals, df_labs):\n",
      "    df_combined = df_vitals.drop('ICU', axis=1).copy()\n",
      "    df_combined = df_combined.join(df_labs.drop(['ID', 'TIME'], axis=1))\n",
      "    df_combined.drop(['ID', 'TIME'], axis=1, inplace=True)\n",
      "    ### Process the entire data using this process\n",
      "    return df_combined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def norm_transform(x, x_range, W):\n",
      "    if(x<x_range[0]):\n",
      "        x=x_range[0]\n",
      "    if(x>x_range[1]):\n",
      "        x=x_range[1]\n",
      "    return np.dot(W, [1, x, log(1+x)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_x_w(df_combined):\n",
      "    x_range = np.zeros((n_features, 2))\n",
      "    W = np.zeros((n_features, 3))\n",
      "    for i in xrange(n_features):\n",
      "    #for i in xrange(1):\n",
      "        vals = df_combined.ix[df_combined.ix[:, i].notnull(), i]\n",
      "        vals = np.sort(vals)\n",
      "\n",
      "        # find the quantiles\n",
      "        N = vals.shape[0]\n",
      "        q = np.array([(j-0.5)/N for j in xrange(N)])\n",
      "\n",
      "        i_l = np.min(np.arange(q.shape[0])[q>0.01])\n",
      "        i_u = np.max(np.arange(q.shape[0])[q<0.99])\n",
      "\n",
      "        x_range[i, 0] = vals[i_l]\n",
      "        x_range[i, 1] = vals[i_u]\n",
      "\n",
      "        vals = vals[i_l: i_u+1]\n",
      "        q=norm.ppf(q[i_l: i_u+1]) / 3\n",
      "\n",
      "        X = np.ones((vals.shape[0], 3))\n",
      "        X[:, 1] = vals\n",
      "        X[:, 2] = np.log(1 + vals)\n",
      "\n",
      "        W[i, :] = np.dot(np.linalg.pinv(np.dot(X.T, X)),\n",
      "                         np.dot(X.T, q)\n",
      "                         )\n",
      "    \n",
      "    return [x_range, W]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_norm_df(df_vitals, df_labs, x_range, W, path=None):\n",
      "    df_combined = get_df_combined(df_vitals, df_labs)\n",
      "    ### Normalize following the procedure in the paper\n",
      "    #### Find the xL, xU, w1, w2, w3 vars\n",
      "    # transform one element given range and W\n",
      "    df_norm = df_combined\n",
      "    for i in xrange(n_features):\n",
      "        df_norm.ix[:, i] = df_norm.ix[:, i].apply(lambda x:norm_transform(x, x_range[i], W[i]))\n",
      "    df_norm[df_norm.isnull()] = 0\n",
      "    \n",
      "    df_norm['TIME'] = df_vitals.TIME\n",
      "\n",
      "    if path is not None:\n",
      "        df_norm.to_csv(path=path)\n",
      "    return df_norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_norm_patients_from_df(df_vitals, df_labs, df_age, x_range, W, path=None):\n",
      "    df = get_norm_df(df_vitals, df_labs, x_range, W, path)\n",
      "    \n",
      "    patient_combined = [np.array(df.ix[df_vitals['ID'] == ID, :]) for ID in df_vitals['ID'].unique()]\n",
      "\n",
      "\n",
      "    age_combined = np.array(df_age.AGE)\n",
      "    icu_combined = np.array([np.array(df_vitals.ICU[df_vitals['ID']==i]) for i in df_vitals['ID'].unique()])\n",
      "    return [patient_combined, age_combined, icu_combined]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_patients_living_dead(patient_combined):\n",
      "    # split into living and dead\n",
      "    patient_combined_dead = [patient_combined[ID-1] for ID in df_age['ID']\n",
      "                                                          if df_labels.ix[ID - 1, 'LABEL'] == 1]\n",
      "    patient_combined_living = [patient_combined[ID-1] for ID in df_labels['ID']\n",
      "                                                          if df_labels.ix[ID - 1, 'LABEL'] == 0]\n",
      "    return [patient_combined_living, patient_combined_dead]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_combined = np.array(df_labels.LABEL)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Read the valus directly from the files\n",
      "#df_norm = get_norm_df()\n",
      "df_norm = pd.read_csv('/root/code/xerox/windows/svm_norm_data.csv')\n",
      "df_norm.drop(['Unnamed: 0'], axis=1, inplace=True)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_features = 31"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_ind = 31"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_combined = get_df_combined(df_vitals, df_labs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_range, W = get_x_w(df_combined)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print x_range[0], W[0], norm_transform(100, x_range[0], W[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  77.  184.] [-9.50483 -0.00169  2.02252] -0.339251822373\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[patient_combined, age_combined, icu_combined] = get_norm_patients_from_df(df_vitals, df_labs,\n",
      "                                                         df_age, x_range, W, path=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_combined = np.array(patient_combined)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_n_windows(ts, n_windows, stats, time_=None):\n",
      "    if time_ is not None:\n",
      "        cols = [i for i in np.arange(ts.shape[1]) if i != time_]\n",
      "        n_features = ts.shape[1] - 1\n",
      "    else:\n",
      "        cols = np.arange(ts.shape[1])\n",
      "        n_features = ts.shape[1]\n",
      "    \n",
      "    #print n_features\n",
      "    l = np.zeros((n_windows, len(stats) * n_features))\n",
      "    n = int(ts.shape[0] / n_windows)\n",
      "    \n",
      "    # get windows\n",
      "    for j in xrange(0, n_windows):\n",
      "        if (j==n_windows-1):\n",
      "            window = ts[j*n :, :] \n",
      "        else:\n",
      "            window = ts[j*n : (j+1)*n, :] \n",
      "\n",
      "        # apply stats to the window and append into a row\n",
      "        for k in xrange(len(stats)):\n",
      "            f = stats[k]\n",
      "            if f.func_name == '<lambda>':\n",
      "                if time_ is None:\n",
      "                    l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], None)\n",
      "                else:\n",
      "                    l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], window[:, time_])\n",
      "            else:\n",
      "                l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], axis=0)\n",
      "    return l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def get_windows_data(data, n_windows, stats):\n",
      "    window_stats = []\n",
      "    for i in xrange(len(data)):\n",
      "        ts = data[i]\n",
      "\n",
      "        if(ts.shape[0] < n_windows):\n",
      "            #window_stats.append(None)    # We want to keep 1-1 mapping with patients..\n",
      "            n = int(np.ceil(1.0 * n_windows / ts.shape[0]))\n",
      "            t = np.zeros((ts.shape[0] * n, ts.shape[1]))\n",
      "            for i in xrange(ts.shape[0]):\n",
      "                for k in xrange(n):\n",
      "                    t[n*i + k, :] = ts[i, :]\n",
      "            \n",
      "            ts = t\n",
      "\n",
      "        l = get_n_windows(ts, n_windows, stats)\n",
      "        window_stats.append(l)\n",
      "        \n",
      "    return window_stats"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Given list of patient time series, give a matrix with one row for each patient containing all windows\n",
      "def get_rows_data(data, n_windows, stats, time=None):\n",
      "    n_features = data[0].shape[1]\n",
      "    if time is not None:\n",
      "        n_features = n_features - 1\n",
      "    data_windows = np.zeros((len(data), n_windows*n_features*len(stats)))\n",
      "    for i in xrange(len(data)):\n",
      "        ts = data[i]\n",
      "\n",
      "        if(ts.shape[0] < n_windows):\n",
      "            #window_stats.append(None)    # We want to keep 1-1 mapping with patients..\n",
      "            n = int(np.ceil(1.0 * n_windows / ts.shape[0]))\n",
      "            t = np.zeros((ts.shape[0] * n, ts.shape[1]))\n",
      "            for i in xrange(ts.shape[0]):\n",
      "                for k in xrange(n):\n",
      "                    t[n*i + k, :] = ts[i, :]\n",
      "            \n",
      "            ts = t\n",
      "            continue\n",
      "\n",
      "        l = get_n_windows(ts, n_windows, stats, time)\n",
      "        data_windows[i, :] = np.hstack(l)\n",
      "        \n",
      "    return data_windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## For ONLINE prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get windows starting with zero upto end for the time series 'ts', ONLY for which icu=1 (If provided)\n",
      "def get_online_windows(ts, icu=None):\n",
      "    if icu is None:\n",
      "        p_windows = np.array([ts[:i+1, :] for i in xrange(ts.shape[0])])\n",
      "    else:   # inclue only if icu[i] == 1\n",
      "        p_windows = np.array([ts[:i+1, :] for i in xrange(ts.shape[0]) if icu[i]==1])\n",
      "    return p_windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get stats of a given ts for all possible windows starting with 1 element\n",
      "def get_all_window_stats(ts, n_windows, stats, time=None, icu=None):\n",
      "    p_windows = get_online_windows(ts, icu)\n",
      "    p_all_window_stats = get_rows_data(p_windows, n_windows, stats, time)\n",
      "    return p_all_window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Given a LIST of patient time series, give back a list of matrices, one for each time series, where each row is window 0..i\n",
      "def get_list_all_window_stats(data, n_windows, stats, time=None, list_of_icu=None):\n",
      "    all_window_stats = []\n",
      "    for i, d in enumerate(data):\n",
      "        if list_of_icu is None:\n",
      "            all_window_stats.append(get_all_window_stats(d, n_windows, stats, time))\n",
      "        else:\n",
      "            all_window_stats.append(get_all_window_stats(d, n_windows, stats, time, list_of_icu[i]))\n",
      "    \n",
      "    return all_window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### For testing online ones!\n",
      "ts = patients_valid[0:2]\n",
      "ts[1].shape\n",
      "p_windows = get_online_windows(ts[1])\n",
      "p_windows[10].shape\n",
      "p_stats = get_all_window_stats(ts[1], n_windows, stats)\n",
      "p_stats.shape\n",
      "p_all = get_list_all_window_stats(ts, n_windows, stats)\n",
      "p_all[1].shape"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Confusion!\n",
      "def get_ss(confusion):\n",
      "    tn = confusion[0, 0]  # label=0, pred=0\n",
      "    fp = confusion[0, 1]  # label=0, pred=1\n",
      "    \n",
      "    fn = confusion[1, 0]  # label=1, pred=0\n",
      "    tp = confusion[1, 1]  # label=1, pred=1\n",
      "    \n",
      "    sens = (1.0*tp/(tp+fn))\n",
      "    spec = (1.0*tn/(tn+fp))\n",
      "    \n",
      "    #print confusion\n",
      "    #print\n",
      "    #prittp, fp, fn, tn, sens, spec\n",
      "    #print 'Sensitiviy: ', sens, '\\nSpecificity: ', spec\n",
      "    return sens, spec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Split Data!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_train_valid_test(data_combined, labels_combined, icu_combined, age_combined, split=[0.6, 0.2]):\n",
      "    \n",
      "    ind = np.arange(0, len(labels_combined))\n",
      "    np.random.shuffle(ind)\n",
      "    \n",
      "    N = len(ind)\n",
      "    N_train = int(split[0] * N)\n",
      "    N_valid = int((split[1]+split[0]) * N)\n",
      "    \n",
      "    ind_train = ind[:N_train]\n",
      "    ind_valid = ind[N_train:N_valid]\n",
      "    ind_test = ind[N_valid:]\n",
      "    \n",
      "    data_combined = np.array(data_combined)\n",
      "    labels_combined = np.array(labels_combined)\n",
      "    \n",
      "    data_train = data_combined[ind_train]\n",
      "    labels_train = labels_combined[ind_train]\n",
      "    age_train = age_combined[ind_train]\n",
      "    icu_train = icu_combined[ind_train]\n",
      "    \n",
      "    age_valid = age_combined[ind_valid]\n",
      "    icu_valid = icu_combined[ind_valid]\n",
      "    labels_valid = labels_combined[ind_valid]\n",
      "    data_valid = data_combined[ind_valid]\n",
      "\n",
      "    age_test = age_combined[ind_test]\n",
      "    icu_test = icu_combined[ind_test]\n",
      "    labels_test = labels_combined[ind_test]\n",
      "    data_test = data_combined[ind_test]\n",
      "    \n",
      "    return [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "            #ind_train, ind_valid, ind_test]\n",
      "            icu_train, icu_valid, icu_test,\n",
      "            age_train, age_valid, age_test, ind_train, ind_valid, ind_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Separate dead and alive in train and validation sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def separate_living_dead(data, labels):\n",
      "    data_living = data[labels == 0]\n",
      "    data_dead = data[labels == 1]\n",
      "    return [data_living, data_dead]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Find number of dead and alive patients in train and validation sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sizes(data_living, data_dead):\n",
      "    n_dead = data_dead.shape[0]\n",
      "    n_living = data_living.shape[0]\n",
      "    n_combined = n_dead + n_living\n",
      "    \n",
      "    return n_dead, n_living, n_combined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GET DATA!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data(patient_combined, labels_combined, age_combined, icu_combined, n_windows, stats, split, time=None):\n",
      "    ### Generate windowed data\n",
      "    data_windows_combined = get_rows_data(patient_combined, n_windows, stats, time)\n",
      "    #data_windows_combined = np.hstack((data_windows_combined, age_combined))\n",
      "\n",
      "    print data_windows_combined.shape\n",
      "    ### split into train and validation sets, living and dead\n",
      "    [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "     icu_train, icu_valid, icu_test,\n",
      "     age_train, age_valid, age_test, ind_train, ind_valid, ind_test] = split_train_valid_test(data_windows_combined,\n",
      "     #ind_train, ind_valid, ind_test] = split_train_valid_test(data_windows_combined,\n",
      "                                                                         labels_combined, icu_combined,\n",
      "                                                                         age_combined, split=split)\n",
      "    \n",
      "    print data_train.shape\n",
      "    [data_train_living, data_train_dead] = separate_living_dead(data_train, labels_train)\n",
      "    [data_valid_living, data_valid_dead] = separate_living_dead(data_valid, labels_valid)\n",
      "    [data_test_living, data_test_dead] = separate_living_dead(data_test, labels_test)\n",
      "    \n",
      "    [age_train_living, age_train_dead] = separate_living_dead(age_train, labels_train)\n",
      "    [age_valid_living, age_valid_dead] = separate_living_dead(age_valid, labels_valid)\n",
      "    [age_test_living, age_test_dead] = separate_living_dead(age_test, labels_test)\n",
      "    [icu_train_living, icu_train_dead] = separate_living_dead(icu_train, labels_train)\n",
      "    [icu_valid_living, icu_valid_dead] = separate_living_dead(icu_valid, labels_valid)\n",
      "    [icu_test_living, icu_test_dead] = separate_living_dead(icu_test, labels_test)\n",
      "    \n",
      "    labels_train = labels_train.reshape((labels_train.shape[0], 1))\n",
      "    labels_valid = labels_valid.reshape((labels_valid.shape[0], 1))\n",
      "    labels_test = labels_test.reshape((labels_test.shape[0], 1))\n",
      "    \n",
      "    print data_train.shape\n",
      "    n_train_dead, n_train_living, n_train_combined = get_sizes(data_train_living, data_train_dead)\n",
      "    n_valid_dead, n_valid_living, n_valid_combined = get_sizes(data_valid_living, data_valid_dead)\n",
      "    n_test_dead, n_test_living, n_test_combined = get_sizes(data_test_living, data_test_dead)\n",
      "    \n",
      "    print 'Train:', n_train_dead, n_train_living, labels_train.shape[0]\n",
      "    print 'Valid:', n_valid_dead, n_valid_living, labels_valid.shape[0]\n",
      "    print 'Test:', n_test_dead, n_test_living, labels_test.shape[0]\n",
      "\n",
      "    ### Split into balacned sets!\n",
      "    n_train_splits = int (n_train_living / n_train_dead)\n",
      "    train_split = int (n_train_living / n_train_splits)\n",
      "    print 'Train Splits', n_train_splits, train_split, n_train_dead + n_train_splits * train_split, n_train_combined\n",
      "    print data_train.shape\n",
      "    print data_train[1].shape\n",
      "    \n",
      "    return [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "            data_train_living, data_train_dead, data_valid_living, data_valid_dead, data_test_living, data_test_dead,\n",
      "            age_train_living, age_train_dead, age_valid_living, age_valid_dead, age_test_living, age_test_dead,\n",
      "            icu_train_living, icu_train_dead, icu_valid_living, icu_valid_dead, icu_test_living, icu_test_dead,\n",
      "            train_split, ind_train, ind_valid, ind_test, n_train_splits, train_split]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Classify!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train balanced models!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_balanced(models, data_living, data_dead):\n",
      "    C_train = []\n",
      "    for i in xrange(n_train_splits):\n",
      "        # NO RANDOM SHUFFLE NOW!\n",
      "        data_bal = np.vstack((data_living[i * train_split: (i+1) * train_split, :],\n",
      "                              data_dead[:, :]) )\n",
      "        \n",
      "        label_bal = np.vstack((np.zeros((train_split, 1)),\n",
      "                               np.ones((data_dead.shape[0], 1))))\n",
      "\n",
      "        models[i].fit(data_bal, label_bal[:, 0])\n",
      "        C_train.append(confusion_matrix(label_bal[:,], models[i].predict(data_bal)))\n",
      "        \n",
      "    return C_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### GIVES THE SCORES OF EACH MODEL ON THE DATA\n",
      "def score_models(models, data_valid, labels_valid):\n",
      "    C_valid = []\n",
      "    for i in xrange(n_train_splits):\n",
      "        y = models[i].predict(data_valid)\n",
      "        C_valid.append(confusion_matrix(labels_valid[:], y))\n",
      "        #get_ss(C_valid[i])\n",
      "    return C_valid    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_proba(models_bal, data, sort=False):\n",
      "    probs = np.zeros((data.shape[0], len(models_bal)))\n",
      "        \n",
      "    probs = np.array([model.predict_proba(data)[:, 1] for model in models_bal]).T\n",
      "    if sort:\n",
      "        probs = np.sort(probs)\n",
      "    return probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find theta that maximises the sens at 99% spec on (data, labels)\n",
      "def train_theta_max_sens(models, data, labels, pr=None, N=100, verbose=False):\n",
      "    sens = []\n",
      "    spec = []\n",
      "    theta_arr = []\n",
      "    if pr!=None:\n",
      "        y_prob = get_pr_probs(data, pr, models)\n",
      "    else:\n",
      "        y_prob = get_model_sum_probs(data, models)\n",
      "        \n",
      "    for t in xrange(1, N):\n",
      "        theta = t*(1.0 / (N-1))\n",
      "        if pr!= None:\n",
      "            y = get_pr_prob_predictions(y_prob, theta)\n",
      "        else:\n",
      "            y = get_model_prob_predictions(y_prob, theta)\n",
      "        \n",
      "        se, sp = get_ss(confusion_matrix(labels, y))\n",
      "        sens.append(se); spec.append(sp); theta_arr.append(theta)\n",
      "\n",
      "    sens = np.array(sens); spec = np.array(spec); theta_arr = np.array(theta_arr);\n",
      "    \n",
      "    # Check if atleast one has >0.99 spec and non zero sens\n",
      "    if (sens[spec>0.99] > 0).any():   # take max spec for which sens>0\n",
      "        ind = spec>0.99\n",
      "        max_ind = np.argmax(sens[ind]) # take max sens for spec>0.99\n",
      "    elif (sens>0).any():\n",
      "        ind = sens>0\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "    else:\n",
      "        ind = np.arange(spec.shape[0])\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        \n",
      "    sens_ = sens[ind][max_ind]\n",
      "    spec_ = spec[ind][max_ind]\n",
      "    theta = theta_arr[ind][max_ind]\n",
      "    \n",
      "    if verbose==True:\n",
      "        print sens, spec\n",
      "        \n",
      "    #print max_ind, sens_, spec_\n",
      "    #print sens[max_ind], spec[max_ind]\n",
      "    return theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Feature selection!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Get col name, window, stats\n",
      "def get_col_stat_window(c):\n",
      "    i = c % (n_features)\n",
      "    f = col_labs[i]\n",
      "    w = int(c / (n_features * len(stats)))\n",
      "    s = stats[int((c % (n_features * len(stats))) / (n_features))].func_name\n",
      "    \n",
      "    return i, f, s, w"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_str(col):\n",
      "    return '-'.join([str(x) for x in get_col_stat_window(col)[1:-1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Following functions for finding mean prediction with threshold (rather than glm)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## NAME IS MISLEADING, IT GIVES MEAN PROB!\n",
      "def get_model_sum_probs(data, models):\n",
      "    prob_sum = np.zeros((data.shape[0], 2))\n",
      "    for m in models:\n",
      "        p = m.predict_proba(data)\n",
      "        prob_sum = prob_sum + p\n",
      "    \n",
      "    prob_sum = prob_sum / len(models)\n",
      "\n",
      "    return prob_sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_model_prob_predictions(prob_sum, theta):\n",
      "    y =  prob_sum[:, 1] - prob_sum[:, 0] > theta\n",
      "    return y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_model_mean_predictions(data, models, theta, verbose=False):\n",
      "    prob_sum = get_model_sum_probs(data, models)\n",
      "    if verbose:\n",
      "        print prob_sum\n",
      "    return get_model_prob_predictions(prob_sum, theta)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Version with prediction on the validation set\n",
      "##### Train classifier by finding the mean probabilities, and return sens and spec\n",
      "def train_and_score_cols(models, cols, data_train_living=data_train_living, data_train_dead=data_train_dead,\n",
      "                         data_valid=data_valid, labels_valid=labels_valid, verbose=False):\n",
      "    \n",
      "    if cols==None:\n",
      "        cols = np.arange(data_train_living.shape[1])\n",
      "    print cols\n",
      "    train_balanced(models, data_train_living[:, cols], data_train_dead[:, cols]);\n",
      "    \n",
      "    theta_max = train_theta_max_sens(models, data_valid[:, cols], labels_valid, verbose=verbose)\n",
      "    y = get_model_mean_predictions(data_valid[:, cols], models, theta_max, verbose=verbose)\n",
      "    \n",
      "    se, sp = get_ss(confusion_matrix(labels_valid, y))\n",
      "    #print se, sp\n",
      "    return se, sp, theta_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get the column sensitivity and specificity scores\n",
      "def get_col_se_sp(models, data_train_living, data_train_dead, data_valid, labels_valid):\n",
      "    n = data_train_living.shape[1]\n",
      "    se = np.zeros((n,1))\n",
      "    sp = np.zeros((n,1))\n",
      "    \n",
      "    for i in xrange(n):\n",
      "        se[i], sp[i], t = train_and_score_cols(models, [i], data_train_living, data_train_dead, data_valid, labels_valid)\n",
      "    return se, sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## All feature+stats pairs, taken together to train the models\n",
      "def get_feature_stat_se_sp(models):\n",
      "    n = data_train_living.shape[1] / n_windows\n",
      "    se = np.zeros((n,1))\n",
      "    sp = np.zeros((n,1))\n",
      "    \n",
      "    for i in xrange(n):\n",
      "        cols = [i + j*n for j in xrange(n_windows)]\n",
      "        print cols\n",
      "        se[i], sp[i], t = train_and_score_cols(models, [i], data_train_living, data_train_dead, data_valid, labels_valid)\n",
      "    return se, sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Given cols in first window, train for all windows of that col\n",
      "def train_score_col_windows(models, cols, verbose=False):\n",
      "    n = data_train_living.shape[1] / n_windows\n",
      "    cols_all_windows = np.zeros((1, len(cols)*n_windows))\n",
      "    \n",
      "    for i in xrange(0, n_windows):\n",
      "        cols_all_windows[0, i*len(cols):(i+1)*len(cols)] = [j + i*n for j in cols]\n",
      "        \n",
      "    cols_ =  np.array(cols_all_windows[0, :], dtype=int).tolist()\n",
      "    print cols_\n",
      "    se, sp, t = train_and_score_cols(models, cols_, data_train_living, data_train_dead, data_valid, labels_valid,\n",
      "                                     verbose)\n",
      "    return se, sp, t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_df(se_f, sp_f):\n",
      "    out = np.hstack((np.arange(se_f.shape[0]).reshape((se_f.shape[0], 1)), se_f, sp_f, np.abs(sp_f - se_f)))\n",
      "    cols = [get_str(i) for i in np.array(out[:, 0], dtype=int)]\n",
      "\n",
      "    df_feat = pd.DataFrame(data=out, columns=['ind', 'sens', 'spec', 'diff'])\n",
      "    df_feat['name'] = cols\n",
      "    return df_feat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GO ONLINE!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_stacked_windows_ind(list_of_window_arrays):\n",
      "    data_all_windows_stacked = np.vstack(list_of_window_arrays)\n",
      "    ind_all_windows_stacked = np.vstack([np.ones((x.shape[0], 1)) * i for i, x in enumerate(list_of_window_arrays) ])\n",
      "    return data_all_windows_stacked, ind_all_windows_stacked[:, 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- get validation patients\n",
      "- get list of (all windows) of each patient\n",
      "- stack the windows up for whatever data you want to classify\n",
      "    - maintain an index to get back separate patients\n",
      "    - Classify windows\n",
      "- get back classifications for each patient separately\n",
      "- define \"some\" metric to classify the entire series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Takes list of patient time series, and creates windows starting at zero\n",
      "def get_stacked_windows_from_ts(list_of_patient_ts, n_windows, stats, time=None, list_of_icu=None, cols=None):\n",
      "    list_of_window_arrays = get_list_all_window_stats(list_of_patient_ts, n_windows, stats, time, list_of_icu)\n",
      "    data_all_windows_stacked, ind_all_windows_stacked = get_stacked_windows_ind(list_of_window_arrays)\n",
      "   \n",
      "    if cols is None:\n",
      "        return data_all_windows_stacked, ind_all_windows_stacked\n",
      "    else:\n",
      "        return data_all_windows_stacked[:, cols], ind_all_windows_stacked"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def get_list_of_prediction_arrays(data, ind_stacked):\n",
      "    inds = np.unique(ind_stacked)\n",
      "    list_y_preds = [data[ind_stacked==i, :].copy() for i in inds]\n",
      "    return np.array(list_y_preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def view_series_random(list_y, n=10):\n",
      "    ind = np.arange(list_y.shape[0])\n",
      "    np.random.shuffle(ind)\n",
      "    for i, l in enumerate(list_y[ind[:n]]):\n",
      "        print i, l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# TS!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_in_inds(p):\n",
      "    if (ind_train==p).any():\n",
      "        print \"train\"\n",
      "    if (ind_valid==p).any():\n",
      "        print \"valid\"\n",
      "    if (ind_test==p).any():\n",
      "        print \"test\"\n",
      "def get_confusion_inds(labels, y):\n",
      "    ind_fn = np.array([((not y[i]) & (labels[i] != y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_fp = np.array([(y[i] & (labels[i] != y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_tp = np.array([(labels[i] & (labels[i] == y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_tn = np.array([((not labels[i]) & (labels[i] == y[i])) for i in xrange(labels.shape[0])])\n",
      "    return [ind_fp, ind_fn, ind_tp, ind_tn]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## FOR THE COMPLEX MODEL!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_probs_all_windows(list_of_time_series, n_windows, stats, models, time, list_of_val_series=None, cols=None):\n",
      "    # Get stacked windows of all patients, and an ind of which patitent has which rows\n",
      "    data_windows_stacked, ind_windows_stacked = get_stacked_windows_from_ts(list_of_time_series, n_windows,\n",
      "                                                                            stats, time, list_of_val_series, cols)\n",
      "    # Get probability estimates for all windows (of all patients) using the forests\n",
      "    dead_probs_stacked = get_proba(models, data_windows_stacked)\n",
      "    \n",
      "    # Append MEAN of all column predictions as a feature\n",
      "    dead_probs_stacked = np.hstack((dead_probs_stacked,\n",
      "                                    np.mean(dead_probs_stacked, axis=1).reshape(dead_probs_stacked.shape[0], 1)))\n",
      "    #dead_probs_stacked = np.mean(dead_probs_stacked, axis=1).reshape(dead_probs_stacked.shape[0], 1)\n",
      "    \n",
      "    # separate the probabilities paitient wise \n",
      "    list_probs = get_list_of_prediction_arrays(dead_probs_stacked, ind_windows_stacked)\n",
      "    return list_probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# takes in the probability matrix for the data, and threshold theta, returns final predictions, \n",
      "def get_unstacked_predictions_from_probs(y_prob_stacked, ind_stacked, theta):\n",
      "    y_pred_stacked = get_model_prob_predictions(y_prob_stacked, theta)\n",
      "    y_pred_stacked = y_pred_stacked.reshape((y_pred_stacked.shape[0], 1))\n",
      "    \n",
      "    list_y_preds = get_list_of_prediction_arrays(y_pred_stacked, ind_stacked)\n",
      "    y_any = np.array([(list_y_preds[i] == True).any() for i in xrange(list_y_preds.shape[0])])\n",
      "    return y_any, list_y_preds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find theta that maximises the sens at 99% spec on (data, labels)\n",
      "def train_theta_max_sens_stacked(y_prob, ind_stacked, labels, N=100, verbose=False):\n",
      "    TH = 0.994\n",
      "    sens = []; spec = []; theta_arr = []\n",
      "\n",
      "    for t in xrange(1, N):\n",
      "        theta = t*(1.0 / (N-1))\n",
      "        y, l = get_unstacked_predictions_from_probs(y_prob, ind_stacked, theta)\n",
      "        se, sp = get_ss(confusion_matrix(labels, y))\n",
      "        sens.append(se); spec.append(sp); theta_arr.append(theta)\n",
      "\n",
      "    sens = np.array(sens); spec = np.array(spec); theta_arr = np.array(theta_arr);\n",
      "    \n",
      "    # Check if atleast one has >0.99 spec and non zero sens\n",
      "    print sens[spec>TH]\n",
      "    if (sens[spec>TH] > 0).any():   # take max spec for which sens>0\n",
      "        ind = spec>TH\n",
      "        max_ind = np.argmax(sens[ind]) # take max sens for spec>0.99\n",
      "        print '1'\n",
      "    elif (sens>0).any():\n",
      "        ind = sens>0\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        print '2'\n",
      "    else:\n",
      "        ind = np.arange(spec.shape[0])\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        print '3'\n",
      "        \n",
      "    sens_ = sens[ind][max_ind]\n",
      "    spec_ = spec[ind][max_ind]\n",
      "    theta = theta_arr[ind][max_ind]\n",
      "    \n",
      "    if verbose==True:\n",
      "        print sens, spec\n",
      "        \n",
      "    #print max_ind, sens_, spec_\n",
      "    #print sens[max_ind], spec[max_ind]\n",
      "    return theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def slope(X):\n",
      "    sl = np.zeros((X.shape[1],))\n",
      "    y = np.arange(X.shape[0])     # SHOULD BE TIME HERE\n",
      "    for i, x in enumerate(X.T):\n",
      "        A = np.vstack([x, np.ones(len(x))]).T\n",
      "        m, c = np.linalg.lstsq(A, y)[0]\n",
      "        #print m,c\n",
      "        sl[i] = m\n",
      "    return sl"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def slope(x, time_):\n",
      "    n = x.shape[0]; nc = x.shape[1]\n",
      "    \n",
      "    #sl = np.zeros((1,))\n",
      "    if time_ is None:\n",
      "        y = np.arange(n).reshape((n, 1))   # SHOULD BE TIMESTAMPS\n",
      "    else:\n",
      "        y = time_.reshape((time_.shape[0], 1))\n",
      "    \n",
      "    xy = np.sum(x*y, axis=0)\n",
      "    xm = np.mean(x, axis=0)\n",
      "    ym = np.mean(y, axis=0)\n",
      "    x2 = np.sum(x*x, axis=0)\n",
      "    \n",
      "    sl = 1.0*(xy - n*xm*ym) / (x2 - n*xm*xm)\n",
      "    sl[np.isnan(sl)] = 0\n",
      "    sl[np.isinf(sl)] = 0\n",
      "    return sl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Just return teh timestamp\n",
      "def get_prediction_timestamp(y_preds, patient_ts, time_ind, icu_ts):\n",
      "    if not (y_preds==1).any():\n",
      "        return -1\n",
      "    \n",
      "    times = patient_ts[:, time_ind]\n",
      "    icu = np.array(icu_ts, dtype=bool)\n",
      "    y = np.array(y_preds[:,0], dtype=bool)\n",
      "    \n",
      "    return times[icu][y][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For one patient, if no 1s, return -1\n",
      "def get_prediction_time(y_preds, patient_ts, time_ind, icu_ts):\n",
      "    if not (y_preds==1).any():\n",
      "        return -1\n",
      "    \n",
      "    times = patient_ts[:, time_ind]\n",
      "    icu = np.array(icu_ts, dtype=bool)\n",
      "    y = np.array(y_preds[:,0], dtype=bool)\n",
      "    \n",
      "    return (times[times.shape[0]-1] - times[icu][y][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_prediction_times_all_patients(list_y_preds, list_of_patients, time_ind, list_of_icu_times):\n",
      "    pred_times = [get_prediction_time(list_y_preds[i], list_of_patients[i], time_ind, list_of_icu_times[i]) for i in \n",
      "                  xrange(list_y_preds.shape[0])]\n",
      "    return np.array(pred_times)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# WORKSPACE!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_combined = np.array(patient_combined)\n",
      "patient_combined = np.array(patient_combined)\n",
      "np.random.seed(2)\n",
      "\n",
      "### BIG FOREST PARAMS\n",
      "stats_big = [np.mean, np.var, np.min, np.max,\n",
      "             lambda x, axis:x[x.shape[0]-1],    # first element\n",
      "             lambda x, axis:x[0],               # last element\n",
      "             lambda x, time_: slope(x, time_)]  # slope of the window\n",
      "n_windows_big = 1\n",
      "\n",
      "### NOTE: If n<n_windows, ignored!\n",
      "n_windows = 1\n",
      "split = [0.60, 0.40]    # train%, validation%, (test%)\n",
      "#stats = [np.nanmean, np.nanmax , np.nanvar, np.nanmin, lambda x, axis:x.shape[0], lambda x, axis:x[x.shape[0]-1]]\n",
      "stats = [np.mean, np.var, np.min, np.max,\n",
      "         lambda x, axis:x[x.shape[0]-1],    # first element\n",
      "         lambda x, axis:x[0],               # last element\n",
      "         lambda x, time_: slope(x, time_)]          # slope of the window\n",
      "\n",
      "# Get the data from the patients\n",
      "[data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      " data_train_living, data_train_dead, data_valid_living, data_valid_dead, data_test_living, data_test_dead,\n",
      " icu_train_living, icu_train_dead, icu_valid_living, icu_valid_dead, icu_test_living, icu_test_dead,\n",
      " age_train_living, age_train_dead, age_valid_living, age_valid_dead, age_test_living, age_test_dead,\n",
      " train_split, ind_train, ind_valid, ind_test, n_train_splits, train_split] = get_data(patient_combined,\n",
      "                                                            labels_combined, age_combined,\n",
      "                                                            icu_combined, n_windows, stats, split, time=time_ind)\n",
      "\n",
      "patients_train = patient_combined[ind_train]\n",
      "patients_valid = patient_combined[ind_valid]\n",
      "patients_test = patient_combined[ind_test]    # Data_combined = patient_combined\n",
      "\n",
      "#icu_combined = icu_combined.reshape((icu_combined.shape[0],))\n",
      "age_combined = age_combined.reshape((age_combined.shape[0], 1))\n",
      "age_train = age_combined[ind_train]\n",
      "age_valid = age_combined[ind_valid]\n",
      "age_test = age_combined[ind_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3594, 217)\n",
        "(2156, 217)\n",
        "(2156, 217)\n",
        "Train: 153 2003 2156\n",
        "Valid: 92 1346 1438\n",
        "Test: 0 0 0\n",
        "Train Splits 13 154 2155 2156\n",
        "(2156, 217)\n",
        "(217,)\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forests_final_1 = [RandomForestClassifier(n_estimators=100, class_weight={0:1, 0:1}, max_features=3,\n",
      "                                      n_jobs=-1, max_depth=3\n",
      "                                      ) for i in xrange(n_train_splits)]\n",
      "cols_feat = [127, 125,124,128,113,25,2]\n",
      "cols_feat = [2, 3, 0, 1, 4, 25]\n",
      "cols_feat = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_and_score_cols(forests_final_1, cols_feat, data_train_living, data_train_dead, data_valid, labels_valid, verbose=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
        "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
        "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
        "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
        "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
        "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
        " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
        " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
        " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
        " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
        " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
        " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
        " 216]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "(0.6086956521739131, 0.9903417533432393, 0.23232323232323235)"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "list_probs_train = get_probs_all_windows(patients_train, n_windows, stats, forests_final_1, time=time_ind,\n",
      "                                         cols=cols_feat)\n",
      "###### INCLUDE ICU! Make ONE entry with the stats of all windows\n",
      "# Again, make n_windows_big windwows using the entire time series (n_train, n_windows_big * len(stats_big) * n_train_splits)\n",
      "train_prob_stats = get_rows_data(list_probs_train, n_windows_big, stats_big)\n",
      "#train_prob_stats =  np.hstack((train_prob_stats, age_train))   # Append the age column here\n",
      "forest_big = RandomForestClassifier(n_estimators=100, class_weight={0:1, 1:1}, max_features=4,\n",
      "                                      n_jobs=-1, max_depth=10)\n",
      "forest_big.fit(train_prob_stats, labels_train[:, 0])\n",
      "#### train a new ensemble of random forests, and \n",
      "train_prob_stats_living, train_prob_stats_dead = separate_living_dead(train_prob_stats, labels_train[:, 0])\n",
      "train_balanced(forests_big, train_prob_stats_living, train_prob_stats_living);\n",
      "## now train a threshold for controlling sensitivity and specificity on the validation set\n",
      "# Get probs of only windows that are in the ICU for each patient\n",
      "list_probs = get_probs_all_windows(patients_valid, n_windows, stats, forests_final_1, time_ind,\n",
      "                                   icu_combined[ind_valid], cols=cols_feat)\n",
      "# Get rows (online) for each time series of probabilities\n",
      "prob_windows_stacked_val, ind_windows_stacked_val = get_stacked_windows_from_ts(list_probs, n_windows_big, stats_big)\n",
      "ind_windows_stacked_val = np.array(ind_windows_stacked_val, dtype=int)\n",
      "#prob_windows_stacked_val = np.hstack((prob_windows_stacked_val, age_valid[ind_windows_stacked_val])) # Stack AGE\n",
      "y_prob_stacked_val = forest_big.predict_proba(prob_windows_stacked_val)\n",
      "theta_max = train_theta_max_sens_stacked(y_prob_stacked_val, ind_windows_stacked_val, labels_valid, verbose=True)\n",
      "theta_max\n",
      "y_prob_stacked_val.shape\n",
      "np.sum(y_prob_stacked_val>=0.7)\n",
      "y_any_valid, list_y_preds_val = get_unstacked_predictions_from_probs(y_prob_stacked_val, ind_windows_stacked_val, theta_max)\n",
      "get_ss((confusion_matrix(labels_valid, y_any_valid)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Prediction times"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = get_prediction_times_all_patients(list_y_preds_val, patients_valid, time_ind, icu_combined[ind_valid])\n",
      "print 'median:', np.median(l[l>0]/3600), ', min:', np.min(l[l>0]/3600)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "median: 40.4861111111 , min: 0.165277777778\n"
       ]
      }
     ],
     "prompt_number": 392
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Get predictions for all windows (of probs) using the forest\n",
      "y_pred_stacked = forest_big.predict(prob_windows_stacked_val)\n",
      "y_pred_stacked = y_pred_stacked.reshape((y_pred_stacked.shape[0], 1))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print np.arange(y_any_valid.shape[0])[y_any_valid]  # all valid indices with at least one 1\n",
      "# find the indices at which 1 was predicted, and the label\n",
      "# i = 31\n",
      "#print np.arange(list_y_preds_val[i].shape[0])[list_y_preds_val[i][:, 0] == 1], labels_valid[i]\n",
      "#print labels_valid[y_any_valid != (l>0)]    # TRUE LABELS WHERE THE PREDICTION 1 WAS MADE AT TIME 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 283
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## MISCLASSIFIED PATIENTS!\n",
      "l = np.array([x.shape[0] for x in patient_combined])\n",
      "l[[689, 694, 699, 695, 705, 715]]\n",
      "np.arange(3594)[argsort(l)==2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 934
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# LOAD VALIDATION DATA!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_age_valid = pd.read_csv('validation/id_age_val.csv')\n",
      "df_vitals_valid = pd.read_csv('validation/id_time_vitals_val.csv')\n",
      "df_labs_valid = pd.read_csv('validation/id_time_labs_val.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_labels_valid = pd.read_csv('/root/Downloads/id_label_val.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path=None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path='/root/code/xerox/windows/svm_norm_data_valid.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 300
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[patients_combined_val, age_combined_val, icu_combined_val] = get_norm_patients_from_df(df_vitals_valid, df_labs_valid,\n",
      "                                                                                         df_age_valid, x_range, W, path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get probs of only windows that are in the ICU for each patient\n",
      "list_probs = get_probs_all_windows(patients_combined_val, n_windows, stats, forests_final_1, time_ind,\n",
      "                                       icu_combined_val, cols=cols_feat)\n",
      "# Get rows (online) for each time series of probabilities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prob_windows_stacked, ind_windows_stacked = get_stacked_windows_from_ts(list_probs, n_windows_big, stats_big)\n",
      "ind_windows_stacked = np.array(ind_windows_stacked, dtype=int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#prob_windows_stacked_val = np.hstack((prob_windows_stacked_val, age_valid[ind_windows_stacked_val])) # Stack AGE\n",
      "y_prob_stacked = forest_big.predict_proba(prob_windows_stacked)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_any, list_y_preds = get_unstacked_predictions_from_probs(y_prob_stacked, ind_windows_stacked, theta_max)\n",
      "get_ss(confusion_matrix(df_labels_valid.label, y_any))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "(0.35365853658536583, 0.9874551971326165)"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_any, list_y_preds = get_unstacked_predictions_from_probs(y_prob_stacked, ind_windows_stacked, theta_max+0.05)\n",
      "get_ss(confusion_matrix(df_labels_valid.label, y_any))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 130,
       "text": [
        "(0.25609756097560976, 0.9901433691756273)"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = get_prediction_times_all_patients(list_y_preds, patients_combined_val, time_ind, icu_combined_val)\n",
      "print 'median:', np.median(l[l>0]/3600), ', min:', np.min(l[l>0]/3600)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "median: 73.4484722222 , min: 0.106111111111\n"
       ]
      }
     ],
     "prompt_number": 435
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(y_any)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 436,
       "text": [
        "51"
       ]
      }
     ],
     "prompt_number": 436
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "icu = np.array(df_vitals_valid.TIME[df_vitals_valid.ICU==1])\n",
      "icu = icu.reshape((icu.shape[0], 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 437
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_preds_stacked = np.vstack(list_y_preds)\n",
      "y_preds_stacked = y_preds_stacked.reshape((y_preds_stacked.shape[0], 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 438
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_pred_arr = np.hstack((np.array(df_vitals_valid.ID[df_vitals_valid.ICU==1]).reshape((icu.shape[0], 1)),\n",
      "                            icu, y_preds_stacked))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 439
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_pred_arr = np.array(final_pred_arr, dtype=int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 440
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt('/root/output2.csv', final_pred_arr, delimiter=',', fmt='%d')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 441
    }
   ],
   "metadata": {}
  }
 ]
}