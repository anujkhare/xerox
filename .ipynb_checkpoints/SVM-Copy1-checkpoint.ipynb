{
 "metadata": {
  "name": "",
  "signature": "sha256:4de8af1b42c90a0fdb14bfde8ce0c017c4546b04c8356e1eb1f1f600b919a9a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%vimception"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Line magic function `%vimception` not found.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import pandas\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_age = pd.read_csv('data_train/id_age_train.csv')\n",
      "df_labels = pd.read_csv('data_train/id_label_train.csv')\n",
      "df_vitals = pd.read_csv('data_train/id_time_vitals_train.csv')\n",
      "df_labs = pd.read_csv('data_train/id_time_labs_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_vitals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>ID</th>\n",
        "      <th>TIME</th>\n",
        "      <th>V1</th>\n",
        "      <th>V2</th>\n",
        "      <th>V3</th>\n",
        "      <th>V4</th>\n",
        "      <th>V5</th>\n",
        "      <th>V6</th>\n",
        "      <th>ICU</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0     </th>\n",
        "      <td>    1</td>\n",
        "      <td>      0</td>\n",
        "      <td>  86</td>\n",
        "      <td>  49</td>\n",
        "      <td>  70</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  87</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1     </th>\n",
        "      <td>    1</td>\n",
        "      <td>   4320</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  70</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2     </th>\n",
        "      <td>    1</td>\n",
        "      <td>   5646</td>\n",
        "      <td>  91</td>\n",
        "      <td>  58</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 96.6</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3     </th>\n",
        "      <td>    1</td>\n",
        "      <td>   5703</td>\n",
        "      <td> 140</td>\n",
        "      <td>  73</td>\n",
        "      <td>  91</td>\n",
        "      <td> 32</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4     </th>\n",
        "      <td>    1</td>\n",
        "      <td>   6342</td>\n",
        "      <td> 139</td>\n",
        "      <td>  90</td>\n",
        "      <td> 107</td>\n",
        "      <td> 29</td>\n",
        "      <td> 101</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5     </th>\n",
        "      <td>    1</td>\n",
        "      <td>   6609</td>\n",
        "      <td> 152</td>\n",
        "      <td>  75</td>\n",
        "      <td> 109</td>\n",
        "      <td> 30</td>\n",
        "      <td> 101</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6     </th>\n",
        "      <td>    1</td>\n",
        "      <td>   6894</td>\n",
        "      <td> 140</td>\n",
        "      <td>  79</td>\n",
        "      <td>  84</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  98</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7     </th>\n",
        "      <td>    1</td>\n",
        "      <td>   6957</td>\n",
        "      <td> 140</td>\n",
        "      <td>  72</td>\n",
        "      <td> 108</td>\n",
        "      <td> 31</td>\n",
        "      <td> 101</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8     </th>\n",
        "      <td>    1</td>\n",
        "      <td>   7511</td>\n",
        "      <td> 132</td>\n",
        "      <td>  68</td>\n",
        "      <td> 110</td>\n",
        "      <td> 31</td>\n",
        "      <td>  95</td>\n",
        "      <td> 95.2</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9     </th>\n",
        "      <td>    1</td>\n",
        "      <td>   8372</td>\n",
        "      <td> 139</td>\n",
        "      <td>  70</td>\n",
        "      <td> 106</td>\n",
        "      <td> 31</td>\n",
        "      <td>  97</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10    </th>\n",
        "      <td>    1</td>\n",
        "      <td>   9297</td>\n",
        "      <td> 134</td>\n",
        "      <td>  68</td>\n",
        "      <td> 105</td>\n",
        "      <td> 31</td>\n",
        "      <td>  99</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  10213</td>\n",
        "      <td> 134</td>\n",
        "      <td>  68</td>\n",
        "      <td> 105</td>\n",
        "      <td> 31</td>\n",
        "      <td>  99</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  11079</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  11123</td>\n",
        "      <td> 132</td>\n",
        "      <td>  67</td>\n",
        "      <td>  96</td>\n",
        "      <td> 31</td>\n",
        "      <td> 100</td>\n",
        "      <td> 93.1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  12015</td>\n",
        "      <td> 132</td>\n",
        "      <td>  69</td>\n",
        "      <td>  92</td>\n",
        "      <td> 31</td>\n",
        "      <td> 101</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  12889</td>\n",
        "      <td> 127</td>\n",
        "      <td>  72</td>\n",
        "      <td>  92</td>\n",
        "      <td> 31</td>\n",
        "      <td>  97</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  13798</td>\n",
        "      <td> 124</td>\n",
        "      <td>  65</td>\n",
        "      <td>  86</td>\n",
        "      <td> 31</td>\n",
        "      <td>  97</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  14713</td>\n",
        "      <td> 119</td>\n",
        "      <td>  67</td>\n",
        "      <td>  86</td>\n",
        "      <td> 31</td>\n",
        "      <td>  97</td>\n",
        "      <td> 90.6</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  15577</td>\n",
        "      <td> 106</td>\n",
        "      <td>  64</td>\n",
        "      <td>  80</td>\n",
        "      <td> 30</td>\n",
        "      <td>  97</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  16523</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  72</td>\n",
        "      <td> 31</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  17415</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  94</td>\n",
        "      <td> 31</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  17581</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  77</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 100</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  17644</td>\n",
        "      <td> 141</td>\n",
        "      <td> 116</td>\n",
        "      <td>  77</td>\n",
        "      <td> 24</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  17893</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  17938</td>\n",
        "      <td> 149</td>\n",
        "      <td>  74</td>\n",
        "      <td>  73</td>\n",
        "      <td> 31</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  18306</td>\n",
        "      <td> 137</td>\n",
        "      <td>  85</td>\n",
        "      <td>  73</td>\n",
        "      <td> 31</td>\n",
        "      <td>  87</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  21903</td>\n",
        "      <td> 124</td>\n",
        "      <td>  62</td>\n",
        "      <td>  84</td>\n",
        "      <td> 31</td>\n",
        "      <td>  82</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  22787</td>\n",
        "      <td> 112</td>\n",
        "      <td>  52</td>\n",
        "      <td>  85</td>\n",
        "      <td> 31</td>\n",
        "      <td>  78</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  23670</td>\n",
        "      <td> 117</td>\n",
        "      <td>  56</td>\n",
        "      <td>  88</td>\n",
        "      <td> 31</td>\n",
        "      <td>  71</td>\n",
        "      <td> 90.7</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29    </th>\n",
        "      <td>    1</td>\n",
        "      <td>  24584</td>\n",
        "      <td> 116</td>\n",
        "      <td>  51</td>\n",
        "      <td>  93</td>\n",
        "      <td> 31</td>\n",
        "      <td>  70</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628407</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 107386</td>\n",
        "      <td> 114</td>\n",
        "      <td>  71</td>\n",
        "      <td>  67</td>\n",
        "      <td> 15</td>\n",
        "      <td>  96</td>\n",
        "      <td> 97.7</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628408</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 111004</td>\n",
        "      <td> 124</td>\n",
        "      <td>  70</td>\n",
        "      <td>  72</td>\n",
        "      <td> 15</td>\n",
        "      <td>  95</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628409</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 114605</td>\n",
        "      <td> 117</td>\n",
        "      <td>  69</td>\n",
        "      <td>  67</td>\n",
        "      <td> 18</td>\n",
        "      <td>  96</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628410</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 115010</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628411</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 118210</td>\n",
        "      <td> 114</td>\n",
        "      <td>  72</td>\n",
        "      <td>  75</td>\n",
        "      <td> 18</td>\n",
        "      <td>  95</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628412</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 121812</td>\n",
        "      <td> 114</td>\n",
        "      <td>  84</td>\n",
        "      <td>  79</td>\n",
        "      <td> 24</td>\n",
        "      <td>  95</td>\n",
        "      <td> 97.1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628413</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 125428</td>\n",
        "      <td> 126</td>\n",
        "      <td>  72</td>\n",
        "      <td>  76</td>\n",
        "      <td> 22</td>\n",
        "      <td>  97</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628414</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 129024</td>\n",
        "      <td> 124</td>\n",
        "      <td>  69</td>\n",
        "      <td>  72</td>\n",
        "      <td> 22</td>\n",
        "      <td>  98</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628415</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 132575</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  97</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628416</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 134562</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  66</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628417</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 134989</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  63</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628418</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 136184</td>\n",
        "      <td> 121</td>\n",
        "      <td>  71</td>\n",
        "      <td>  74</td>\n",
        "      <td> 21</td>\n",
        "      <td>  98</td>\n",
        "      <td> 97.4</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628419</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 143397</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  68</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628420</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 150035</td>\n",
        "      <td> 150</td>\n",
        "      <td>  88</td>\n",
        "      <td>  75</td>\n",
        "      <td> 13</td>\n",
        "      <td>  96</td>\n",
        "      <td> 98.1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628421</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 150727</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  63</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628422</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 155715</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  72</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628423</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 164985</td>\n",
        "      <td> 124</td>\n",
        "      <td>  78</td>\n",
        "      <td>  69</td>\n",
        "      <td> 25</td>\n",
        "      <td>  94</td>\n",
        "      <td> 98.0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628424</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 179398</td>\n",
        "      <td> 125</td>\n",
        "      <td>  77</td>\n",
        "      <td>  71</td>\n",
        "      <td> 21</td>\n",
        "      <td>  94</td>\n",
        "      <td> 98.7</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628425</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 193776</td>\n",
        "      <td> 119</td>\n",
        "      <td>  85</td>\n",
        "      <td>  62</td>\n",
        "      <td> 22</td>\n",
        "      <td>  93</td>\n",
        "      <td> 98.3</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628426</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 199795</td>\n",
        "      <td> 119</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 98.3</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628427</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 208218</td>\n",
        "      <td> 124</td>\n",
        "      <td>  80</td>\n",
        "      <td>  76</td>\n",
        "      <td> 19</td>\n",
        "      <td>  92</td>\n",
        "      <td> 98.1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628428</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 222611</td>\n",
        "      <td> 127</td>\n",
        "      <td>  92</td>\n",
        "      <td>  73</td>\n",
        "      <td> 17</td>\n",
        "      <td>  95</td>\n",
        "      <td> 98.7</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628429</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 236974</td>\n",
        "      <td> 142</td>\n",
        "      <td>  87</td>\n",
        "      <td>  55</td>\n",
        "      <td> 17</td>\n",
        "      <td>  96</td>\n",
        "      <td> 98.2</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628430</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 251404</td>\n",
        "      <td> 130</td>\n",
        "      <td>  78</td>\n",
        "      <td>  56</td>\n",
        "      <td> 17</td>\n",
        "      <td>  95</td>\n",
        "      <td> 98.0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628431</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 265781</td>\n",
        "      <td> 132</td>\n",
        "      <td>  79</td>\n",
        "      <td>  59</td>\n",
        "      <td> 17</td>\n",
        "      <td>  94</td>\n",
        "      <td> 98.0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628432</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 280223</td>\n",
        "      <td> 112</td>\n",
        "      <td>  50</td>\n",
        "      <td>  58</td>\n",
        "      <td> 17</td>\n",
        "      <td>  95</td>\n",
        "      <td> 97.1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628433</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 290430</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628434</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 296075</td>\n",
        "      <td> 105</td>\n",
        "      <td>  59</td>\n",
        "      <td>  65</td>\n",
        "      <td> 17</td>\n",
        "      <td>  98</td>\n",
        "      <td> 98.3</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628435</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 299096</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  93</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>628436</th>\n",
        "      <td> 3594</td>\n",
        "      <td> 309027</td>\n",
        "      <td> 109</td>\n",
        "      <td>  68</td>\n",
        "      <td>  90</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  94</td>\n",
        "      <td> 98.0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>628437 rows \u00d7 9 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "          ID    TIME   V1   V2   V3  V4   V5    V6  ICU\n",
        "0          1       0   86   49   70 NaN   87   NaN    0\n",
        "1          1    4320  NaN  NaN   70 NaN  NaN   NaN    0\n",
        "2          1    5646   91   58  NaN NaN  NaN  96.6    1\n",
        "3          1    5703  140   73   91  32  NaN   NaN    1\n",
        "4          1    6342  139   90  107  29  101   NaN    1\n",
        "5          1    6609  152   75  109  30  101   NaN    1\n",
        "6          1    6894  140   79   84 NaN   98   NaN    1\n",
        "7          1    6957  140   72  108  31  101   NaN    1\n",
        "8          1    7511  132   68  110  31   95  95.2    1\n",
        "9          1    8372  139   70  106  31   97   NaN    1\n",
        "10         1    9297  134   68  105  31   99   NaN    1\n",
        "11         1   10213  134   68  105  31   99   NaN    1\n",
        "12         1   11079  NaN  NaN  NaN NaN  NaN   NaN    1\n",
        "13         1   11123  132   67   96  31  100  93.1    1\n",
        "14         1   12015  132   69   92  31  101   NaN    1\n",
        "15         1   12889  127   72   92  31   97   NaN    1\n",
        "16         1   13798  124   65   86  31   97   NaN    1\n",
        "17         1   14713  119   67   86  31   97  90.6    1\n",
        "18         1   15577  106   64   80  30   97   NaN    1\n",
        "19         1   16523  NaN  NaN   72  31  NaN   NaN    1\n",
        "20         1   17415  NaN  NaN   94  31  NaN   NaN    1\n",
        "21         1   17581  NaN  NaN   77 NaN  100   NaN    1\n",
        "22         1   17644  141  116   77  24  NaN   NaN    1\n",
        "23         1   17893  NaN  NaN  NaN NaN  NaN   NaN    1\n",
        "24         1   17938  149   74   73  31  NaN   NaN    1\n",
        "25         1   18306  137   85   73  31   87   NaN    1\n",
        "26         1   21903  124   62   84  31   82   NaN    1\n",
        "27         1   22787  112   52   85  31   78   NaN    1\n",
        "28         1   23670  117   56   88  31   71  90.7    1\n",
        "29         1   24584  116   51   93  31   70   NaN    1\n",
        "...      ...     ...  ...  ...  ...  ..  ...   ...  ...\n",
        "628407  3594  107386  114   71   67  15   96  97.7    1\n",
        "628408  3594  111004  124   70   72  15   95   NaN    1\n",
        "628409  3594  114605  117   69   67  18   96   NaN    1\n",
        "628410  3594  115010  NaN  NaN  NaN NaN  NaN   NaN    1\n",
        "628411  3594  118210  114   72   75  18   95   NaN    1\n",
        "628412  3594  121812  114   84   79  24   95  97.1    1\n",
        "628413  3594  125428  126   72   76  22   97   NaN    1\n",
        "628414  3594  129024  124   69   72  22   98   NaN    1\n",
        "628415  3594  132575  NaN  NaN  NaN NaN   97   NaN    1\n",
        "628416  3594  134562  NaN  NaN   66 NaN  NaN   NaN    1\n",
        "628417  3594  134989  NaN  NaN   63 NaN  NaN   NaN    1\n",
        "628418  3594  136184  121   71   74  21   98  97.4    1\n",
        "628419  3594  143397  NaN  NaN   68 NaN  NaN   NaN    1\n",
        "628420  3594  150035  150   88   75  13   96  98.1    1\n",
        "628421  3594  150727  NaN  NaN   63 NaN  NaN   NaN    1\n",
        "628422  3594  155715  NaN  NaN   72 NaN  NaN   NaN    1\n",
        "628423  3594  164985  124   78   69  25   94  98.0    1\n",
        "628424  3594  179398  125   77   71  21   94  98.7    1\n",
        "628425  3594  193776  119   85   62  22   93  98.3    1\n",
        "628426  3594  199795  119  NaN  NaN NaN  NaN  98.3    1\n",
        "628427  3594  208218  124   80   76  19   92  98.1    1\n",
        "628428  3594  222611  127   92   73  17   95  98.7    1\n",
        "628429  3594  236974  142   87   55  17   96  98.2    1\n",
        "628430  3594  251404  130   78   56  17   95  98.0    1\n",
        "628431  3594  265781  132   79   59  17   94  98.0    1\n",
        "628432  3594  280223  112   50   58  17   95  97.1    1\n",
        "628433  3594  290430  NaN  NaN  NaN NaN  NaN   NaN    1\n",
        "628434  3594  296075  105   59   65  17   98  98.3    1\n",
        "628435  3594  299096  NaN  NaN  NaN NaN   93   NaN    1\n",
        "628436  3594  309027  109   68   90 NaN   94  98.0    1\n",
        "\n",
        "[628437 rows x 9 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vitals = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(6):\n",
      "    col = 'V' + str(i)\n",
      "    v = df_vitals.ix[]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Impute with mean\n",
      "df_vitals_mean = df_vitals.copy()\n",
      "for i in xrange(1, 7):\n",
      "    col = 'V' + str(i)\n",
      "    index = df_vitals_mean.ix[:, col].isnull()\n",
      "    df_vitals_mean.ix[index, col] = df_vitals_mean.ix[index^1, col].mean()\n",
      "df_labs_mean = df_labs.copy()\n",
      "for i in xrange(1, 26):\n",
      "    col = 'L' + str(i)\n",
      "    index = df_labs_mean.ix[:, col].isnull()\n",
      "    df_labs_mean.ix[index, col] = df_labs_mean.ix[index^1, col].mean()\n",
      "# Combined values imputed with mean\n",
      "patient_combined_mean = [np.append(np.array(df_vitals_mean.ix[df_vitals_mean['ID'] == ID, 2:8]),\n",
      "                                   np.array(df_labs_mean.ix[df_labs_mean['ID'] == ID, 2:27]), axis=1)\n",
      "                         for ID in df_labels['ID'].unique()                        \n",
      "                         ]\n",
      "\n",
      "labels_combined = list(df_labels.ix[:, 'LABEL'])\n",
      "# Windows!\n",
      "window_size = 10\n",
      "stride = 1\n",
      "n_features = 31\n",
      "n_stats = 4\n",
      "data = patient_combined_mean\n",
      "labels = []\n",
      "window_stats = []\n",
      "\n",
      "for i in xrange(len(data)):\n",
      "    ts = data[i]\n",
      "    n_windows = ts.shape[0] - window_size + 1 # NO STRIDE!!\n",
      "    \n",
      "    if(n_windows <= 0):\n",
      "        #window_stats.append(None)    # We want to keep 1-1 mapping with patients..\n",
      "        continue\n",
      "    \n",
      "    l = np.zeros((n_windows, n_stats * n_features))\n",
      "    \n",
      "    for j in xrange(0, n_windows, stride):   # NO STRIDE!\n",
      "        window = ts[j : window_size+j, :] \n",
      "        l[j, :n_features] = np.nanmean(window, axis=0)\n",
      "        l[j, n_features:2*n_features] = np.nanvar(window, axis=0)\n",
      "        l[j, 2*n_features:3*n_features] = np.nanmin(window, axis=0)\n",
      "        l[j, 3*n_features:4*n_features] = np.nanmax(window, axis=0)\n",
      "    \n",
      "    window_stats.append(l)\n",
      "    labels.append(labels_combined[i])\n",
      "\n",
      "# SET teh global variable\n",
      "window_stats_patient = window_stats\n",
      "labels = np.array(labels)\n",
      "print len(window_stats_patient)\n",
      "print len(labels)\n",
      "### Save the data\n",
      "np.save('/root/code/xerox/windows/windows_combined', window_stats_patient)\n",
      "np.save('/root/code/xerox/windows/labels_combined', labels)\n",
      "### No. of patients with NO WINDOW\n",
      "print sum([window_stats_patient_dead[i] == None for i in xrange(n_dead)])\n",
      "print sum([window_stats_patient_living[i] == None for i in xrange(n_living)])\n",
      "print len(window_stats_patient_dead)\n",
      "print len(window_stats_patient_living)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_combined = np.load('/root/code/xerox/windows/windows_combined.npy')\n",
      "labels_combined = np.load('/root/code/xerox/windows/labels_combined.npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(labels_combined)\n",
      "print len(data_combined)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3546\n",
        "3546\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# RANDOM FOREST"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind = np.arange(0, len(labels_combined))\n",
      "np.random.shuffle(ind)\n",
      "N = len(ind)\n",
      "split = 0.8"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N_train = int(split * N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind_train = ind[:N_train]\n",
      "ind_valid = ind[N_train:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(99,)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "(99, 1)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_train = labels_train[1:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = svm.NuSVC(kernel='poly', degree=2, gamma=10**(-1.7))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s.fit(data_train, labels_train[:, 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "setting an array element with a sequence.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-21-d3fb7584a26d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/kcm/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/kcm/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Divide into sets and then stack to get dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Generte the data matrix for stacked data\n",
      "data_train = np.vstack(data_combined[ind_train])\n",
      "data_valid = np.vstack(data_combined[ind_valid])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "MemoryError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-9-f9bc301974a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Generte the data matrix for stacked data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_combined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_combined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind_valid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/kcm/anaconda/lib/python2.7/site-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mMemoryError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Generate the labels for the stacked data\n",
      "labels_train = np.vstack([np.zeros((data_combined[i].shape[0], 1)) + labels_combined[i] for i in ind_train])\n",
      "labels_valid = np.vstack([np.zeros((data_combined[i].shape[0], 1)) + labels_combined[i] for i in ind_valid])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_train_dead = int(sum(labels_train)[0])\n",
      "n_train_living = int(sum(1 - labels_train)[0])\n",
      "n_train_combined = n_train_living + n_train_dead"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'labels_train' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-8-91b4119728b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mn_train_dead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mn_train_living\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mn_train_combined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_train_living\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn_train_dead\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'labels_train' is not defined"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_valid_dead = int(sum(labels_valid)[0])\n",
      "n_valid_living = int(sum(1 - labels_valid)[0])\n",
      "n_valid_combined = n_valid_living + n_valid_dead"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print n_train_dead, n_train_living, labels_train.shape[0]\n",
      "print n_valid_dead, n_valid_living, labels_valid.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "56828 415719 472547\n",
        "14358 109327 123685\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Generate list of living and dead patients in train and validation dtta"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patient_train_living = [data_combined[i] for i in ind_train if labels_combined[i] ==0]\n",
      "patient_train_dead = [data_combined[i] for i in ind_train if labels_combined[i] ==1]\n",
      "patient_valid_living = [data_combined[i] for i in ind_valid if labels_combined[i] ==0]\n",
      "patient_valid_dead = [data_combined[i] for i in ind_valid if labels_combined[i] ==1]\n",
      "print len(patient_valid_living), len(patient_valid_dead)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "665 45\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train_living = np.vstack(patient_train_living)\n",
      "data_train_dead = np.vstack(patient_train_dead)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Confusion!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def get_ss(confusion):\n",
      "    tn = confusion[0, 0]  # label=0, pred=0\n",
      "    fp = confusion[0, 1]  # label=0, pred=1\n",
      "    \n",
      "    fn = confusion[1, 0]  # label=1, pred=0\n",
      "    tp = confusion[1, 1]  # label=1, pred=1\n",
      "    \n",
      "    sens = (1.0*tp/(tp+fn))\n",
      "    spec = (1.0*tn/(tn+fp))\n",
      "    \n",
      "    print confusion\n",
      "    print\n",
      "    #print tp, fp, fn, tn, sens, spec\n",
      "    print 'Sensitiviy: ', sens, '\\nSpecificity: ', spec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Split training set into equal dead and living parts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_train_living/ n_train_dead"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "7"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_split = int (n_train_living / (n_train_living / n_train_dead))\n",
      "n_train_splits = int (n_train_living / n_train_dead)\n",
      "print n_train_splits, train_split, n_train_splits * train_split, n_train_combined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7 59388 415716 472547\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forests = [svm.NuSVC(kernel='poly', degree=2, gamma=10**(-1.7), probability=True)] * n_train_splits"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forests[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "NuSVC(cache_size=200, coef0=0.0, degree=2, gamma=0.0199526231497,\n",
        "   kernel='poly', max_iter=-1, nu=0.5, probability=True, random_state=None,\n",
        "   shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "for i in xrange(len(C_valid)):\n",
      "    print i\n",
      "    get_ss(C_train[i])\n",
      "    print \n",
      "    get_ss(C_valid[i])\n",
      "    print\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "[[54622     6]\n",
        " [   49 54579]]\n",
        "\n",
        "Sensitiviy:  0.99910302409 \n",
        "Specificity:  0.999890166215\n",
        "\n",
        "[[75266 26112]\n",
        " [ 6737  9821]]\n",
        "\n",
        "Sensitiviy:  0.593127189274 \n",
        "Specificity:  0.742429323916\n",
        "\n",
        "\n",
        "1\n",
        "[[54614    14]\n",
        " [   43 54585]]\n",
        "\n",
        "Sensitiviy:  0.999212857875 \n",
        "Specificity:  0.999743721169\n",
        "\n",
        "[[75267 26111]\n",
        " [ 6887  9671]]\n",
        "\n",
        "Sensitiviy:  0.58406812417 \n",
        "Specificity:  0.74243918799\n",
        "\n",
        "\n",
        "2\n",
        "[[54619     9]\n",
        " [   32 54596]]\n",
        "\n",
        "Sensitiviy:  0.999414219814 \n",
        "Specificity:  0.999835249323\n",
        "\n",
        "[[71453 29925]\n",
        " [ 5955 10603]]\n",
        "\n",
        "Sensitiviy:  0.640355115352 \n",
        "Specificity:  0.704817613289\n",
        "\n",
        "\n",
        "3\n",
        "[[54623     5]\n",
        " [   57 54571]]\n",
        "\n",
        "Sensitiviy:  0.998956579044 \n",
        "Specificity:  0.999908471846\n",
        "\n",
        "[[75341 26037]\n",
        " [ 7105  9453]]\n",
        "\n",
        "Sensitiviy:  0.570902282884 \n",
        "Specificity:  0.743169129397\n",
        "\n",
        "\n",
        "4\n",
        "[[54622     6]\n",
        " [   51 54577]]\n",
        "\n",
        "Sensitiviy:  0.999066412829 \n",
        "Specificity:  0.999890166215\n",
        "\n",
        "[[75505 25873]\n",
        " [ 6768  9790]]\n",
        "\n",
        "Sensitiviy:  0.591254982486 \n",
        "Specificity:  0.744786837381\n",
        "\n",
        "\n",
        "5\n",
        "[[54619     9]\n",
        " [   47 54581]]\n",
        "\n",
        "Sensitiviy:  0.999139635352 \n",
        "Specificity:  0.999835249323\n",
        "\n",
        "[[74604 26774]\n",
        " [ 6884  9674]]\n",
        "\n",
        "Sensitiviy:  0.584249305472 \n",
        "Specificity:  0.735899307542\n",
        "\n",
        "\n",
        "6\n",
        "[[54622     6]\n",
        " [   39 54589]]\n",
        "\n",
        "Sensitiviy:  0.999286080398 \n",
        "Specificity:  0.999890166215\n",
        "\n",
        "[[74630 26748]\n",
        " [ 7064  9494]]\n",
        "\n",
        "Sensitiviy:  0.573378427346 \n",
        "Specificity:  0.736155773442\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 267
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C_train = []\n",
      "C_valid = []\n",
      "y_valid = np.zeros((n_valid_combined, n_train_splits))\n",
      "for i in xrange(n_train_splits):\n",
      "    #ind_bal = np.arange(0, train_split+n_train_dead); np.random.shuffle(ind_bal);\n",
      "    data_bal = np.vstack((data_train_living[i*train_split:(i+1)*train_split, :], data_train_dead[:, :]) )\n",
      "    label_bal = np.vstack((np.zeros((train_split, 1)), np.ones((n_train_dead, 1))))\n",
      "    \n",
      "    forests[i].fit(data_bal, label_bal)\n",
      "    \n",
      "    print i\n",
      "    C_train.append(metrics.confusion_matrix(label_bal, forests[i].predict(data_bal)))\n",
      "    get_ss(C_train[i])\n",
      "    print\n",
      "    y = forests[i].predict(data_valid)\n",
      "    y_valid[:, i] = y\n",
      "    C_valid.append(metrics.confusion_matrix(labels_valid, y))\n",
      "    get_ss(C_valid[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(y_valid, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 205,
       "text": [
        "array([ 35933.,  35782.,  40528.,  35490.,  35663.,  36448.,  36242.])"
       ]
      }
     ],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Majority vote?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comp_matrix = np.zeros((n_valid_combined, n_train_splits))\n",
      "for i in xrange(n_train_splits):\n",
      "    comp_matrix[:, i] = y_valid[:, i] == labels_valid[:, 0]\n",
      "print comp_matrix.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(117936, 7)\n"
       ]
      }
     ],
     "prompt_number": 273
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(comp_matrix, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 274,
       "text": [
        "array([ 81163.,  81262.,  77635.,  80204.,  81121.,  80790.,  80836.])"
       ]
      }
     ],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s_1 = np.max(comp_matrix, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 307
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_1 = labels_valid.copy()\n",
      "y_1 = 1-y_1;\n",
      "y_1[s_1 == 1] = labels_valid[s_1 == 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 314
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_1.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 322,
       "text": [
        "(117936, 1)"
       ]
      }
     ],
     "prompt_number": 322
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_ss(metrics.confusion_matrix(labels_valid, y_1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[92956  8422]\n",
        " [ 1614 14944]]\n",
        "\n",
        "Sensitiviy:  0.902524459476 \n",
        "Specificity:  0.916924776579\n"
       ]
      }
     ],
     "prompt_number": 323
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(np.sum(comp_matrix[labels_valid[:, 0] == 1 ,:], axis=1)>0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 278,
       "text": [
        "14944"
       ]
      }
     ],
     "prompt_number": 278
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Combining the arrays makes predictions much much faster, but adds an overhead to find patients\n",
      "data_train_living = np.vstack(patient_train_living)\n",
      "data_train_dead = np.vstack(patient_train_dead)\n",
      "data_valid_living = np.vstack(patient_valid_living)\n",
      "data_valid_dead = np.vstack(patient_valid_dead)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate Ids of patients in the training and validation separated arrays\n",
      "id_train_living = np.vstack([np.zeros((patient.shape[0], 1)) + i for i, patient in enumerate(patient_train_living)\n",
      "                             ])\n",
      "id_train_dead = np.vstack([np.zeros((patient.shape[0], 1)) + i for i, patient in enumerate(patient_train_dead)\n",
      "                             ])\n",
      "id_valid_living = np.vstack([np.zeros((patient.shape[0], 1)) + i for i, patient in enumerate(patient_valid_living)\n",
      "                             ])\n",
      "id_valid_dead = np.vstack([np.zeros((patient.shape[0], 1)) + i for i, patient in enumerate(patient_valid_dead)\n",
      "                             ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 365
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Predict separtely for each of the sets\n",
      "pred_train_living = f.predict(data_train_living)\n",
      "pred_train_dead = f.predict(data_train_dead)\n",
      "pred_valid_dead = f.predict(data_valid_dead)\n",
      "pred_valid_living = f.predict(data_valid_living)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 423
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To easily access a specific patient\n",
      "def predp_train_living(i):\n",
      "    return pred_train_living[id_train_living[:, 0] == i]\n",
      "def predp_train_dead(i):\n",
      "    return pred_train_dead[id_train_dead[:, 0] == i]\n",
      "\n",
      "def predp_valid_living(i):\n",
      "    return pred_valid_living[id_valid_living[:, 0] == i]\n",
      "def predp_valid_dead(i):\n",
      "    return pred_valid_dead[id_valid_dead[:, 0] == i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 424
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_valid_living = np.array([np.array(predp_valid_living(i)) for i in xrange(len(patient_valid_living))])\n",
      "y_valid_dead = np.array([np.array(predp_valid_dead(i)) for i in xrange(len(patient_valid_dead))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 438
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train_living = np.array([np.array(predp_train_living(i)) for i in xrange(len(patient_train_living))])\n",
      "y_train_dead = np.array([np.array(predp_train_dead(i)) for i in xrange(len(patient_train_dead))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 439
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_valid_living = np.array([np.mean(predp_valid_living(i)) for i in xrange(len(patient_valid_living))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 433
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(y_valid_living < 0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 435,
       "text": [
        "0.9609022556390977"
       ]
      }
     ],
     "prompt_number": 435
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "for i in xrange(len(patient_valid_living)):\n",
      "    print np.mean(predp_valid_living(i))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n",
        "0.1875\n",
        "0.0229885057471\n",
        "0.433333333333\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0888888888889\n",
        "0.0\n",
        "0.138047138047\n",
        "0.144032921811\n",
        "0.14224137931\n",
        "0.0\n",
        "0.266666666667\n",
        "0.0\n",
        "0.0\n",
        "0.012323943662\n",
        "0.0487804878049\n",
        "0.312072892938\n",
        "0.0\n",
        "0.162303664921\n",
        "0.0\n",
        "0.0\n",
        "0.0760869565217\n",
        "0.0\n",
        "0.0\n",
        "0.148936170213\n",
        "0.0\n",
        "0.0197238658777\n",
        "0.0\n",
        "0.178489702517\n",
        "0.0\n",
        "0.0995260663507\n",
        "0.0120481927711\n",
        "0.0\n",
        "0.0\n",
        "0.00793650793651\n",
        "0.0\n",
        "0.0\n",
        "0.280961182994\n",
        "0.030534351145\n",
        "0.0\n",
        "0.0\n",
        "0.112676056338\n",
        "0.121428571429\n",
        "0.10071942446\n",
        "0.0\n",
        "0.0\n",
        "0.432098765432\n",
        "0.0\n",
        "0.0909090909091\n",
        "0.0\n",
        "0.0932203389831\n",
        "0.0\n",
        "0.070796460177\n",
        "0.0\n",
        "0.441176470588\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.00520833333333\n",
        "0.0\n",
        "0.0149253731343\n",
        "0.0\n",
        "0.131661442006\n",
        "0.166666666667\n",
        "0.244956772334\n",
        "0.0280373831776\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.187145557656\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.19298245614\n",
        "0.282402528978\n",
        "0.264462809917\n",
        "0.0247933884298\n",
        "0.048275862069\n",
        "0.0\n",
        "0.0\n",
        "0.328125\n",
        "0.0965732087227\n",
        "0.149377593361\n",
        "0.0267857142857\n",
        "0.0449438202247\n",
        "0.0\n",
        "0.0\n",
        "0.0194174757282\n",
        "0.192307692308\n",
        "0.0142857142857\n",
        "0.0\n",
        "0.0\n",
        "0.0579710144928\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.217948717949\n",
        "0.471074380165\n",
        "0.0\n",
        "0.0724637681159\n",
        "0.0\n",
        "0.227848101266\n",
        "0.012987012987\n",
        "0.244897959184\n",
        "0.0\n",
        "0.0\n",
        "0.0377358490566\n",
        "0.0\n",
        "0.0\n",
        "0.226666666667\n",
        "0.0\n",
        "0.170212765957\n",
        "0.0\n",
        "0.0\n",
        "0.03\n",
        "0.0\n",
        "0.0\n",
        "0.188449848024\n",
        "0.0\n",
        "0.271428571429\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.155172413793\n",
        "0.148648648649\n",
        "0.25\n",
        "0.0\n",
        "0.0\n",
        "0.125\n",
        "0.0526315789474\n",
        "0.0\n",
        "0.00701754385965\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.016393442623\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.190476190476\n",
        "0.194092827004\n",
        "0.0856031128405\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.388838060384\n",
        "0.0\n",
        "0.0195652173913\n",
        "0.0155642023346\n",
        "0.285714285714\n",
        "0.333333333333\n",
        "0.246575342466\n",
        "0.107692307692\n",
        "0.218181818182\n",
        "0.0\n",
        "0.0\n",
        "0.0326086956522\n",
        "0.0\n",
        "0.072864321608\n",
        "0.0\n",
        "0.0191570881226\n",
        "0.129909365559\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0736842105263\n",
        "0.0751252086811\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.00461538461538\n",
        "0.00149700598802\n",
        "0.00247524752475\n",
        "0.0\n",
        "0.196335078534\n",
        "0.0567164179104\n",
        "0.0\n",
        "0.0\n",
        "0.166666666667\n",
        "0.178947368421\n",
        "0.390438247012\n",
        "0.00847457627119\n",
        "0.0\n",
        "0.207207207207\n",
        "0.0980392156863\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.16393442623\n",
        "0.0352760736196\n",
        "0.0\n",
        "0.0333333333333\n",
        "0.0\n",
        "0.036036036036\n",
        "0.0637362637363\n",
        "0.0\n",
        "0.0970873786408\n",
        "0.0\n",
        "0.0361445783133\n",
        "0.05\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.121951219512\n",
        "0.0\n",
        "0.0\n",
        "0.197674418605\n",
        "0.0155440414508\n",
        "0.0\n",
        "0.0120192307692\n",
        "0.0309734513274\n",
        "0.0823529411765\n",
        "0.0\n",
        "0.0181818181818\n",
        "0.0703125\n",
        "0.0\n",
        "0.162629757785\n",
        "0.0\n",
        "0.0\n",
        "0.0121951219512\n",
        "0.00970873786408\n",
        "0.0583333333333\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.116438356164\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0645161290323\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.122302158273\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0505836575875\n",
        "0.0173913043478\n",
        "0.109022556391\n",
        "0.133333333333\n",
        "0.0\n",
        "0.115384615385\n",
        "0.0\n",
        "0.0334728033473\n",
        "0.277777777778\n",
        "0.00819672131148\n",
        "0.0484848484848\n",
        "0.00595238095238\n",
        "0.12\n",
        "0.0\n",
        "0.222921914358\n",
        "0.0\n",
        "0.0\n",
        "0.0188679245283\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0208333333333\n",
        "0.0890410958904\n",
        "0.0196078431373\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.105734767025\n",
        "0.265402843602\n",
        "0.0\n",
        "0.416666666667\n",
        "0.0740740740741\n",
        "0.0\n",
        "0.0902255639098\n",
        "0.0\n",
        "0.0\n",
        "0.103448275862\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.359154929577\n",
        "0.0\n",
        "0.0\n",
        "0.06\n",
        "0.0552995391705\n",
        "0.0\n",
        "0.379562043796\n",
        "0.165876777251\n",
        "0.256013745704\n",
        "0.0521172638436\n",
        "0.0\n",
        "0.182186234818\n",
        "0.262295081967\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0294117647059\n",
        "0.0\n",
        "0.364341085271\n",
        "0.133333333333\n",
        "0.0\n",
        "0.149028077754\n",
        "0.0\n",
        "0.172413793103\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0125\n",
        "0.211267605634\n",
        "0.0496688741722\n",
        "0.0149253731343\n",
        "0.0173010380623\n",
        "0.0\n",
        "0.300429184549\n",
        "0.0\n",
        "0.0\n",
        "0.212543554007\n",
        "0.0375\n",
        "0.0\n",
        "0.0839694656489\n",
        "0.0\n",
        "0.00136612021858\n",
        "0.00970873786408\n",
        "0.352813852814\n",
        "0.073732718894\n",
        "0.04\n",
        "0.0188679245283\n",
        "0.0\n",
        "0.117647058824\n",
        "0.0\n",
        "0.2\n",
        "0.0736196319018\n",
        "0.0\n",
        "0.0210970464135\n",
        "0.0434782608696\n",
        "0.0\n",
        "0.223880597015\n",
        "0.00363636363636\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.225\n",
        "0.0\n",
        "0.0\n",
        "0.10752688172\n",
        "0.0\n",
        "0.0\n",
        "0.0377358490566\n",
        "0.0555555555556\n",
        "0.015625\n",
        "0.0384615384615\n",
        "0.16835016835\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.181818181818\n",
        "0.0\n",
        "0.0\n",
        "0.089715536105\n",
        "0.025\n",
        "0.0\n",
        "0.00540540540541\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.11320754717\n",
        "0.0\n",
        "0.0\n",
        "0.0617283950617\n",
        "0.397402597403\n",
        "0.005\n",
        "0.0229885057471\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0696864111498\n",
        "0.0\n",
        "0.00411522633745\n",
        "0.265306122449\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.303825956489\n",
        "0.0384615384615\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0319634703196\n",
        "0.0344827586207\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.5\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.00434782608696\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0277777777778\n",
        "0.192592592593\n",
        "0.0\n",
        "0.0778947368421\n",
        "0.0204081632653\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.00772200772201\n",
        "0.0\n",
        "0.127272727273\n",
        "0.392572944297\n",
        "0.043795620438\n",
        "0.0\n",
        "0.0\n",
        "0.00819672131148\n",
        "0.0406504065041\n",
        "0.0125\n",
        "0.0\n",
        "0.142857142857\n",
        "0.0\n",
        "0.093023255814\n",
        "0.0\n",
        "0.0\n",
        "0.110655737705\n",
        "0.00220750551876\n",
        "0.0\n",
        "0.0137457044674\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.145695364238\n",
        "0.0111111111111\n",
        "0.0\n",
        "0.0606060606061\n",
        "0.0172413793103\n",
        "0.00540540540541\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.136801541426\n",
        "0.0\n",
        "0.0\n",
        "0.16814159292\n",
        "0.0520487264673\n",
        "0.0\n",
        "0.0551181102362\n",
        "0.135135135135\n",
        "0.183098591549\n",
        "0.205128205128\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0845070422535\n",
        "0.018691588785\n",
        "0.0227272727273\n",
        "0.0901639344262\n",
        "0.0\n",
        "0.0176470588235\n",
        "0.0108695652174\n",
        "0.0\n",
        "0.185897435897\n",
        "0.0\n",
        "0.22972972973\n",
        "0.217391304348\n",
        "0.0570469798658\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.197580645161\n",
        "0.224880382775\n",
        "0.0666666666667\n",
        "0.0178571428571\n",
        "0.0952380952381\n",
        "0.0491803278689\n",
        "0.138888888889\n",
        "0.386666666667\n",
        "0.0\n",
        "0.120728929385\n",
        "0.0223880597015\n",
        "0.0\n",
        "0.0\n",
        "0.0432432432432\n",
        "0.0170454545455\n",
        "0.122270742358\n",
        "0.0\n",
        "0.336956521739\n",
        "0.0062893081761\n",
        "0.0\n",
        "0.0\n",
        "0.131578947368\n",
        "0.393939393939\n",
        "0.0\n",
        "0.0224215246637\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.046875\n",
        "0.0\n",
        "0.158536585366\n",
        "0.0\n",
        "0.0\n",
        "0.025069637883\n",
        "0.191044776119\n",
        "0.025641025641\n",
        "0.158878504673\n",
        "0.0\n",
        "0.025\n",
        "0.025974025974\n",
        "0.0384615384615\n",
        "0.013698630137\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.182978723404\n",
        "0.0\n",
        "0.0919540229885\n",
        "0.0609318996416\n",
        "0.122935779817\n",
        "0.0\n",
        "0.0666666666667\n",
        "0.00369003690037\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.204819277108\n",
        "0.0327868852459\n",
        "0.15\n",
        "0.0240384615385\n",
        "0.047619047619\n",
        "0.0\n",
        "0.016393442623\n",
        "0.00540540540541\n",
        "0.0\n",
        "0.0\n",
        "0.0818181818182\n",
        "0.0\n",
        "0.245901639344\n",
        "0.046511627907\n",
        "0.269911504425\n",
        "0.0\n",
        "0.0217391304348\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.118644067797\n",
        "0.0\n",
        "0.0\n",
        "0.731707317073\n",
        "0.310160427807\n",
        "0.120689655172\n",
        "0.0\n",
        "0.0268096514745\n",
        "0.00881057268722\n",
        "0.0\n",
        "0.0\n",
        "0.270358306189\n",
        "0.0\n",
        "0.152173913043\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.089527027027\n",
        "0.0\n",
        "0.156862745098\n",
        "0.0\n",
        "0.0277777777778\n",
        "0.0324675324675\n",
        "0.252032520325\n",
        "0.0140845070423\n",
        "0.0736842105263\n",
        "0.648648648649\n",
        "0.0\n",
        "0.0\n",
        "0.283636363636\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0177304964539\n",
        "0.288025889968\n",
        "0.00719424460432\n",
        "0.0\n",
        "0.0325581395349\n",
        "0.0243902439024\n",
        "0.0078431372549\n",
        "0.0\n",
        "0.0710227272727\n",
        "0.0\n",
        "0.0\n",
        "0.193103448276\n",
        "0.230182926829\n",
        "0.0\n",
        "0.0\n",
        "0.0425531914894\n",
        "0.0\n",
        "0.281176470588\n",
        "0.0128755364807\n",
        "0.388190954774\n",
        "0.0994623655914\n",
        "0.0368098159509\n",
        "0.0\n",
        "0.0\n",
        "0.0234899328859\n",
        "0.0\n",
        "0.0\n",
        "0.0384615384615\n",
        "0.0\n",
        "0.0555555555556\n",
        "0.0\n",
        "0.0\n",
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 413
    }
   ],
   "metadata": {}
  }
 ]
}