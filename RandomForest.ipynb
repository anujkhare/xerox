{
 "metadata": {
  "name": "",
  "signature": "sha256:a0a78c4e5dafbca8abee4c2477c63c3368c795593466859b8313a880f1f9a492"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%vimception"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Line magic function `%vimception` not found.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import pandas\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Windows!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "window_size = 10\n",
      "stride = 1\n",
      "n_features = 31\n",
      "n_stats = 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### s\n",
      "patient_combined_dead = patient_combined_dead_neg\n",
      "patient_combined_living = patient_combined_living_neg\n",
      "\n",
      "ts_lens_dead = [x.shape[0] for x in patient_combined_dead]\n",
      "ts_lens_living = [x.shape[0] for x in patient_combined_living]\n",
      "\n",
      "n_dead = len(patient_combined_dead)\n",
      "n_living = len(patient_combined_living)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = patient_combined_mean\n",
      "labels = []\n",
      "window_stats = []\n",
      "\n",
      "for i in xrange(len(data)):\n",
      "    ts = data[i]\n",
      "    n_windows = ts.shape[0] - window_size + 1 # NO STRIDE!!\n",
      "    \n",
      "    if(n_windows <= 0):\n",
      "        #window_stats.append(None)    # We want to keep 1-1 mapping with patients..\n",
      "        continue\n",
      "    \n",
      "    l = np.zeros((n_windows, n_stats * n_features))\n",
      "    \n",
      "    for j in xrange(0, n_windows, stride):   # NO STRIDE!\n",
      "        window = ts[j : window_size+j, :] \n",
      "        l[j, :n_features] = np.nanmean(window, axis=0)\n",
      "        l[j, n_features:2*n_features] = np.nanvar(window, axis=0)\n",
      "        l[j, 2*n_features:3*n_features] = np.nanmin(window, axis=0)\n",
      "        l[j, 3*n_features:4*n_features] = np.nanmax(window, axis=0)\n",
      "    \n",
      "    window_stats.append(l)\n",
      "    labels.append(labels_combined[i])\n",
      "\n",
      "# SET teh global variable\n",
      "window_stats_patient = window_stats\n",
      "labels = np.array(labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(window_stats_patient)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3546\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# RANDOM FOREST"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Divide into sets and then stack to get dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt('/root/code/xerox/windows/window_stats_combined', data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "Mismatch between array dtype ('object') and format specifier ('%.18e')",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-680-57dc99d323f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/root/code/xerox/windows/window_stats_combined'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/kcm/anaconda/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1158\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[0;32m   1159\u001b[0m                                     \u001b[1;34m\"format specifier ('%s')\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m                                     % (str(X.dtype), format))\n\u001b[0m\u001b[0;32m   1161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m             \u001b[0mfooter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfooter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: Mismatch between array dtype ('object') and format specifier ('%.18e')"
       ]
      }
     ],
     "prompt_number": 680
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.array(window_stats_patient)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind = np.arange(0, len(labels))\n",
      "np.random.shuffle(ind)\n",
      "N = len(ind)\n",
      "split = 0.8"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_train = int(split * N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind_train = ind[:n_train]\n",
      "ind_valid = ind[n_train:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train = np.vstack(data[ind_train])\n",
      "data_valid = np.vstack(data[ind_valid])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_train = np.vstack([np.zeros((data[i].shape[0], 1)) + labels[i] for i in ind_train])\n",
      "labels_valid = np.vstack([np.zeros((data[i].shape[0], 1)) + labels[i] for i in ind_valid])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_train_dead = sum(labels_train)\n",
      "n_train_living = sum(1 - labels_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 521
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print n_dead_train, n_living_train, labels_train.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 59272.] [ 421434.] 480706\n"
       ]
      }
     ],
     "prompt_number": 354
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print n_living_train / n_dead_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 7.11017006]\n"
       ]
      }
     ],
     "prompt_number": 470
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_split = int (n_train_living / (n_train_living / n_train_dead))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 528
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forests = [RandomForestClassifier(n_estimators=10, max_d)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_bal = RandomForestClassifier(n_estimators=30, max_depth=None, max_features=2, oob_score=True)\n",
      "ind_bal = np.arange(0, train_split+n_dead_train); np.random.shuffle(ind_bal);\n",
      "data_bal = np.vstack((data_train_living[:train_split, :], data_train_dead[:, :]) )\n",
      "label_bal = np.vstack((np.zeros((train_split, 1)), np.ones((n_train_dead, 1))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 672
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_bal.fit(data_bal, label_bal)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 673,
       "text": [
        "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=None, max_features=2, max_leaf_nodes=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
        "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
       ]
      }
     ],
     "prompt_number": 673
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_bal.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 674,
       "text": [
        "0.98040390066135785"
       ]
      }
     ],
     "prompt_number": 674
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_bal.score(data_bal, label_bal)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 675,
       "text": [
        "0.99999156431367253"
       ]
      }
     ],
     "prompt_number": 675
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_bal.score(data_valid, labels_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 676,
       "text": [
        "0.72044388276232185"
       ]
      }
     ],
     "prompt_number": 676
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.confusion_matrix(label_bal, f_bal.predict(data_bal))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 670,
       "text": [
        "array([[59272,     0],\n",
        "       [    1, 59271]])"
       ]
      }
     ],
     "prompt_number": 670
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.confusion_matrix(labels_valid, f_bal.predict(data_valid))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 671,
       "text": [
        "array([[76448, 27164],\n",
        "       [ 5279,  6635]])"
       ]
      }
     ],
     "prompt_number": 671
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Weigh inversely propotional to sizes\n",
      "w0 = n_dead_train / (n_dead_train + n_living_train)\n",
      "w1 = n_living_train / (n_dead_train + n_living_train)\n",
      "print w0, w1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.12330198] [ 0.87669802]\n"
       ]
      }
     ],
     "prompt_number": 355
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = RandomForestClassifier(n_estimators=10, max_depth=20, n_jobs=-1, class_weight={0:w0, 1:1} ,oob_score=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 250,
       "text": [
        "(480706, 124)"
       ]
      }
     ],
     "prompt_number": 250
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.fit(data_train, labels_train[:, 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 251,
       "text": [
        "RandomForestClassifier(bootstrap=True,\n",
        "            class_weight={0: array([ 0.1233]), 1: 1}, criterion='gini',\n",
        "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
        "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
       ]
      }
     ],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.oob_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 252,
       "text": [
        "0.90600907831397981"
       ]
      }
     ],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.score(data_valid, labels_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 253,
       "text": [
        "0.82910340529404636"
       ]
      }
     ],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train = f.predict(data_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(labels_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 255,
       "text": [
        "array([ 11914.])"
       ]
      }
     ],
     "prompt_number": 255
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metric"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'metric' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-eeb1e9249a73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'metric' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = metric.confusion_matrix(labels_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'metric' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-67c66aed1a3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'metric' is not defined"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_predicted = f.predict(data_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 257
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum([(1-y_predicted[i]) for i in xrange(len(y_predicted)) if labels_valid[i]==1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 258,
       "text": [
        "9670.0"
       ]
      }
     ],
     "prompt_number": 258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.confusion_matrix(labels_valid, y_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 259,
       "text": [
        "array([[93539, 10073],\n",
        "       [ 9670,  2244]])"
       ]
      }
     ],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "10073.0 / (10073 + 2244)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "0.8178127790858164"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "2244.0 / 9670"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "0.23205791106514995"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Now try sequence prediction!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patient_train_living = [data[i] for i in ind_train if labels[i] ==0]\n",
      "patient_train_dead = [data[i] for i in ind_train if labels[i] ==1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patient_valid_living = [data[i] for i in ind_valid if labels[i] ==0]\n",
      "patient_valid_dead = [data[i] for i in ind_valid if labels[i] ==1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 262
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(patient_valid_living), len(patient_valid_dead)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "665 45\n"
       ]
      }
     ],
     "prompt_number": 263
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forest = RandomForestClassifier(n_estimators=10, max_depth=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 453
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_all = np.vstack((data_train, data_valid))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 461
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_all = np.vstack((labels_train, labels_valid))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 465
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forest.fit(data_all, labels_all)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 466,
       "text": [
        "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0,\n",
        "            warm_start=False)"
       ]
      }
     ],
     "prompt_number": 466
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Feature importances!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances = forest.feature_importances_\n",
      "\n",
      "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
      "indices = np.argsort(importances)[::-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 467
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(124):\n",
      "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
      "\n",
      "# Plot the feature importances of the forest\n",
      "plt.figure()\n",
      "plt.title(\"Feature importances\")\n",
      "plt.bar(range(124), importances[indices],\n",
      "       color=\"r\", yerr=std[indices], align=\"center\")\n",
      "plt.xticks(range(124), indices)\n",
      "plt.xlim([-1, 125])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature ranking:\n",
        "1. feature 2 (0.043686)\n",
        "2. feature 3 (0.039663)\n",
        "3. feature 65 (0.039507)\n",
        "4. feature 0 (0.032293)\n",
        "5. feature 4 (0.031835)\n",
        "6. feature 95 (0.027690)\n",
        "7. feature 1 (0.027282)\n",
        "8. feature 63 (0.027251)\n",
        "9. feature 62 (0.025958)\n",
        "10. feature 34 (0.025483)\n",
        "11. feature 32 (0.024803)\n",
        "12. feature 64 (0.024066)\n",
        "13. feature 35 (0.023747)\n",
        "14. feature 5 (0.023543)\n",
        "15. feature 33 (0.023375)\n",
        "16. feature 94 (0.023098)\n",
        "17. feature 93 (0.022652)\n",
        "18. feature 36 (0.022189)\n",
        "19. feature 31 (0.022154)\n",
        "20. feature 96 (0.021898)\n",
        "21. feature 66 (0.019856)\n",
        "22. feature 67 (0.018578)\n",
        "23. feature 98 (0.017980)\n",
        "24. feature 23 (0.017231)\n",
        "25. feature 54 (0.016283)\n",
        "26. feature 97 (0.015198)\n",
        "27. feature 85 (0.013307)\n",
        "28. feature 13 (0.009328)\n",
        "29. feature 116 (0.009129)\n",
        "30. feature 9 (0.008895)\n",
        "31. feature 74 (0.008789)\n",
        "32. feature 48 (0.008706)\n",
        "33. feature 12 (0.007978)\n",
        "34. feature 40 (0.007745)\n",
        "35. feature 10 (0.007650)\n",
        "36. feature 16 (0.007100)\n",
        "37. feature 73 (0.006892)\n",
        "38. feature 41 (0.006814)\n",
        "39. feature 44 (0.006762)\n",
        "40. feature 102 (0.006652)\n",
        "41. feature 43 (0.006423)\n",
        "42. feature 11 (0.006162)\n",
        "43. feature 26 (0.005603)\n",
        "44. feature 25 (0.005596)\n",
        "45. feature 15 (0.005481)\n",
        "46. feature 14 (0.005426)\n",
        "47. feature 47 (0.005254)\n",
        "48. feature 75 (0.005223)\n",
        "49. feature 6 (0.005115)\n",
        "50. feature 46 (0.005106)\n",
        "51. feature 72 (0.005001)\n",
        "52. feature 78 (0.004877)\n",
        "53. feature 88 (0.004768)\n",
        "54. feature 17 (0.004637)\n",
        "55. feature 8 (0.004587)\n",
        "56. feature 7 (0.004578)\n",
        "57. feature 106 (0.004556)\n",
        "58. feature 105 (0.004542)\n",
        "59. feature 45 (0.004518)\n",
        "60. feature 42 (0.004435)\n",
        "61. feature 110 (0.004425)\n",
        "62. feature 71 (0.004399)\n",
        "63. feature 37 (0.004368)\n",
        "64. feature 39 (0.004299)\n",
        "65. feature 38 (0.004254)\n",
        "66. feature 77 (0.004236)\n",
        "67. feature 103 (0.004221)\n",
        "68. feature 27 (0.004095)\n",
        "69. feature 118 (0.004059)\n",
        "70. feature 57 (0.004050)\n",
        "71. feature 30 (0.004039)\n",
        "72. feature 56 (0.003938)\n",
        "73. feature 76 (0.003744)\n",
        "74. feature 69 (0.003574)\n",
        "75. feature 61 (0.003407)\n",
        "76. feature 70 (0.003263)\n",
        "77. feature 20 (0.003161)\n",
        "78. feature 99 (0.002954)\n",
        "79. feature 120 (0.002921)\n",
        "80. feature 113 (0.002803)\n",
        "81. feature 51 (0.002721)\n",
        "82. feature 109 (0.002524)\n",
        "83. feature 68 (0.002498)\n",
        "84. feature 28 (0.002487)\n",
        "85. feature 58 (0.002420)\n",
        "86. feature 92 (0.002392)\n",
        "87. feature 59 (0.002347)\n",
        "88. feature 108 (0.002330)\n",
        "89. feature 123 (0.002275)\n",
        "90. feature 87 (0.002235)\n",
        "91. feature 104 (0.002175)\n",
        "92. feature 21 (0.002146)\n",
        "93. feature 107 (0.002068)\n",
        "94. feature 101 (0.001805)\n",
        "95. feature 79 (0.001802)\n",
        "96. feature 83 (0.001797)\n",
        "97. feature 100 (0.001783)\n",
        "98. feature 52 (0.001705)\n",
        "99. feature 89 (0.001613)\n",
        "100. feature 82 (0.001499)\n",
        "101. feature 121 (0.001317)\n",
        "102. feature 90 (0.001305)\n",
        "103. feature 119 (0.001135)\n",
        "104. feature 50 (0.000335)\n",
        "105. feature 114 (0.000301)\n",
        "106. feature 19 (0.000285)\n",
        "107. feature 24 (0.000269)\n",
        "108. feature 81 (0.000244)\n",
        "109. feature 115 (0.000178)\n",
        "110. feature 55 (0.000150)\n",
        "111. feature 112 (0.000137)\n",
        "112. feature 22 (0.000134)\n",
        "113. feature 29 (0.000122)\n",
        "114. feature 86 (0.000089)\n",
        "115. feature 53 (0.000082)\n",
        "116. feature 84 (0.000054)\n",
        "117. feature 60 (0.000053)\n",
        "118. feature 91 (0.000021)\n",
        "119. feature 117 (0.000019)\n",
        "120. feature 122 (0.000006)\n",
        "121. feature 49 (0.000001)\n",
        "122. feature 80 (0.000000)\n",
        "123. feature 111 (0.000000)\n",
        "124. feature 18 (0.000000)\n"
       ]
      }
     ],
     "prompt_number": 468
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classify sequences of patients using the mean of the window prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Combining the arrays makes predictions much much faster, but adds an overhead to find patients\n",
      "data_train_living = np.vstack(patient_train_living)\n",
      "data_train_dead = np.vstack(patient_train_dead)\n",
      "data_valid_living = np.vstack(patient_valid_living)\n",
      "data_valid_dead = np.vstack(patient_valid_dead)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate Ids of patients in the training and validation separated arrays\n",
      "id_train_living = np.vstack([np.zeros((patient.shape[0], 1)) + i for i, patient in enumerate(patient_train_living)\n",
      "                             ])\n",
      "id_train_dead = np.vstack([np.zeros((patient.shape[0], 1)) + i for i, patient in enumerate(patient_train_dead)\n",
      "                             ])\n",
      "id_valid_living = np.vstack([np.zeros((patient.shape[0], 1)) + i for i, patient in enumerate(patient_valid_living)\n",
      "                             ])\n",
      "id_valid_dead = np.vstack([np.zeros((patient.shape[0], 1)) + i for i, patient in enumerate(patient_valid_dead)\n",
      "                             ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 365
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Predict separtely for each of the sets\n",
      "pred_train_living = f.predict(data_train_living)\n",
      "pred_train_dead = f.predict(data_train_dead)\n",
      "pred_valid_dead = f.predict(data_valid_dead)\n",
      "pred_valid_living = f.predict(data_valid_living)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 423
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To easily access a specific patient\n",
      "def predp_train_living(i):\n",
      "    return pred_train_living[id_train_living[:, 0] == i]\n",
      "def predp_train_dead(i):\n",
      "    return pred_train_dead[id_train_dead[:, 0] == i]\n",
      "\n",
      "def predp_valid_living(i):\n",
      "    return pred_valid_living[id_valid_living[:, 0] == i]\n",
      "def predp_valid_dead(i):\n",
      "    return pred_valid_dead[id_valid_dead[:, 0] == i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 424
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_valid_living = np.array([np.array(predp_valid_living(i)) for i in xrange(len(patient_valid_living))])\n",
      "y_valid_dead = np.array([np.array(predp_valid_dead(i)) for i in xrange(len(patient_valid_dead))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 438
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train_living = np.array([np.array(predp_train_living(i)) for i in xrange(len(patient_train_living))])\n",
      "y_train_dead = np.array([np.array(predp_train_dead(i)) for i in xrange(len(patient_train_dead))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 439
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_valid_living = np.array([np.mean(predp_valid_living(i)) for i in xrange(len(patient_valid_living))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 433
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(y_valid_living < 0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 435,
       "text": [
        "0.9609022556390977"
       ]
      }
     ],
     "prompt_number": 435
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "for i in xrange(len(patient_valid_living)):\n",
      "    print np.mean(predp_valid_living(i))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n",
        "0.1875\n",
        "0.0229885057471\n",
        "0.433333333333\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0888888888889\n",
        "0.0\n",
        "0.138047138047\n",
        "0.144032921811\n",
        "0.14224137931\n",
        "0.0\n",
        "0.266666666667\n",
        "0.0\n",
        "0.0\n",
        "0.012323943662\n",
        "0.0487804878049\n",
        "0.312072892938\n",
        "0.0\n",
        "0.162303664921\n",
        "0.0\n",
        "0.0\n",
        "0.0760869565217\n",
        "0.0\n",
        "0.0\n",
        "0.148936170213\n",
        "0.0\n",
        "0.0197238658777\n",
        "0.0\n",
        "0.178489702517\n",
        "0.0\n",
        "0.0995260663507\n",
        "0.0120481927711\n",
        "0.0\n",
        "0.0\n",
        "0.00793650793651\n",
        "0.0\n",
        "0.0\n",
        "0.280961182994\n",
        "0.030534351145\n",
        "0.0\n",
        "0.0\n",
        "0.112676056338\n",
        "0.121428571429\n",
        "0.10071942446\n",
        "0.0\n",
        "0.0\n",
        "0.432098765432\n",
        "0.0\n",
        "0.0909090909091\n",
        "0.0\n",
        "0.0932203389831\n",
        "0.0\n",
        "0.070796460177\n",
        "0.0\n",
        "0.441176470588\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.00520833333333\n",
        "0.0\n",
        "0.0149253731343\n",
        "0.0\n",
        "0.131661442006\n",
        "0.166666666667\n",
        "0.244956772334\n",
        "0.0280373831776\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.187145557656\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.19298245614\n",
        "0.282402528978\n",
        "0.264462809917\n",
        "0.0247933884298\n",
        "0.048275862069\n",
        "0.0\n",
        "0.0\n",
        "0.328125\n",
        "0.0965732087227\n",
        "0.149377593361\n",
        "0.0267857142857\n",
        "0.0449438202247\n",
        "0.0\n",
        "0.0\n",
        "0.0194174757282\n",
        "0.192307692308\n",
        "0.0142857142857\n",
        "0.0\n",
        "0.0\n",
        "0.0579710144928\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.217948717949\n",
        "0.471074380165\n",
        "0.0\n",
        "0.0724637681159\n",
        "0.0\n",
        "0.227848101266\n",
        "0.012987012987\n",
        "0.244897959184\n",
        "0.0\n",
        "0.0\n",
        "0.0377358490566\n",
        "0.0\n",
        "0.0\n",
        "0.226666666667\n",
        "0.0\n",
        "0.170212765957\n",
        "0.0\n",
        "0.0\n",
        "0.03\n",
        "0.0\n",
        "0.0\n",
        "0.188449848024\n",
        "0.0\n",
        "0.271428571429\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.155172413793\n",
        "0.148648648649\n",
        "0.25\n",
        "0.0\n",
        "0.0\n",
        "0.125\n",
        "0.0526315789474\n",
        "0.0\n",
        "0.00701754385965\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.016393442623\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.190476190476\n",
        "0.194092827004\n",
        "0.0856031128405\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.388838060384\n",
        "0.0\n",
        "0.0195652173913\n",
        "0.0155642023346\n",
        "0.285714285714\n",
        "0.333333333333\n",
        "0.246575342466\n",
        "0.107692307692\n",
        "0.218181818182\n",
        "0.0\n",
        "0.0\n",
        "0.0326086956522\n",
        "0.0\n",
        "0.072864321608\n",
        "0.0\n",
        "0.0191570881226\n",
        "0.129909365559\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0736842105263\n",
        "0.0751252086811\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.00461538461538\n",
        "0.00149700598802\n",
        "0.00247524752475\n",
        "0.0\n",
        "0.196335078534\n",
        "0.0567164179104\n",
        "0.0\n",
        "0.0\n",
        "0.166666666667\n",
        "0.178947368421\n",
        "0.390438247012\n",
        "0.00847457627119\n",
        "0.0\n",
        "0.207207207207\n",
        "0.0980392156863\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.16393442623\n",
        "0.0352760736196\n",
        "0.0\n",
        "0.0333333333333\n",
        "0.0\n",
        "0.036036036036\n",
        "0.0637362637363\n",
        "0.0\n",
        "0.0970873786408\n",
        "0.0\n",
        "0.0361445783133\n",
        "0.05\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.121951219512\n",
        "0.0\n",
        "0.0\n",
        "0.197674418605\n",
        "0.0155440414508\n",
        "0.0\n",
        "0.0120192307692\n",
        "0.0309734513274\n",
        "0.0823529411765\n",
        "0.0\n",
        "0.0181818181818\n",
        "0.0703125\n",
        "0.0\n",
        "0.162629757785\n",
        "0.0\n",
        "0.0\n",
        "0.0121951219512\n",
        "0.00970873786408\n",
        "0.0583333333333\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.116438356164\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0645161290323\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.122302158273\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0505836575875\n",
        "0.0173913043478\n",
        "0.109022556391\n",
        "0.133333333333\n",
        "0.0\n",
        "0.115384615385\n",
        "0.0\n",
        "0.0334728033473\n",
        "0.277777777778\n",
        "0.00819672131148\n",
        "0.0484848484848\n",
        "0.00595238095238\n",
        "0.12\n",
        "0.0\n",
        "0.222921914358\n",
        "0.0\n",
        "0.0\n",
        "0.0188679245283\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0208333333333\n",
        "0.0890410958904\n",
        "0.0196078431373\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.105734767025\n",
        "0.265402843602\n",
        "0.0\n",
        "0.416666666667\n",
        "0.0740740740741\n",
        "0.0\n",
        "0.0902255639098\n",
        "0.0\n",
        "0.0\n",
        "0.103448275862\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.359154929577\n",
        "0.0\n",
        "0.0\n",
        "0.06\n",
        "0.0552995391705\n",
        "0.0\n",
        "0.379562043796\n",
        "0.165876777251\n",
        "0.256013745704\n",
        "0.0521172638436\n",
        "0.0\n",
        "0.182186234818\n",
        "0.262295081967\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0294117647059\n",
        "0.0\n",
        "0.364341085271\n",
        "0.133333333333\n",
        "0.0\n",
        "0.149028077754\n",
        "0.0\n",
        "0.172413793103\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0125\n",
        "0.211267605634\n",
        "0.0496688741722\n",
        "0.0149253731343\n",
        "0.0173010380623\n",
        "0.0\n",
        "0.300429184549\n",
        "0.0\n",
        "0.0\n",
        "0.212543554007\n",
        "0.0375\n",
        "0.0\n",
        "0.0839694656489\n",
        "0.0\n",
        "0.00136612021858\n",
        "0.00970873786408\n",
        "0.352813852814\n",
        "0.073732718894\n",
        "0.04\n",
        "0.0188679245283\n",
        "0.0\n",
        "0.117647058824\n",
        "0.0\n",
        "0.2\n",
        "0.0736196319018\n",
        "0.0\n",
        "0.0210970464135\n",
        "0.0434782608696\n",
        "0.0\n",
        "0.223880597015\n",
        "0.00363636363636\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.225\n",
        "0.0\n",
        "0.0\n",
        "0.10752688172\n",
        "0.0\n",
        "0.0\n",
        "0.0377358490566\n",
        "0.0555555555556\n",
        "0.015625\n",
        "0.0384615384615\n",
        "0.16835016835\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.181818181818\n",
        "0.0\n",
        "0.0\n",
        "0.089715536105\n",
        "0.025\n",
        "0.0\n",
        "0.00540540540541\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.11320754717\n",
        "0.0\n",
        "0.0\n",
        "0.0617283950617\n",
        "0.397402597403\n",
        "0.005\n",
        "0.0229885057471\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0696864111498\n",
        "0.0\n",
        "0.00411522633745\n",
        "0.265306122449\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.303825956489\n",
        "0.0384615384615\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0319634703196\n",
        "0.0344827586207\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.5\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.00434782608696\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0277777777778\n",
        "0.192592592593\n",
        "0.0\n",
        "0.0778947368421\n",
        "0.0204081632653\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.00772200772201\n",
        "0.0\n",
        "0.127272727273\n",
        "0.392572944297\n",
        "0.043795620438\n",
        "0.0\n",
        "0.0\n",
        "0.00819672131148\n",
        "0.0406504065041\n",
        "0.0125\n",
        "0.0\n",
        "0.142857142857\n",
        "0.0\n",
        "0.093023255814\n",
        "0.0\n",
        "0.0\n",
        "0.110655737705\n",
        "0.00220750551876\n",
        "0.0\n",
        "0.0137457044674\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.145695364238\n",
        "0.0111111111111\n",
        "0.0\n",
        "0.0606060606061\n",
        "0.0172413793103\n",
        "0.00540540540541\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.136801541426\n",
        "0.0\n",
        "0.0\n",
        "0.16814159292\n",
        "0.0520487264673\n",
        "0.0\n",
        "0.0551181102362\n",
        "0.135135135135\n",
        "0.183098591549\n",
        "0.205128205128\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0845070422535\n",
        "0.018691588785\n",
        "0.0227272727273\n",
        "0.0901639344262\n",
        "0.0\n",
        "0.0176470588235\n",
        "0.0108695652174\n",
        "0.0\n",
        "0.185897435897\n",
        "0.0\n",
        "0.22972972973\n",
        "0.217391304348\n",
        "0.0570469798658\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.197580645161\n",
        "0.224880382775\n",
        "0.0666666666667\n",
        "0.0178571428571\n",
        "0.0952380952381\n",
        "0.0491803278689\n",
        "0.138888888889\n",
        "0.386666666667\n",
        "0.0\n",
        "0.120728929385\n",
        "0.0223880597015\n",
        "0.0\n",
        "0.0\n",
        "0.0432432432432\n",
        "0.0170454545455\n",
        "0.122270742358\n",
        "0.0\n",
        "0.336956521739\n",
        "0.0062893081761\n",
        "0.0\n",
        "0.0\n",
        "0.131578947368\n",
        "0.393939393939\n",
        "0.0\n",
        "0.0224215246637\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.046875\n",
        "0.0\n",
        "0.158536585366\n",
        "0.0\n",
        "0.0\n",
        "0.025069637883\n",
        "0.191044776119\n",
        "0.025641025641\n",
        "0.158878504673\n",
        "0.0\n",
        "0.025\n",
        "0.025974025974\n",
        "0.0384615384615\n",
        "0.013698630137\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.182978723404\n",
        "0.0\n",
        "0.0919540229885\n",
        "0.0609318996416\n",
        "0.122935779817\n",
        "0.0\n",
        "0.0666666666667\n",
        "0.00369003690037\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.204819277108\n",
        "0.0327868852459\n",
        "0.15\n",
        "0.0240384615385\n",
        "0.047619047619\n",
        "0.0\n",
        "0.016393442623\n",
        "0.00540540540541\n",
        "0.0\n",
        "0.0\n",
        "0.0818181818182\n",
        "0.0\n",
        "0.245901639344\n",
        "0.046511627907\n",
        "0.269911504425\n",
        "0.0\n",
        "0.0217391304348\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.118644067797\n",
        "0.0\n",
        "0.0\n",
        "0.731707317073\n",
        "0.310160427807\n",
        "0.120689655172\n",
        "0.0\n",
        "0.0268096514745\n",
        "0.00881057268722\n",
        "0.0\n",
        "0.0\n",
        "0.270358306189\n",
        "0.0\n",
        "0.152173913043\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.089527027027\n",
        "0.0\n",
        "0.156862745098\n",
        "0.0\n",
        "0.0277777777778\n",
        "0.0324675324675\n",
        "0.252032520325\n",
        "0.0140845070423\n",
        "0.0736842105263\n",
        "0.648648648649\n",
        "0.0\n",
        "0.0\n",
        "0.283636363636\n",
        "0.0\n",
        "0.0\n",
        "0.0\n",
        "0.0177304964539\n",
        "0.288025889968\n",
        "0.00719424460432\n",
        "0.0\n",
        "0.0325581395349\n",
        "0.0243902439024\n",
        "0.0078431372549\n",
        "0.0\n",
        "0.0710227272727\n",
        "0.0\n",
        "0.0\n",
        "0.193103448276\n",
        "0.230182926829\n",
        "0.0\n",
        "0.0\n",
        "0.0425531914894\n",
        "0.0\n",
        "0.281176470588\n",
        "0.0128755364807\n",
        "0.388190954774\n",
        "0.0994623655914\n",
        "0.0368098159509\n",
        "0.0\n",
        "0.0\n",
        "0.0234899328859\n",
        "0.0\n",
        "0.0\n",
        "0.0384615384615\n",
        "0.0\n",
        "0.0555555555556\n",
        "0.0\n",
        "0.0\n",
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 413
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pred_train_living = np.array([np.mean(f.predict(patient)) for patient in patient_train_living])\n",
      "pred_train_dead = np.array([np.mean(f.predict(patient)) for patient in patient_train_dead])\n",
      "pred_valid_living = np.array([np.mean(f.predict(patient)) for patient in patient_valid_living])\n",
      "pred_valid_dead = np.array([np.mean(f.predict(patient)) for patient in patient_valid_dead])"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Find the errors using some threshold\n",
      "- Decide the threshold using training data?\n",
      "    - RF will OVERFIT the training data, classify everything properly, no errors, mean = 0 (or 1 for dead)\n",
      "-\n",
      "- REgressor?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "t0 = 0.4\n",
      "### Thresholded the mean on the training set\n",
      "tn = pred_train_living[pred_train_living < t0].shape[0] * 100.0 / pred_train_living.shape[0]\n",
      "tp = pred_train_dead[pred_train_dead >= t0].shape[0] * 100.0 / pred_train_dead.shape[0]\n",
      "\n",
      "fn = pred_train_dead[pred_train_dead < t0].shape[0] * 100.0 / pred_train_dead.shape[0]\n",
      "fp = pred_train_living[pred_train_living >= t0].shape[0] * 100.0 / pred_train_living.shape[0]\n",
      "\n",
      "print tn, '\\t', fp\n",
      "print fn, tp\n",
      "### Test the thresholded mean results on validation set\n",
      "tn = pred_valid_living[pred_valid_living < t0].shape[0] * 100.0 / pred_valid_living.shape[0]\n",
      "tp = pred_valid_dead[pred_valid_dead >= t0].shape[0] * 100.0 / pred_valid_dead.shape[0]\n",
      "\n",
      "fn = pred_valid_dead[pred_valid_dead < t0].shape[0] * 100.0 / pred_valid_dead.shape[0]\n",
      "fp = pred_valid_living[pred_valid_living >= t0].shape[0] * 100.0 / pred_valid_living.shape[0]\n",
      "\n",
      "print tn, '\\t', fp\n",
      "print fn, tp\n",
      "## Method:\n",
      "- Using mean of predicted values of time stamps.\n",
      "\n",
      "## Results!\n",
      "- On training data\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## RF reports :P\n",
      "- Works well (a little too well) in classifying the outputs\n",
      "\n",
      "## TODO\n",
      "- use the rf to classify the windows of the other time series\n",
      "- Try using mean again\n",
      "\n",
      "### SKEW SKEW SKEW!!\n",
      "- \n",
      "- Use the classification of the RF on the windows as some feature for an hmm, or other classifier?\n",
      "    - The idea is that we want the model to get surer that it has seen some consistent 1 windows before it starts throwing out 1s.\n",
      "- Age, ICU!\n",
      "\n",
      "###  Done\n",
      "- impute missing values with -1 for RF\n",
      "- get patient wise data, split into 2 sets\n",
      "- generate matrices using 1, and train RF"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Save csv\n",
      "np.savetxt('windows/window_stats_living.csv', window_stats_living, delimiter=',')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Populate the df!\n",
      "\n",
      "n_windows_dead = np.array(ts_lens_dead) - window_size + 1\n",
      "n_windows_dead = sum(n_windows_dead[n_windows_dead > 0])\n",
      "n_windows_living = np.array(ts_lens_living) - window_size + 1\n",
      "n_windows_living = sum(n_windows_living[n_windows_living > 0])\n",
      "#### Create dataframes for the stats\n",
      "df_window_stats_living = pd.DataFrame(index=np.arange(0, n_windows_living), columns=cols)\n",
      "df_window_stats_dead = pd.DataFrame(index=np.arange(0, n_windows_dead), columns=cols)\n",
      "#### Populate the dataframe\n",
      "k = 0\n",
      "for x in window_stats_patient_dead:\n",
      "    if x is None:\n",
      "        continue\n",
      "    df_window_stats_dead.loc[k : k+x.shape[0]-1] = x\n",
      "    k = k+x.shape[0]\n",
      "df_window_stats_dead"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}