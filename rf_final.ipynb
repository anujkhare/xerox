{
 "metadata": {
  "name": "",
  "signature": "sha256:d103ba221c72e8c54a96fa95eb487bed2acd8cb1e7823bb6c079431a40b9a263"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "%reset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "col_labs =[\n",
      "\"Systolic Blood Pressure in mmHg\",\n",
      "\"Diastolic Blood Pressure in mmHg\", \n",
      "\"Heart Rate in bpm\", \n",
      "\"Respiration Rate in bpm\",\n",
      "\"Oxygen Saturation in %\",\n",
      "\"Temperature in Celsius\",\n",
      "\"Arterial blood PH in ph\",\n",
      "\"Partial Pressure of Carbon dioxide (PaCO2) in mmHg\",\n",
      "\"Partial Pressure of Oxygen (PaO2) in mmHg\",\n",
      "\"Sodium in mmol/L\",\n",
      "\"Potassium in mmol/L\",\n",
      "\"Bicarbonate in mmol/L\",\n",
      "\"Blood Urea Nitrogen in mg/dL\",\n",
      "\"Serum Creatinine in mg/dL\",\n",
      "\"WBC Count in x 103/\u00b5L\",\n",
      "\"Hematocrit %\",\n",
      "\"Platelet Count in x 103/\u00b5L\",\n",
      "\"Bilirubin in mg/dL\",\n",
      "\"Urine Output in ml\",\n",
      "\"LDL Cholesterol in mg/dL\",\n",
      "\"Lactic Acid in mmol/L\",\n",
      "\"Troponin I in ng/ml\",\n",
      "\"Troponin T in ng/ml\",\n",
      "\"Random Blood Glucose in mg/dL\",\n",
      "\"Fasting Blood Glucose in mg/dL\",\n",
      "\"Fraction of Inspired Oxygen (FiO2) in %\",\n",
      "\"Albumin in g/dl\",\n",
      "\"Alkaline Phosphatase in IU/L\",\n",
      "\"Alanine in IU/L\",\n",
      "\"HDL Cholesterol in mg/dL\",\n",
      "\"Magnesium in mg/dL\"]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pysal\n",
      "from pysal import *\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import svm\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from math import *\n",
      "from scipy.stats import *\n",
      "import re\n",
      "import pandas\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import Series, DataFrame\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.stats import norm\n",
      "from sklearn.linear_model import *\n",
      "from scipy.stats import norm\n",
      "import os\n",
      "import scipy\n",
      "from sklearn.externals import joblib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_df_combined(df_vitals, df_labs):\n",
      "    df_combined = df_vitals.drop('ICU', axis=1).copy()\n",
      "    df_combined = df_combined.join(df_labs.drop(['ID', 'TIME'], axis=1))\n",
      "    df_combined.drop(['ID', 'TIME'], axis=1, inplace=True)\n",
      "    ### Process the entire data using this process\n",
      "    return df_combined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def norm_transform(x, x_range, W):\n",
      "    if(x<x_range[0]):\n",
      "        x=x_range[0]\n",
      "    if(x>x_range[1]):\n",
      "        x=x_range[1]\n",
      "    return np.dot(W, [1, x, log(1+x)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_x_w(df_combined, n_features=31):\n",
      "    x_range = np.zeros((n_features, 2))\n",
      "    W = np.zeros((n_features, 3))\n",
      "    for i in xrange(n_features):\n",
      "    #for i in xrange(1):\n",
      "        vals = df_combined.ix[df_combined.ix[:, i].notnull(), i]\n",
      "        vals = np.sort(vals)\n",
      "\n",
      "        # find the quantiles\n",
      "        N = vals.shape[0]\n",
      "        q = np.array([(j-0.5)/N for j in xrange(N)])\n",
      "\n",
      "        i_l = np.min(np.arange(q.shape[0])[q>0.01])\n",
      "        i_u = np.max(np.arange(q.shape[0])[q<0.99])\n",
      "\n",
      "        x_range[i, 0] = vals[i_l]\n",
      "        x_range[i, 1] = vals[i_u]\n",
      "\n",
      "        vals = vals[i_l: i_u+1]\n",
      "        q=norm.ppf(q[i_l: i_u+1]) / 3\n",
      "\n",
      "        X = np.ones((vals.shape[0], 3))\n",
      "        X[:, 1] = vals\n",
      "        X[:, 2] = np.log(1 + vals)\n",
      "\n",
      "        W[i, :] = np.dot(np.linalg.pinv(np.dot(X.T, X)),\n",
      "                         np.dot(X.T, q)\n",
      "                         )\n",
      "    \n",
      "    return [x_range, W]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_norm_df(df_vitals, df_labs, x_range, W, path=None):\n",
      "    df_combined = get_df_combined(df_vitals, df_labs)\n",
      "    ### Normalize following the procedure in the paper\n",
      "    #### Find the xL, xU, w1, w2, w3 vars\n",
      "    # transform one element given range and W\n",
      "    df_norm = df_combined\n",
      "    for i in xrange(n_features):\n",
      "        df_norm.ix[:, i] = df_norm.ix[:, i].apply(lambda x:norm_transform(x, x_range[i], W[i]))\n",
      "    df_norm[df_norm.isnull()] = 0\n",
      "    \n",
      "    df_norm['TIME'] = df_vitals.TIME\n",
      "\n",
      "    if path is not None:\n",
      "        df_norm.to_csv(path=path)\n",
      "    return df_norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 196
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_norm_patients_from_df(df_vitals, df_labs, df_age, x_range, W, path=None):\n",
      "    df = get_norm_df(df_vitals, df_labs, x_range, W, path)\n",
      "    \n",
      "    patient_combined = [np.array(df.ix[df_vitals['ID'] == ID, :]) for ID in df_vitals['ID'].unique()]\n",
      "\n",
      "\n",
      "    age_combined = np.array(df_age.AGE)\n",
      "    icu_combined = np.array([np.array(df_vitals.ICU[df_vitals['ID']==i]) for i in df_vitals['ID'].unique()])\n",
      "    return [patient_combined, age_combined, icu_combined]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_patients_living_dead(patient_combined):\n",
      "    # split into living and dead\n",
      "    patient_combined_dead = [patient_combined[ID-1] for ID in df_age['ID']\n",
      "                                                          if df_labels.ix[ID - 1, 'LABEL'] == 1]\n",
      "    patient_combined_living = [patient_combined[ID-1] for ID in df_labels['ID']\n",
      "                                                          if df_labels.ix[ID - 1, 'LABEL'] == 0]\n",
      "    return [patient_combined_living, patient_combined_dead]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "np.set_printoptions(precision=5, suppress=True)\n",
      "df_vitals = pd.read_csv('data_train/id_time_vitals_train.csv')\n",
      "df_labs = pd.read_csv('data_train/id_time_labs_train.csv')\n",
      "df_age = pd.read_csv('data_train/id_age_train.csv')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Normalize differently\n",
      "for col in df_combined.columns:\n",
      "    for i in xrange(df_combined.count()[0]):\n",
      "        if np.isnan(df_combined.ix[i, col]):\n",
      "            if i==0:\n",
      "                df_combined.ix[i,col] = 0\n",
      "            else:\n",
      "                df_combined.ix[i, col] = df_combined.ix[i-1, col]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Read the valus directly from the files\n",
      "### df_norm = get_norm_df()\n",
      "df_norm = pd.read_csv('/root/code/xerox/windows/svm_norm_data.csv')\n",
      "df_norm.drop(['Unnamed: 0'], axis=1, inplace=True)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "df_combined = get_df_combined(df_vitals, df_labs)\n",
      "x_range, W = get_x_w(df_combined)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "print x_range[0], W[0], norm_transform(100, x_range[0], W[0])"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[patient_combined, age_combined, icu_combined] = get_norm_patients_from_df(df_vitals, df_labs,\n",
      "                                                         df_age, x_range, W, path=None)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Save the np arrays for speed and load from here\n",
      "np.save('/root/code/xerox/patient_combined_train', patient_combined)\n",
      "np.save('/root/code/xerox/age_combined_train', age_combined)\n",
      "np.save('/root/code/xerox/icu_combined_train', icu_combined)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Normalize the ages\n",
      "x_range_age, W_age = get_x_w(df_age, 2)\n",
      "x_range_age = x_range_age[1]; W_age = W_age[1, :];\n",
      "age_combined = np.array([norm_transform(x, x_range_age, W_age) for x in age_combined]).reshape((age_combined.shape[0], 1))"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "del df_age, df_labels, df_vitals, df_labs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "del df_norm, df_combined"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "np.save('/root/code/xerox/age_combined_train.npy', age_combined)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "data_combined = np.array(patient_combined)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Code for windows!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_n_windows(ts, n_windows, stats, time_=None, last_window_size=None):\n",
      "    if time_ is not None:\n",
      "        cols = [i for i in np.arange(ts.shape[1]) if i != time_]\n",
      "        n_features = ts.shape[1] - 1\n",
      "    else:\n",
      "        cols = np.arange(ts.shape[1])\n",
      "        n_features = ts.shape[1]\n",
      "    \n",
      "    #print n_features\n",
      "    l = np.zeros((n_windows, len(stats) * n_features))\n",
      "    if last_window_size is None:\n",
      "        n = int(ts.shape[0] / n_windows)\n",
      "        last_window_size = 0\n",
      "    else:\n",
      "        n = int((ts.shape[0] - last_window_size) / (n_windows-1))\n",
      "    \n",
      "    # get windows\n",
      "    for j in xrange(0, n_windows):\n",
      "        if (j==n_windows-1):\n",
      "            window = ts[j*n :, :] \n",
      "        else:\n",
      "            window = ts[j*n : (j+1)*n, :] \n",
      "        #print window\n",
      "\n",
      "        # apply stats to the window and append into a row\n",
      "        for k in xrange(len(stats)):\n",
      "            f = stats[k]\n",
      "            if f.func_name == '<lambda>':\n",
      "                if time_ is None:\n",
      "                    l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], None)\n",
      "                else:\n",
      "                    l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], window[:, time_])\n",
      "            else:\n",
      "                l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], axis=0)\n",
      "    return l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Given list of patient time series, give a matrix with one row for each patient containing all windows\n",
      "def get_rows_data(data, n_windows, stats, time=None, last_window_size=None, icu_ind=None, verbose=False):\n",
      "    n_features = data[0].shape[1]\n",
      "    if time is not None:\n",
      "        n_features = n_features - 1\n",
      "    data_windows = np.zeros((len(data), n_windows*n_features*len(stats)))\n",
      "    for i in xrange(len(data)):\n",
      "        ts = data[i]\n",
      "        if icu_ind is not None:\n",
      "            ind = np.array(icu_ind[i], dtype=bool)\n",
      "            #print ts, icu_ind[i]\n",
      "            ts = ts[ind, :]\n",
      "            if verbose:\n",
      "                print ts.shape\n",
      "\n",
      "        if(ts.shape[0] < n_windows):\n",
      "            #window_stats.append(None)    # We want to keep 1-1 mapping with patients..\n",
      "            n = int(np.ceil(1.0 * n_windows / ts.shape[0]))\n",
      "            t = np.zeros((ts.shape[0] * n, ts.shape[1]))\n",
      "            for j in xrange(ts.shape[0]):\n",
      "                for k in xrange(n):\n",
      "                    t[n*j + k, :] = ts[j, :]\n",
      "            \n",
      "            ts = t\n",
      "\n",
      "        l = get_n_windows(ts, n_windows, stats, time, last_window_size=last_window_size)\n",
      "        data_windows[i, :] = np.hstack(l)\n",
      "        \n",
      "    return data_windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 200
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## For ONLINE prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get windows starting with zero upto end for the time series 'ts', ONLY for which icu=1 (If provided)\n",
      "def get_online_windows(ts, icu=None, window_size=None):\n",
      "    if icu is not None:\n",
      "        icu_ind = np.array(icu, dtype=bool)\n",
      "        ts = ts[icu_ind]\n",
      "        \n",
      "    if window_size is None:\n",
      "        #if icu is None:\n",
      "        #    p_windows = np.array([ts[:i+1, :] for i in xrange(ts.shape[0])])\n",
      "        #else:   # inclue only if icu[i] == 1\n",
      "                #p_windows = np.array([ts[:i+1, :] for i in xrange(ts.shape[0]) if icu[i]==1])\n",
      "        p_windows = np.array([ts[:i+1, :] for i in xrange(ts.shape[0])])\n",
      "    else:   # Taking sliding window of fixed size if window size is se\n",
      "        #if icu is None:\n",
      "        #    p_windows = np.array([ts[max(i-window_size+1, 0):i+1, :] for i in xrange(ts.shape[0])])\n",
      "        #else:   # inclue only if icu[i] == 1\n",
      "        #    p_windows = np.array([ts[max(i-window_size+1, 0):i+1, :] for i in xrange(ts.shape[0]) if icu[i]==1])\n",
      "        p_windows = np.array([ts[max(i-window_size+1, 0):i+1, :] for i in xrange(ts.shape[0])])\n",
      "    return p_windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get stats of a given ts for all possible windows starting with 1 element\n",
      "def get_all_window_stats(ts, n_windows, stats, time=None, icu=None, window_size=None, icu_bias=False, last_window_size=None):\n",
      "    p_windows = get_online_windows(ts, icu, window_size=window_size)\n",
      "    p_all_window_stats = get_rows_data(p_windows, n_windows, stats, time, last_window_size=last_window_size)\n",
      "    return p_all_window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Given a LIST of patient time series, give back a list of matrices, one for each time series, where each row is a SLIDING window 0..i\n",
      "def get_list_all_window_stats(data, n_windows, stats, time=None, list_of_icu=None, window_size=None,\n",
      "                              labels_for_icu_bias=None, last_window_size=None):\n",
      "        \n",
      "    all_window_stats = []\n",
      "    for i, d in enumerate(data):\n",
      "        if (list_of_icu is None) or (labels_for_icu_bias is not None and labels_for_icu_bias[i]==0):\n",
      "            all_window_stats.append(get_all_window_stats(d, n_windows, stats, time, window_size=window_size,\n",
      "                                                         last_window_size=last_window_size))\n",
      "        else:\n",
      "            all_window_stats.append(get_all_window_stats(d, n_windows, stats, time, list_of_icu[i],\n",
      "                                                         window_size=window_size, last_window_size=last_window_size))\n",
      "    \n",
      "    return all_window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Confusion!\n",
      "def get_ss(confusion):\n",
      "    tn = confusion[0, 0]  # label=0, pred=0\n",
      "    fp = confusion[0, 1]  # label=0, pred=1\n",
      "    \n",
      "    fn = confusion[1, 0]  # label=1, pred=0\n",
      "    tp = confusion[1, 1]  # label=1, pred=1\n",
      "    \n",
      "    sens = (1.0*tp/(tp+fn))\n",
      "    spec = (1.0*tn/(tn+fp))\n",
      "    \n",
      "    #print confusion\n",
      "    #print\n",
      "    #prittp, fp, fn, tn, sens, spec\n",
      "    #print 'Sensitiviy: ', sens, '\\nSpecificity: ', spec\n",
      "    return sens, spec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 204
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Split Data!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_ind_split(N, split):\n",
      "    ind = np.arange(0, N)\n",
      "    np.random.shuffle(ind)\n",
      "    \n",
      "    N = len(ind)\n",
      "    N_train = int(split[0] * N)\n",
      "    N_valid = int((split[1]+split[0]) * N)\n",
      "    \n",
      "    ind_train = ind[:N_train]\n",
      "    ind_valid = ind[N_train:N_valid]\n",
      "    ind_test = ind[N_valid:]\n",
      "    \n",
      "    return [ind_train, ind_valid, ind_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_train_valid_test(data_combined, labels_combined, icu_combined, age_combined, split=[0.6, 0.2]):\n",
      "    \n",
      "    N = len(labels_combined)\n",
      "    ind_train, ind_valid, ind_test = get_ind_split(N, split)\n",
      "    \n",
      "    data_combined = np.array(data_combined)\n",
      "    labels_combined = np.array(labels_combined)\n",
      "    \n",
      "    data_train = data_combined[ind_train]\n",
      "    labels_train = labels_combined[ind_train]\n",
      "    age_train = age_combined[ind_train]\n",
      "    icu_train = icu_combined[ind_train]\n",
      "    \n",
      "    age_valid = age_combined[ind_valid]\n",
      "    icu_valid = icu_combined[ind_valid]\n",
      "    labels_valid = labels_combined[ind_valid]\n",
      "    data_valid = data_combined[ind_valid]\n",
      "\n",
      "    age_test = age_combined[ind_test]\n",
      "    icu_test = icu_combined[ind_test]\n",
      "    labels_test = labels_combined[ind_test]\n",
      "    data_test = data_combined[ind_test]\n",
      "    \n",
      "    return [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "            #ind_train, ind_valid, ind_test]\n",
      "            icu_train, icu_valid, icu_test,\n",
      "            age_train, age_valid, age_test, ind_train, ind_valid, ind_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 206
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Separate dead and alive in train and validation sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def separate_living_dead(data, labels):\n",
      "    data_living = data[labels == 0]\n",
      "    data_dead = data[labels == 1]\n",
      "    return [data_living, data_dead]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 207
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Find number of dead and alive patients in train and validation sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sizes(data_living, data_dead):\n",
      "    n_dead = data_dead.shape[0]\n",
      "    n_living = data_living.shape[0]\n",
      "    n_combined = n_dead + n_living\n",
      "    \n",
      "    return n_dead, n_living, n_combined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 208
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GET DATA!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data(patient_combined, labels_combined, age_combined, icu_combined, n_windows, stats, split, time=None):\n",
      "    ### Generate windowed data\n",
      "    data_windows_combined = get_rows_data(patient_combined, n_windows, stats, time)\n",
      "    #data_windows_combined = np.hstack((data_windows_combined, age_combined))\n",
      "\n",
      "    print data_windows_combined.shape\n",
      "    ### split into train and validation sets, living and dead\n",
      "    [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "     icu_train, icu_valid, icu_test,\n",
      "     age_train, age_valid, age_test, ind_train, ind_valid, ind_test] = split_train_valid_test(data_windows_combined,\n",
      "     #ind_train, ind_valid, ind_test] = split_train_valid_test(data_windows_combined,\n",
      "                                                                         labels_combined, icu_combined,\n",
      "                                                                         age_combined, split=split)\n",
      "    \n",
      "    print data_train.shape\n",
      "    [data_train_living, data_train_dead] = separate_living_dead(data_train, labels_train)\n",
      "    [data_valid_living, data_valid_dead] = separate_living_dead(data_valid, labels_valid)\n",
      "    [data_test_living, data_test_dead] = separate_living_dead(data_test, labels_test)\n",
      "    \n",
      "    [age_train_living, age_train_dead] = separate_living_dead(age_train, labels_train)\n",
      "    [age_valid_living, age_valid_dead] = separate_living_dead(age_valid, labels_valid)\n",
      "    [age_test_living, age_test_dead] = separate_living_dead(age_test, labels_test)\n",
      "    [icu_train_living, icu_train_dead] = separate_living_dead(icu_train, labels_train)\n",
      "    [icu_valid_living, icu_valid_dead] = separate_living_dead(icu_valid, labels_valid)\n",
      "    [icu_test_living, icu_test_dead] = separate_living_dead(icu_test, labels_test)\n",
      "    \n",
      "    labels_train = labels_train.reshape((labels_train.shape[0], 1))\n",
      "    labels_valid = labels_valid.reshape((labels_valid.shape[0], 1))\n",
      "    labels_test = labels_test.reshape((labels_test.shape[0], 1))\n",
      "    \n",
      "    print data_train.shape\n",
      "    n_train_dead, n_train_living, n_train_combined = get_sizes(data_train_living, data_train_dead)\n",
      "    n_valid_dead, n_valid_living, n_valid_combined = get_sizes(data_valid_living, data_valid_dead)\n",
      "    n_test_dead, n_test_living, n_test_combined = get_sizes(data_test_living, data_test_dead)\n",
      "    \n",
      "    print 'Train:', n_train_dead, n_train_living, labels_train.shape[0]\n",
      "    print 'Valid:', n_valid_dead, n_valid_living, labels_valid.shape[0]\n",
      "    print 'Test:', n_test_dead, n_test_living, labels_test.shape[0]\n",
      "\n",
      "    ### Split into balacned sets!\n",
      "    n_train_splits = int (n_train_living / n_train_dead)\n",
      "    train_split = int (n_train_living / n_train_splits)\n",
      "    print 'Train Splits', n_train_splits, train_split, n_train_dead + n_train_splits * train_split, n_train_combined\n",
      "    print data_train.shape\n",
      "    print data_train[1].shape\n",
      "    \n",
      "    return [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "            data_train_living, data_train_dead, data_valid_living, data_valid_dead, data_test_living, data_test_dead,\n",
      "            age_train_living, age_train_dead, age_valid_living, age_valid_dead, age_test_living, age_test_dead,\n",
      "            icu_train_living, icu_train_dead, icu_valid_living, icu_valid_dead, icu_test_living, icu_test_dead,\n",
      "            train_split, ind_train, ind_valid, ind_test, n_train_splits, train_split]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 209
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Classify!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train balanced models!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_balanced(models, data, labels, verbose=True):\n",
      "    data_living, data_dead = separate_living_dead(data, labels[:, 0])\n",
      "    n_train_splits = len(models)\n",
      "    train_split = int(data_living.shape[0] / n_train_splits)\n",
      "    if verbose:\n",
      "        print n_train_splits, train_split, data_living.shape[0]\n",
      "        \n",
      "    C_train = []\n",
      "    for i in xrange(n_train_splits):\n",
      "        # NO RANDOM SHUFFLE NOW!\n",
      "        data_bal = np.vstack((data_living[i * train_split: (i+1) * train_split, :],\n",
      "                              data_dead[:, :]) )\n",
      "        \n",
      "        label_bal = np.vstack((np.zeros((train_split, 1)),\n",
      "                               np.ones((data_dead.shape[0], 1))))\n",
      "\n",
      "        models[i].fit(data_bal, label_bal[:, 0])\n",
      "        C_train.append(confusion_matrix(label_bal[:,], models[i].predict(data_bal)))\n",
      "        \n",
      "    return C_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### GIVES THE SCORES OF EACH MODEL ON THE DATA\n",
      "def score_models(models, data_valid, labels_valid):\n",
      "    C_valid = []\n",
      "    for i in xrange(n_train_splits):\n",
      "        y = models[i].predict(data_valid)\n",
      "        C_valid.append(confusion_matrix(labels_valid[:], y))\n",
      "        #get_ss(C_valid[i])\n",
      "    return C_valid    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_proba(models_bal, data, sort=False):\n",
      "    probs = np.zeros((data.shape[0], len(models_bal)))\n",
      "        \n",
      "    probs = np.array([model.predict_proba(data)[:, 1] for model in models_bal]).T\n",
      "    if sort:\n",
      "        probs = np.sort(probs)\n",
      "    return probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find theta that maximises the sens at 99% spec on (data, labels)\n",
      "def train_theta_max_sens(models, data, labels, pr=None, N=100, verbose=False):\n",
      "    sens = []\n",
      "    spec = []\n",
      "    theta_arr = []\n",
      "    if pr!=None:\n",
      "        y_prob = get_pr_probs(data, pr, models)\n",
      "    else:\n",
      "        y_prob = get_model_sum_probs(data, models)\n",
      "        \n",
      "    for t in xrange(1, N):\n",
      "        theta = t*(1.0 / (N-1))\n",
      "        if pr!= None:\n",
      "            y = get_pr_prob_predictions(y_prob, theta)\n",
      "        else:\n",
      "            y = get_model_prob_predictions(y_prob, theta)\n",
      "        \n",
      "        se, sp = get_ss(confusion_matrix(labels, y))\n",
      "        sens.append(se); spec.append(sp); theta_arr.append(theta)\n",
      "\n",
      "    sens = np.array(sens); spec = np.array(spec); theta_arr = np.array(theta_arr);\n",
      "    \n",
      "    # Check if atleast one has >0.99 spec and non zero sens\n",
      "    if (sens[spec>0.99] > 0).any():   # take max spec for which sens>0\n",
      "        ind = spec>0.99\n",
      "        max_ind = np.argmax(sens[ind]) # take max sens for spec>0.99\n",
      "    elif (sens>0).any():\n",
      "        ind = sens>0\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "    else:\n",
      "        ind = np.arange(spec.shape[0])\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        \n",
      "    sens_ = sens[ind][max_ind]\n",
      "    spec_ = spec[ind][max_ind]\n",
      "    theta = theta_arr[ind][max_ind]\n",
      "    \n",
      "    if verbose==True:\n",
      "        print sens, spec\n",
      "        \n",
      "    #print max_ind, sens_, spec_\n",
      "    #print sens[max_ind], spec[max_ind]\n",
      "    return theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 213
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Feature selection!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Get col name, window, stats\n",
      "def get_col_stat_window(c):\n",
      "    i = c % (n_features)\n",
      "    f = col_labs[i]\n",
      "    w = int(c / (n_features * len(stats)))\n",
      "    s = stats[int((c % (n_features * len(stats))) / (n_features))].func_name\n",
      "    \n",
      "    return i, f, s, w"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_str(col):\n",
      "    return '-'.join([str(x) for x in get_col_stat_window(col)[1:-1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 215
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Following functions for finding mean prediction with threshold (rather than glm)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## NAME IS MISLEADING, IT GIVES MEAN PROB!\n",
      "def get_model_sum_probs(data, models):\n",
      "    prob_sum = np.zeros((data.shape[0], 2))\n",
      "    for m in models:\n",
      "        p = m.predict_proba(data)\n",
      "        prob_sum = prob_sum + p\n",
      "    \n",
      "    prob_sum = prob_sum / len(models)\n",
      "\n",
      "    return prob_sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_model_prob_predictions(prob_sum, theta):\n",
      "    y =  prob_sum[:, 1] - prob_sum[:, 0] > theta\n",
      "    return y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_model_mean_predictions(data, models, theta, verbose=False):\n",
      "    prob_sum = get_model_sum_probs(data, models)\n",
      "    if verbose:\n",
      "        print prob_sum\n",
      "    return get_model_prob_predictions(prob_sum, theta)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Version with prediction on the validation set\n",
      "##### Train classifier by finding the mean probabilities, and return sens and spec\n",
      "def train_and_score_cols(models, cols, data_train, labels_train,\n",
      "                         data_valid, labels_valid, verbose=False):\n",
      "    \n",
      "    data_train_living, data_train_dead = separate_living_dead(data_train, labels_train[:, 0])\n",
      "    \n",
      "    if cols==None:\n",
      "        cols = np.arange(data_train_living.shape[1])\n",
      "    #print cols\n",
      "    #print data_train_living.shape, data_train_dead.shape\n",
      "    print 'Training balanced..'\n",
      "    train_balanced(models, data_train[:, cols], labels_train);\n",
      "    \n",
      "    print 'Finding theta'\n",
      "    theta_max = train_theta_max_sens(models, data_valid[:, cols], labels_valid, verbose=verbose)\n",
      "    y = get_model_mean_predictions(data_valid[:, cols], models, theta_max, verbose=verbose)\n",
      "    \n",
      "    se, sp = get_ss(confusion_matrix(labels_valid, y))\n",
      "    #print se, sp\n",
      "    return se, sp, theta_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get the column sensitivity and specificity scores\n",
      "def get_col_se_sp(models, data_train, data_valid, labels_valid):\n",
      "    n = data_train_living.shape[1]\n",
      "    se = np.zeros((n,1))\n",
      "    sp = np.zeros((n,1))\n",
      "    \n",
      "    for i in xrange(n):\n",
      "        se[i], sp[i], t = train_and_score_cols(models, [i], data_train, labels_train, data_valid, labels_valid)\n",
      "    return se, sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## All feature+stats pairs, taken together to train the models\n",
      "def get_feature_stat_se_sp(models, data_train, labels_train, data_valid, labels_valid):\n",
      "    n = data_train_living.shape[1] / n_windows\n",
      "    se = np.zeros((n,1))\n",
      "    sp = np.zeros((n,1))\n",
      "    \n",
      "    for i in xrange(n):\n",
      "        cols = [i + j*n for j in xrange(n_windows)]\n",
      "        print cols\n",
      "        se[i], sp[i], t = train_and_score_cols(models, [i], data_train, labels_train, data_valid, labels_valid)\n",
      "    return se, sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Given cols in first window, train for all windows of that col\n",
      "def train_score_col_windows(models, cols, verbose=False):\n",
      "    n = data_train_living.shape[1] / n_windows\n",
      "    cols_all_windows = np.zeros((1, len(cols)*n_windows))\n",
      "    \n",
      "    for i in xrange(0, n_windows):\n",
      "        cols_all_windows[0, i*len(cols):(i+1)*len(cols)] = [j + i*n for j in cols]\n",
      "        \n",
      "    cols_ =  np.array(cols_all_windows[0, :], dtype=int).tolist()\n",
      "    print cols_\n",
      "    se, sp, t = train_and_score_cols(models, cols_, data_train_living, data_train_dead, data_valid, labels_valid,\n",
      "                                     verbose)\n",
      "    return se, sp, t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_df(se_f, sp_f):\n",
      "    out = np.hstack((np.arange(se_f.shape[0]).reshape((se_f.shape[0], 1)), se_f, sp_f, np.abs(sp_f - se_f)))\n",
      "    cols = [get_str(i) for i in np.array(out[:, 0], dtype=int)]\n",
      "\n",
      "    df_feat = pd.DataFrame(data=out, columns=['ind', 'sens', 'spec', 'diff'])\n",
      "    df_feat['name'] = cols\n",
      "    return df_feat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 223
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GO ONLINE!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_stacked_windows_ind(list_of_window_arrays):\n",
      "    data_all_windows_stacked = np.vstack(list_of_window_arrays)\n",
      "    ind_all_windows_stacked = np.vstack([np.ones((x.shape[0], 1)) * i for i, x in enumerate(list_of_window_arrays) ])\n",
      "    return data_all_windows_stacked, ind_all_windows_stacked[:, 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- get validation patients\n",
      "- get list of (all windows) of each patient\n",
      "- stack the windows up for whatever data you want to classify\n",
      "    - maintain an index to get back separate patients\n",
      "    - Classify windows\n",
      "- get back classifications for each patient separately\n",
      "- define \"some\" metric to classify the entire series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Takes list of patient time series, and creates windows starting at zero\n",
      "def get_stacked_windows_from_ts(list_of_patient_ts, n_windows, stats, time=None, list_of_icu=None, cols=None,\n",
      "                                window_size=None, labels_for_icu_bias=False, last_window_size=None):\n",
      "    list_of_window_arrays = get_list_all_window_stats(list_of_patient_ts, n_windows, stats, time, list_of_icu,\n",
      "                                                      window_size=window_size, labels_for_icu_bias=labels_for_icu_bias)\n",
      "    data_all_windows_stacked, ind_all_windows_stacked = get_stacked_windows_ind(list_of_window_arrays)\n",
      "    ind_all_windows_stacked = np.array(ind_all_windows_stacked, dtype=int)\n",
      "   \n",
      "    if cols is None:\n",
      "        return data_all_windows_stacked, ind_all_windows_stacked\n",
      "    else:\n",
      "        return data_all_windows_stacked[:, cols], ind_all_windows_stacked"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def get_list_of_prediction_arrays(data, ind_stacked):\n",
      "    inds = np.unique(ind_stacked)\n",
      "    list_y_preds = [data[ind_stacked==i, :].copy() for i in inds]\n",
      "    return np.array(list_y_preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def view_series_random(list_y, n=10):\n",
      "    ind = np.arange(list_y.shape[0])\n",
      "    np.random.shuffle(ind)\n",
      "    for i, l in enumerate(list_y[ind[:n]]):\n",
      "        print i, l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 227
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# TS!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_in_inds(p):\n",
      "    if (ind_train==p).any():\n",
      "        print \"train\"\n",
      "    if (ind_valid==p).any():\n",
      "        print \"valid\"\n",
      "    if (ind_test==p).any():\n",
      "        print \"test\"\n",
      "def get_confusion_inds(labels, y):\n",
      "    ind_fn = np.array([((not y[i]) & (labels[i] != y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_fp = np.array([(y[i] & (labels[i] != y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_tp = np.array([(labels[i] & (labels[i] == y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_tn = np.array([((not labels[i]) & (labels[i] == y[i])) for i in xrange(labels.shape[0])])\n",
      "    return [ind_fp, ind_fn, ind_tp, ind_tn]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 228
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## FOR THE COMPLEX MODEL!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_probs_all_windows(list_of_time_series, n_windows, stats, models, time, list_of_icu=None, cols=None,\n",
      "                          window_size=None, labels_for_icu_bias=None, last_window_size=None, mean=False):\n",
      "    # Get stacked windows of all patients, and an ind of which patitent has which rows\n",
      "    data_windows_stacked, ind_windows_stacked = get_stacked_windows_from_ts(list_of_time_series, n_windows,\n",
      "                                                                            stats, time, list_of_icu=list_of_icu,\n",
      "                                                                            cols=cols, last_window_size=last_window_size,\n",
      "                                                                            window_size=window_size,\n",
      "                                                                            labels_for_icu_bias=labels_for_icu_bias)\n",
      "    # Get probability estimates for all windows (of all patients) using the forests\n",
      "    dead_probs_stacked = get_proba(models, data_windows_stacked, sort=True)\n",
      "    \n",
      "    # Append MEAN of all column predictions as a feature\n",
      "    if mean:\n",
      "        dead_probs_stacked = np.hstack((dead_probs_stacked,\n",
      "                                    np.min(dead_probs_stacked, axis=1).reshape(dead_probs_stacked.shape[0], 1)))\n",
      "        dead_probs_stacked = np.hstack((dead_probs_stacked,\n",
      "                                    np.max(dead_probs_stacked, axis=1).reshape(dead_probs_stacked.shape[0], 1)))\n",
      "        dead_probs_stacked = np.hstack((dead_probs_stacked,\n",
      "                                    np.mean(dead_probs_stacked, axis=1).reshape(dead_probs_stacked.shape[0], 1)))\n",
      "    #dead_probs_stacked = np.mean(dead_probs_stacked, axis=1).reshape(dead_probs_stacked.shape[0], 1)\n",
      "    \n",
      "    # separate the probabilities paitient wise \n",
      "    list_probs = get_list_of_prediction_arrays(dead_probs_stacked, ind_windows_stacked)\n",
      "    return list_probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# takes in the probability matrix for the data, and threshold theta, returns final predictions, \n",
      "def get_unstacked_predictions_from_probs(y_prob_stacked, ind_stacked, theta):\n",
      "    y_pred_stacked = get_model_prob_predictions(y_prob_stacked, theta)\n",
      "    y_pred_stacked = y_pred_stacked.reshape((y_pred_stacked.shape[0], 1))\n",
      "    \n",
      "    list_y_preds = get_list_of_prediction_arrays(y_pred_stacked, ind_stacked)\n",
      "    y_any = np.array([(list_y_preds[i] == True).any() for i in xrange(list_y_preds.shape[0])])\n",
      "    return y_any, list_y_preds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# takes in the probability matrix for the data, and threshold theta, returns final predictions, \n",
      "def get_unstacked_predictions_from_probs_only_y(y_prob_stacked, ind_stacked, theta):\n",
      "    y_any, l = get_unstacked_predictions_from_probs(y_prob_stacked, ind_stacked, theta)\n",
      "    return y_any"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 231
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find theta that maximises the sens at 99% spec on (data, labels)\n",
      "def train_theta_max_sens_stacked(y_prob, labels, pred_func, ind_stacked=None, N=100, verbose=False, TH=0.99):\n",
      "    sens = []; spec = []; theta_arr = []\n",
      "\n",
      "    for t in xrange(1, N):\n",
      "        theta = t*(1.0 / (N-1))\n",
      "        if ind_stacked is None:\n",
      "            print 'sf'\n",
      "        else:\n",
      "            y = pred_func(y_prob, ind_stacked, theta)\n",
      "        se, sp = get_ss(confusion_matrix(labels, y))\n",
      "        sens.append(se); spec.append(sp); theta_arr.append(theta)\n",
      "\n",
      "    sens = np.array(sens); spec = np.array(spec); theta_arr = np.array(theta_arr);\n",
      "    \n",
      "    # Check if atleast one has >0.99 spec and non zero sens\n",
      "    print sens[spec>TH]\n",
      "    if (sens[spec>TH] > 0).any():   # take max spec for which sens>0\n",
      "        ind = spec>TH\n",
      "        max_ind = np.argmax(sens[ind]) # take max sens for spec>0.99\n",
      "        print '1'\n",
      "    elif (sens>0).any():\n",
      "        ind = sens>0\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        print '2'\n",
      "    else:\n",
      "        ind = np.arange(spec.shape[0])\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        print '3'\n",
      "        \n",
      "    sens_ = sens[ind][max_ind]\n",
      "    spec_ = spec[ind][max_ind]\n",
      "    theta = theta_arr[ind][max_ind]\n",
      "    \n",
      "    if verbose==True:\n",
      "        return theta, sens, spec\n",
      "        \n",
      "    #print max_ind, sens_, spec_\n",
      "    #print sens[max_ind], spec[max_ind]\n",
      "    return theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 232
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def slope(X):\n",
      "    sl = np.zeros((X.shape[1],))\n",
      "    y = np.arange(X.shape[0])     # SHOULD BE TIME HERE\n",
      "    for i, x in enumerate(X.T):\n",
      "        A = np.vstack([x, np.ones(len(x))]).T\n",
      "        m, c = np.linalg.lstsq(A, y)[0]\n",
      "        #print m,c\n",
      "        sl[i] = m\n",
      "    return sl"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def slope(x, time_):\n",
      "    n = x.shape[0]; nc = x.shape[1]\n",
      "    \n",
      "    #sl = np.zeros((1,))\n",
      "    if time_ is None:\n",
      "        y = np.arange(n).reshape((n, 1))   # SHOULD BE TIMESTAMPS\n",
      "    else:\n",
      "        y = time_.reshape((time_.shape[0], 1))\n",
      "    \n",
      "    xy = np.sum(x*y, axis=0)\n",
      "    xm = np.mean(x, axis=0)\n",
      "    ym = np.mean(y, axis=0)\n",
      "    x2 = np.sum(x*x, axis=0)\n",
      "    \n",
      "    sl = 1.0*(xy - n*xm*ym) / (x2 - n*xm*xm)\n",
      "    sl[np.isnan(sl)] = 0\n",
      "    sl[np.isinf(sl)] = 0\n",
      "    return sl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Time"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Just return teh timestamp\n",
      "def get_prediction_timestamp(y_preds, patient_ts, time_ind, icu_ts):\n",
      "    if not (y_preds==1).any():\n",
      "        return -1\n",
      "    \n",
      "    times = patient_ts[:, time_ind]\n",
      "    icu = np.array(icu_ts, dtype=bool)\n",
      "    y = np.array(y_preds[:,0], dtype=bool)\n",
      "    \n",
      "    return times[icu][y][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 234
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For one patient, if no 1s, return -1\n",
      "def get_prediction_time(y_preds, patient_ts, time_ind, icu_ts):\n",
      "    if not (y_preds==1).any():\n",
      "        return -1\n",
      "    \n",
      "    times = patient_ts[:, time_ind]\n",
      "    icu = np.array(icu_ts, dtype=bool)\n",
      "    y = np.array(y_preds[:,0], dtype=bool)\n",
      "    \n",
      "    return (times[times.shape[0]-1] - times[icu][y][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 235
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_prediction_times_all_patients(list_y_preds, list_of_patients, time_ind, list_of_icu_times):\n",
      "    pred_times = [get_prediction_time(list_y_preds[i], list_of_patients[i], time_ind, list_of_icu_times[i]) for i in \n",
      "                  xrange(list_y_preds.shape[0])]\n",
      "    return np.array(pred_times)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_stacked_windows_labels_from_ts(list_of_patients, labels, n_windows, stats, time=None, list_of_icu=None,\n",
      "                                       cols=None, window_size=None, labels_for_icu_bias=None, last_window_size=None):\n",
      "    windows_stacked, ind_windows_stacked = get_stacked_windows_from_ts(list_of_patients, n_windows,\n",
      "                                                                        stats, time=time, list_of_icu=list_of_icu,\n",
      "                                                                        #stats, time=time_ind, list_of_icu=None,\n",
      "                                                                        cols=cols, window_size=window_size,\n",
      "                                                                        labels_for_icu_bias=labels_for_icu_bias)\n",
      "    labels_stacked = np.vstack([np.ones((np.sum(ind_windows_stacked==i), 1))*labels[i] for i in\n",
      "                                      np.unique(ind_windows_stacked)])\n",
      "    return windows_stacked, ind_windows_stacked, labels_stacked"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get list of strings denoting the type of classification\n",
      "def get_str_type(ind_fp, ind_tp, ind_fn, ind_tn):\n",
      "    l = []\n",
      "    for i in xrange(ind_fp.shape[0]):\n",
      "        if ind_fp[i]:\n",
      "            l.append('fp')\n",
      "        if ind_tn[i]:\n",
      "            l.append('tn')\n",
      "        if ind_fn[i]:\n",
      "            l.append('fn')\n",
      "        if ind_tp[i]:\n",
      "            l.append('tp')\n",
      "            \n",
      "    return l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mkdirs(folder):\n",
      "    path = '/root/code/xerox/plots/' + folder  \n",
      "    os.mkdir(path);\n",
      "    os.mkdir(path + '/tp'); os.mkdir(path + '/fp');\n",
      "    os.mkdir(path + '/fn'); os.mkdir(path + '/tn');\n",
      "    return path\n",
      "def plot_all_probs(inds, path, icu_combined, list_y_prob, \n",
      "                   list_big_prob=None, figsize=(30,20), max_plots=30, types_test=None, theta_max=0.5):\n",
      "    ## Generate plots of mean probability and icu times of all patient time series..\n",
      "    f = plt.figure(figsize=figsize)\n",
      "    \n",
      "    if inds is None:\n",
      "        print \"give inds\"\n",
      "        return\n",
      "        #inds = np.array(np.ones(inds.shape[0],)), dtype=bool)\n",
      "    \n",
      "    k = 0\n",
      "    #for i, p in enumerate(patients_combined_val[inds]):\n",
      "    for i in np.arange(list_y_prob.shape[0])[inds]:\n",
      "        k = k+1\n",
      "        if k>max_plots:\n",
      "            break\n",
      "        plt.clf()\n",
      "        bs = np.array(icu_combined[i], dtype=bool)\n",
      "        x = np.arange(icu_combined[i].shape[0])[bs]\n",
      "        for j in xrange(n_train_splits):\n",
      "            plt.plot(x, list_y_prob[i][:, j])       # all prob plots of the forests\n",
      "\n",
      "        if list_big_prob is not None:\n",
      "            plt.ylim((-1, 2))\n",
      "            plt.plot(x, list_big_prob[i][:, 1], 'rx-')    # Prob of dying\n",
      "            plt.plot(x, 2*list_big_prob[i][:, 1]-1, 'g')  # difference b/w dying and living\n",
      "        else:\n",
      "            plt.ylim((0, 1))\n",
      "            \n",
      "        plt.hlines([theta_max], 0, icu_combined[i].shape[0])   # Theta-max line\n",
      "        plt.plot(3*icu_combined[i]-1,  'ro', markersize=30)    # icu markers\n",
      "\n",
      "        tit = str(i) + '_' \n",
      "        if types_test is not None:\n",
      "            tit = tit + types_test[i] \n",
      "        tit = tit + '_' + '_'.join([x.func_name for x in stats_big])\n",
      "        plt.title(tit)\n",
      "    #         plot(prob_mod[:, 1])\n",
      "        if types_test is not None:\n",
      "            f.savefig(path + '/' + types_test[i] + '/valid_'+tit +'.png')\n",
      "        else:\n",
      "            f.savefig(path + '/'  + '/valid_'+tit +'.png')\n",
      "\n",
      "    plt.close(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 239
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# WORKSPACE!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "se_f, sp_f = get_feature_stat_se_sp(forests_final_1)\n",
      "\n",
      "#### Load /save\n",
      "pdf_feat_f = pd.load('/root/code/xerox/windows/df_feat_f')\n",
      "pdf_feat_c = pd.load('/root/code/xerox/windows/df_feat_c')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "se_f, sp_f = get_col_se_sp(forests_final_1, data_train_living, data_train_dead, data_valid, labels_valid)\n",
      "df_feat_f = get_df(se_f, sp_f)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Load /save\n",
      "df_feat_f = pd.load('/root/code/xerox/windows/df_feat_f')\n",
      "### df_feat_c = pd.load('/root/code/xerox/windows/df_feat_c')\n",
      "\n",
      "### df_feat_f.save('/root/code/xerox/windows/df_leaf_f')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.max_rows', 200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 240
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "forests = [RandomForestClassifier(n_estimators=100, class_weight={0:1, 0:1}, max_features=1,\n",
      "                                      n_jobs=-1, max_depth=4\n",
      "                                      ) for i in xrange(n_train_splits)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "l = df_feat_f.sort(columns=['name', 'spec'], ascending=False).to_html()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "df_feat_f[150:200]\n",
      "df_feat_f.sort(columns=['spec', 'diff'], ascending=False)[100:150]   # Diff, sp\n",
      "df_feat_f\n",
      "df_feat_f.sort(columns=[ 'spec', 'sens'], ascending=False)[50:100]   # Specifity, se\n",
      "df_feat_f.sort(columns=['sens', 'spec'], ascending=False) #Sensitivity, sp\n",
      "df_feat_f.sort(columns=['name', 'spec'], ascending=False) #Sensitivity, sp\n",
      "df_feat_f.sort(columns=['diff', 'spec'], ascending=False)   # Diff, sp"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "df_feat_c\n",
      "df_feat_c.sort(columns=['diff', 'spec'], ascending=False)   # Diff, sp\n",
      "df_feat_c\n",
      "df_feat_c.sort(columns=['sens', 'spec'], ascending=False)   # Sensitivity, sp\n",
      "df_feat_c.sort(columns=[ 'spec', 'sens'], ascending=False)   # Specifity, se"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The bigger classifier!\n",
      "\n",
      "- get all SLIDING windows on the training data\n",
      "- label all windows depending on the patients label\n",
      "- train random forests on the sliding windows\n",
      "- training data row - stats of the entire ts\n",
      "- train random forests on the training data in parts\n",
      "- On the full training data\n",
      "    - use the rfs to get probs of each patient ts\n",
      "    - get stats of the probs\n",
      "    - classify the prob stats using non-linear model\n",
      "- On validation data:\n",
      "    - get windows starting from time 0\n",
      "    - classify each window using the learnt non-linear model\n",
      "    \n",
      "### Problems:\n",
      "- train - train data?\n",
      "- if valid data for nlm, less data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_features = 31\n",
      "time_ind = 31\n",
      "#### Save the np arrays for speed and load from here\n",
      "patient_combined = np.load('/root/code/xerox/patient_combined_train.npy')\n",
      "age_combined = np.load('/root/code/xerox/age_combined_train.npy')\n",
      "icu_combined = np.load('/root/code/xerox/icu_combined_train.npy')\n",
      "df_labels = pd.read_csv('data_train/id_label_train.csv')\n",
      "labels_combined = np.array(df_labels.LABEL)\n",
      "age_combined = age_combined.reshape((age_combined.shape[0], 1))\n",
      "labels_combined = labels_combined.reshape((labels_combined.shape[0], 1))\n",
      "patient_combined = np.array(patient_combined)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(100)\n",
      "\n",
      "split = [0.70, 0.30]    # train%, validation%, (test%)\n",
      "[ind_train, ind_valid, ind_test] = get_ind_split(age_combined.shape[0], split)\n",
      "patients_train = patient_combined[ind_train]\n",
      "patients_valid = patient_combined[ind_valid]\n",
      "patients_test = patient_combined[ind_test]    # Data_combined = patient_combined\n",
      "print patients_train.shape, patients_valid.shape, patients_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2515,) (1079,) (0,)\n"
       ]
      }
     ],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats = [np.mean, np.var,\n",
      "         np.min, np.max,\n",
      "         lambda x, axis:x[x.shape[0]-1],    # first element\n",
      "         lambda x, axis:x[0],               # last element\n",
      "         lambda x, time_: slope(x, time_)   # slope of the window\n",
      "        ]          \n",
      "n_windows = 1\n",
      "window_size= None\n",
      "last_window_size = None\n",
      "#cols_feat = []\n",
      "cols_feat = None\n",
      "\n",
      "### BIG FOREST PARAMS\n",
      "stats_big = [np.mean, np.var,\n",
      "             np.median,\n",
      "             lambda x, axis:scipy.stats.mode(x, axis=axis)[0],\n",
      "             np.min, np.max,\n",
      "             lambda x, axis:x[x.shape[0]-1],    # first element\n",
      "             lambda x, axis:x[0],               # last element\n",
      "             lambda x, axis:x.shape[0],\n",
      "             lambda x, time_: slope(x, time_)\n",
      "             ]  # slope of the window\n",
      "n_windows_big = 1\n",
      "window_size_big= None\n",
      "#labels_bias = labels_combined[ind_train]\n",
      "labels_bias = None\n",
      "take_mean=True\n",
      "\n",
      "#n_train_splits = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 248
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats_patients_train = get_rows_data(patients_train, n_windows, stats, time=time_ind, last_window_size=last_window_size,\n",
      "                                     icu_ind=icu_combined[ind_train], verbose=False)\n",
      "stats_patients_valid = get_rows_data(patients_valid, n_windows, stats, time=time_ind, last_window_size=last_window_size,\n",
      "                                     icu_ind=icu_combined[ind_valid], verbose=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 249
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Backchodi start"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print stats_patients_train.shape, stats_patients_valid.shape\n",
      "print labels_combined[ind_valid].shape, labels_combined[ind_train].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2515, 217) (1079, 217)\n",
        "(1079, 1) (2515, 1)\n"
       ]
      }
     ],
     "prompt_number": 250
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "cols_feat = [0, 1, 2, 3, 4, 5, 31, 32, 33, 34, 35, 36]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cols_feat = [127, 125,124,128,113,25,2]\n",
      "#cols_feat = [2, 3, 0, 1, 4, 25]\n",
      "cols_feat = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_train_splits=6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "np.random.seed(1000)\n",
      "forests_final_1 = [RandomForestClassifier(n_estimators=100, class_weight={0:0.1, 0:1}, max_features=10,\n",
      "                                      n_jobs=-1, max_depth=3\n",
      "                                      ) for i in xrange(n_train_splits)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "train_balanced(forests_final_1, stats_patients_train, labels_combined[ind_train])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6 389 2339\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 254,
       "text": [
        "[array([[386,   3],\n",
        "        [ 54, 122]]), array([[385,   4],\n",
        "        [ 52, 124]]), array([[381,   8],\n",
        "        [ 57, 119]]), array([[388,   1],\n",
        "        [ 61, 115]]), array([[387,   2],\n",
        "        [ 61, 115]]), array([[386,   3],\n",
        "        [ 59, 117]])]"
       ]
      }
     ],
     "prompt_number": 254
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# HERE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print n_train_splits"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6\n"
       ]
      }
     ],
     "prompt_number": 255
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### GIVE ONLY ICU TIME WINODWS!\n",
      "list_probs_train = get_probs_all_windows(patients_train, n_windows, stats, forests_final_1, time=time_ind,\n",
      "                                         list_of_icu=icu_combined[ind_train], cols=cols_feat,\n",
      "                                         labels_for_icu_bias=None, mean=take_mean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 256
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "print list_probs_train[0]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list_probs_train[9].shape, np.sum(icu_combined[ind_train][9])\n",
      "print list_probs_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(372, 9) 372\n",
        "(2515,)\n"
       ]
      }
     ],
     "prompt_number": 258
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "prob_stats_row_train = get_rows_data(list_probs_train, n_windows_big, stats_big)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prob_stats_row_train = get_rows_data(prob_min_max_train, n_windows_big, stats_big)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 960
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "print len(stats_big)\n",
      "print prob_stats_row_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'prob_stats_row_train' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-183-4a943b89dd0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats_big\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mprob_stats_row_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'prob_stats_row_train' is not defined"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#train_prob_stats =  np.hstack((train_prob_stats, age_train))   # Append the age column here\n",
      "forest_big = RandomForestClassifier(n_estimators=300, class_weight={0:1, 1:1}, max_features=1,\n",
      "                                      n_jobs=-1, max_depth=3)\n",
      "forest_big.fit(prob_stats_row_train, labels_combined[ind_train][:, 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 966,
       "text": [
        "RandomForestClassifier(bootstrap=True, class_weight={0: 1, 1: 1},\n",
        "            criterion='gini', max_depth=3, max_features=1,\n",
        "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
        "            oob_score=False, random_state=None, verbose=0,\n",
        "            warm_start=False)"
       ]
      }
     ],
     "prompt_number": 966
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_probs_valid = get_probs_all_windows(patients_valid, n_windows, stats, forests_final_1, time=time_ind,\n",
      "                                         list_of_icu=icu_combined[ind_valid], cols=cols_feat,\n",
      "                                         labels_for_icu_bias=None, mean=take_mean)\n",
      "print list_probs_valid.shape, list_probs_valid[0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1438,) (55, 9)\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "print list_probs_valid[0], list_probs_valid[0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.154    0.154    0.166    0.218    0.22     0.236    0.154    0.236\n",
        "   0.19225]\n",
        " [ 0.264    0.28     0.28     0.3      0.312    0.324    0.264    0.324\n",
        "   0.2935 ]\n",
        " [ 0.258    0.272    0.274    0.274    0.31     0.328    0.258    0.328\n",
        "   0.28775]\n",
        " [ 0.142    0.142    0.194    0.218    0.218    0.24     0.142    0.24\n",
        "   0.192  ]\n",
        " [ 0.11     0.128    0.182    0.186    0.188    0.228    0.11     0.228\n",
        "   0.17   ]\n",
        " [ 0.23     0.268    0.272    0.278    0.292    0.322    0.23     0.322\n",
        "   0.27675]\n",
        " [ 0.27     0.296    0.3      0.3      0.326    0.354    0.27     0.354\n",
        "   0.30875]\n",
        " [ 0.152    0.242    0.244    0.262    0.29     0.32     0.152    0.32\n",
        "   0.24775]\n",
        " [ 0.52     0.548    0.568    0.57     0.716    0.898    0.52     0.898\n",
        "   0.65475]\n",
        " [ 0.556    0.566    0.574    0.588    0.706    0.904    0.556    0.904\n",
        "   0.66925]\n",
        " [ 0.254    0.372    0.398    0.482    0.526    0.562    0.254    0.562\n",
        "   0.42625]\n",
        " [ 0.62     0.624    0.644    0.662    0.73     0.922    0.62     0.922\n",
        "   0.718  ]\n",
        " [ 0.604    0.62     0.65     0.694    0.728    0.91     0.604    0.91\n",
        "   0.715  ]\n",
        " [ 0.134    0.22     0.244    0.26     0.336    0.386    0.134    0.386\n",
        "   0.2625 ]\n",
        " [ 0.102    0.192    0.278    0.332    0.338    0.352    0.102    0.352\n",
        "   0.256  ]\n",
        " [ 0.528    0.612    0.626    0.632    0.72     0.92     0.528    0.92\n",
        "   0.68575]\n",
        " [ 0.102    0.172    0.226    0.228    0.306    0.324    0.102    0.324\n",
        "   0.223  ]\n",
        " [ 0.13     0.198    0.2      0.248    0.314    0.378    0.13     0.378\n",
        "   0.247  ]\n",
        " [ 0.134    0.196    0.204    0.248    0.34     0.382    0.134    0.382\n",
        "   0.2525 ]\n",
        " [ 0.22     0.224    0.29     0.322    0.334    0.384    0.22     0.384\n",
        "   0.29725]\n",
        " [ 0.48     0.53     0.592    0.612    0.728    0.918    0.48     0.918\n",
        "   0.65725]\n",
        " [ 0.11     0.126    0.22     0.258    0.33     0.376    0.11     0.376\n",
        "   0.23825]\n",
        " [ 0.112    0.122    0.196    0.246    0.31     0.356    0.112    0.356\n",
        "   0.22625]\n",
        " [ 0.122    0.142    0.198    0.248    0.328    0.374    0.122    0.374\n",
        "   0.2385 ]\n",
        " [ 0.088    0.146    0.192    0.248    0.312    0.348    0.088    0.348\n",
        "   0.22125]\n",
        " [ 0.094    0.102    0.192    0.23     0.244    0.332    0.094    0.332\n",
        "   0.2025 ]\n",
        " [ 0.084    0.098    0.19     0.226    0.25     0.318    0.084    0.318\n",
        "   0.196  ]\n",
        " [ 0.118    0.182    0.226    0.324    0.332    0.348    0.118    0.348\n",
        "   0.2495 ]\n",
        " [ 0.348    0.448    0.546    0.608    0.64     0.854    0.348    0.854\n",
        "   0.58075]\n",
        " [ 0.39     0.492    0.57     0.622    0.714    0.91     0.39     0.91\n",
        "   0.62475]\n",
        " [ 0.104    0.17     0.21     0.234    0.296    0.314    0.104    0.314\n",
        "   0.21825]\n",
        " [ 0.078    0.1      0.19     0.214    0.246    0.312    0.078    0.312\n",
        "   0.19125]\n",
        " [ 0.27     0.352    0.382    0.6      0.606    0.66     0.27     0.66\n",
        "   0.475  ]\n",
        " [ 0.076    0.096    0.188    0.204    0.262    0.3      0.076    0.3\n",
        "   0.18775]\n",
        " [ 0.084    0.154    0.206    0.208    0.246    0.296    0.084    0.296\n",
        "   0.19675]\n",
        " [ 0.086    0.092    0.192    0.198    0.258    0.294    0.086    0.294\n",
        "   0.1875 ]\n",
        " [ 0.072    0.086    0.188    0.198    0.254    0.296    0.072    0.296\n",
        "   0.18275]\n",
        " [ 0.106    0.264    0.284    0.308    0.328    0.448    0.106    0.448\n",
        "   0.2865 ]\n",
        " [ 0.068    0.09     0.186    0.196    0.256    0.294    0.068    0.294\n",
        "   0.1815 ]\n",
        " [ 0.106    0.266    0.27     0.308    0.324    0.442    0.106    0.442\n",
        "   0.283  ]\n",
        " [ 0.52     0.614    0.646    0.678    0.7      0.918    0.52     0.918\n",
        "   0.68925]\n",
        " [ 0.13     0.2      0.268    0.316    0.398    0.414    0.13     0.414\n",
        "   0.28375]\n",
        " [ 0.074    0.092    0.194    0.198    0.258    0.296    0.074    0.296\n",
        "   0.18525]\n",
        " [ 0.078    0.092    0.194    0.194    0.264    0.294    0.078    0.294\n",
        "   0.186  ]\n",
        " [ 0.102    0.186    0.222    0.3      0.308    0.324    0.102    0.324\n",
        "   0.2335 ]\n",
        " [ 0.076    0.096    0.188    0.198    0.264    0.282    0.076    0.282\n",
        "   0.18275]\n",
        " [ 0.08     0.09     0.19     0.198    0.25     0.28     0.08     0.28\n",
        "   0.181  ]\n",
        " [ 0.132    0.17     0.278    0.338    0.398    0.4      0.132    0.4\n",
        "   0.281  ]\n",
        " [ 0.132    0.158    0.268    0.306    0.39     0.41     0.132    0.41\n",
        "   0.27575]\n",
        " [ 0.134    0.16     0.274    0.338    0.382    0.388    0.134    0.388\n",
        "   0.27475]\n",
        " [ 0.132    0.178    0.278    0.3      0.398    0.404    0.132    0.404\n",
        "   0.27825]\n",
        " [ 0.07     0.094    0.178    0.208    0.254    0.278    0.07     0.278\n",
        "   0.17875]\n",
        " [ 0.076    0.106    0.184    0.214    0.246    0.288    0.076    0.288\n",
        "   0.18475]\n",
        " [ 0.094    0.132    0.16     0.258    0.31     0.35     0.094    0.35\n",
        "   0.2185 ]\n",
        " [ 0.042    0.052    0.114    0.156    0.284    0.298    0.042    0.298\n",
        "   0.16075]] (55, 9)\n"
       ]
      }
     ],
     "prompt_number": 346
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "prob_min_max_valid = get_transormed_array(list_probs_valid)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get rows (online) for each time series of probabilities\n",
      "prob_windows_stacked_val, ind_windows_stacked_val = get_stacked_windows_from_ts(list_probs_valid, n_windows_big, stats_big)\n",
      "#prob_windows_stacked_val, ind_windows_stacked_val = get_stacked_windows_from_ts(prob_min_max_valid, n_windows_big, stats_big)\n",
      "ind_windows_stacked_val = np.array(ind_windows_stacked_val, dtype=int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### using only min prob\n",
      "y_probs_stacked_1 = np.vstack(list_probs_valid)\n",
      "y = 0.63 + (1 - y_probs_stacked_1[:, 0].reshape((206816, 1))) < y_probs_stacked_1[:, 0].reshape((206816, 1))\n",
      "y_ = get_list_of_prediction_arrays(y, ind_windows_stacked_val)\n",
      "y_a = np.array([x.any() for x in y_])\n",
      "get_ss(confusion_matrix(labels_combined[ind_valid], y_a))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#prob_windows_stacked_val = np.hstack((prob_windows_stacked_val, age_valid[ind_windows_stacked_val])) # Stack AGE\n",
      "y_prob_stacked_val = forest_big.predict_proba(prob_windows_stacked_val)\n",
      "theta_max, se, sp = train_theta_max_sens_stacked(y_prob_stacked_val, labels_combined[ind_valid],\n",
      "                                          get_unstacked_predictions_from_probs_only_y,\n",
      "                                          ind_windows_stacked_val, N=20, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.21111  0.15556  0.1      0.07778  0.06667  0.04444  0.02222  0.       0.\n",
        "  0.       0.       0.     ]\n",
        "1\n"
       ]
      }
     ],
     "prompt_number": 1190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#theta_max = 0.5\n",
      "y_any_valid, list_y_preds_val = get_unstacked_predictions_from_probs(y_prob_stacked_val, ind_windows_stacked_val, theta_max)\n",
      "get_ss((confusion_matrix(labels_combined[ind_valid], y_any_valid)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1191,
       "text": [
        "(0.2111111111111111, 0.9918397626112759)"
       ]
      }
     ],
     "prompt_number": 1191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print theta_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.947368421053\n"
       ]
      }
     ],
     "prompt_number": 826
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_prob_stacked_val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 733,
       "text": [
        "array([[ 1.,  0.],\n",
        "       [ 1.,  0.],\n",
        "       [ 1.,  0.],\n",
        "       ..., \n",
        "       [ 1.,  0.],\n",
        "       [ 1.,  0.],\n",
        "       [ 1.,  0.]])"
       ]
      }
     ],
     "prompt_number": 733
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "plt.scatter(sp, se)\n",
      "plt.show()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### EN OF BIG FOREST\n",
      "y_prob_stacked_val_en = get_model_sum_probs(prob_windows_stacked_val, forests_big_en)\n",
      "print y_prob_stacked_val_en[:100]\n",
      "theta_en = 0.9\n",
      "y_any_valid_en, list_y_preds_val_en = get_unstacked_predictions_from_probs(y_prob_stacked_val_en, ind_windows_stacked_val,\n",
      "                                                                           theta_en)\n",
      "get_ss((confusion_matrix(labels_combined[ind_valid], y_any_valid_en)))"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## MAKE WINDOW LENGTH DEPENDENT ON LENGTH OF ICU STAY"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print np.arange(y_any_valid.shape[0])[y_any_valid]  # all valid indices with at least one 1\n",
      "# find the indices at which 1 was predicted, and the label\n",
      "# i = 31\n",
      "#print np.arange(list_y_preds_val[i].shape[0])[list_y_preds_val[i][:, 0] == 1], labels_valid[i]\n",
      "#print labels_valid[y_any_valid != (l>0)]    # TRUE LABELS WHERE THE PREDICTION 1 WAS MADE AT TIME 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# LOAD VALIDATION DATA!\n",
      "\n",
      "df_vitals_valid = pd.read_csv('validation/id_time_vitals_val.csv')\n",
      "df_labs_valid = pd.read_csv('validation/id_time_labs_val.csv')\n",
      "\n",
      "df_age_valid = pd.read_csv('validation/id_age_val.csv')\n",
      "\n",
      "[patients_combined_val, age_combined_val, icu_combined_val] = get_norm_patients_from_df(df_vitals_valid, df_labs_valid,\n",
      "                                                                                         df_age_valid, x_range, W, path)\n",
      "icu = np.array(df_vitals_valid.TIME[df_vitals_valid.ICU==1])\n",
      "icu = icu.reshape((icu.shape[0], 1))\n",
      "\n",
      "np.save('/root/code/xerox/patients_combined_val.npy', patients_combined_val)\n",
      "np.save('/root/code/xerox/icu_combined_val.npy', icu_combined_val)\n",
      "\n",
      "np.save('/root/code/xerox/age_combined_val.npy', age_combined_val)\n",
      "\n",
      "age_combined_val = np.array(df_age_valid.AGE)\n",
      "age_combined_val = np.array([norm_transform(x, x_range_age, W_age) for x in age_combined_val]).reshape((age_combined_val.shape[0],1))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "age_combined_val = np.load('/root/code/xerox/age_combined_val.npy')\n",
      "df_labels_valid = pd.read_csv('/root/Downloads/id_label_val.csv', header=False)\n",
      "patients_combined_val = np.load('/root/code/xerox/patients_combined_val.npy')\n",
      "icu_combined_val = np.load('/root/code/xerox/icu_combined_val.npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### TO write final predictions\n",
      "y_preds_stacked = np.vstack(list_y_preds_valid)\n",
      "y_preds_stacked = y_preds_stacked.reshape((y_preds_stacked.shape[0], 1))\n",
      "final_pred_arr = np.hstack((np.array(df_vitals_valid.ID[df_vitals_valid.ICU==1]).reshape((icu.shape[0], 1)),\n",
      "                            icu, y_preds_stacked))\n",
      "final_pred_arr = np.array(final_pred_arr, dtype=int)\n",
      "np.savetxt('/root/output2.csv', final_pred_arr, delimiter=',', fmt='%d')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test on valiataion data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_probs_Valid = get_probs_all_windows(patients_combined_val, n_windows, stats, forests_final_1, time_ind,\n",
      "                                         list_of_icu=icu_combined_val, cols=cols_feat,\n",
      "                                         labels_for_icu_bias=None, mean=take_mean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_stacked_test, ind_windows_stacked_test = get_stacked_windows_ind(list_probs_test)\n",
      "y_probs_stacked = forest_big_m.predict_proba(probs_stacked_test[:, :6])\n",
      "y_any_m, list_y_preds_m = get_unstacked_predictions_from_probs(y_probs_stacked, ind_windows_stacked_test, 0.99999) \n",
      "get_ss(confusion_matrix(df_labels_valid.label, y_any_m))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 368,
       "text": [
        "(0.24390243902439024, 0.989247311827957)"
       ]
      }
     ],
     "prompt_number": 368
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list_probs_test.shape, list_probs_test[0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1198,) (5, 9)\n"
       ]
      }
     ],
     "prompt_number": 359
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get rows (online) for each time series of probabilities\n",
      "prob_windows_stacked_test, ind_windows_stacked_test = get_stacked_windows_from_ts(list_probs_test, n_windows_big, stats_big)\n",
      "ind_windows_stacked_test = np.array(ind_windows_stacked_test, dtype=int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 713
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_big_test = forest_big.predict_proba(prob_windows_stacked_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 937
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_any_test, list_y_preds_test = get_unstacked_predictions_from_probs(probs_big_test, ind_windows_stacked_test, theta_max)\n",
      "se_test, sp_test = get_ss((confusion_matrix(df_labels_valid.label, y_any_test)))\n",
      "print se_test, sp_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.207317073171 0.994623655914\n"
       ]
      }
     ],
     "prompt_number": 938
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "[ind_fp_test, ind_fn_test, ind_tp_test, ind_tn_test] = get_confusion_inds(df_labels_valid.label, y_a)\n",
      "types_test = get_str_type(ind_fp_test, ind_tp_test, ind_fn_test, ind_tn_test)\n",
      "list_big_prob_test = get_list_of_prediction_arrays(probs_big_test, ind_windows_stacked_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 900
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind_tp_test = np.array(ind_tp_test, dtype=bool); ind_tn_test = np.array(ind_tn_test, dtype=bool)\n",
      "ind_fp_test = np.array(ind_fp_test, dtype=bool); ind_fn_test = np.array(ind_fn_test, dtype=bool)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 901
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 802
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.ioff()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 902
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if 'run_no' not in locals():\n",
      "    print 'hey'\n",
      "    run_no = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 903
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_no = run_no+1\n",
      "folder = 'run'+ str(run_no) + '_' + str(se_test) + '_' + str(sp_test)\n",
      "#folder = '9_99'\n",
      "if labels_bias is not None:\n",
      "    folder = folder + '_all'\n",
      "if cols_feat is not None:\n",
      "    folder = folder + '_cols'\n",
      "    \n",
      "folder = folder + '_' + '_'.join([x.func_name for x in stats_big])\n",
      "\n",
      "path = mkdirs(folder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 904
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.save('/root/code/xerox/plots/' + folder + '/list_y_preds_test.npy', list_y_preds_test)\n",
      "np.save('/root/code/xerox/plots/' + folder + '/list_y_prob_test.npy', list_probs_test)\n",
      "np.save('/root/code/xerox/plots/' + folder + '/list_big_prob_test.npy', list_big_prob_test)\n",
      "np.save('/root/code/xerox/plots/' + folder + '/types_test.npy', types_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 906
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_all_probs(ind_fp_test, path, icu_combined_val, list_probs_test, list_big_prob_test, figsize=(30, 20))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 914
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_all_probs(ind_tp_test[:], path, icu_combined_val, list_probs_test, list_big_prob_test, figsize=(30, 20))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 915
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_all_probs(ind_fn_test[:], path, icu_combined_val, list_probs_test, list_big_prob_test, figsize=(30, 20))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 916
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_all_probs(ind_tn_test[:20], path, icu_combined_val, list_probs_test, list_big_prob_test, figsize=(30, 20))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 917
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### using only mean\n",
      "y_probs_stacked_1 = np.vstack(list_probs_test)\n",
      "y = 0.63 + (1 - y_probs_stacked_1[:, 0].reshape((y_probs_stacked_1.shape[0], 1))) < y_probs_stacked_1[:, 0].reshape((y_probs_stacked_1.shape[0], 1))\n",
      "y_ = get_list_of_prediction_arrays(y, ind_windows_stacked_test)\n",
      "print y_.shape\n",
      "y_a = np.array([x.any() for x in y_])\n",
      "y_[61]\n",
      "print y_a.shape\n",
      "get_ss(confusion_matrix(df_labels_valid.label, y_a))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1198,)\n",
        "(1198,)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 928,
       "text": [
        "(0.25609756097560976, 0.9946236559139785)"
       ]
      }
     ],
     "prompt_number": 928
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### pred times\n",
      "pred_times_valid = get_prediction_times_all_patients(list_y_preds_valid, patients_combined_val, time_ind=time_ind, list_of_icu_times=icu_combined_val)\n",
      "pred_times_actual = pred_times_valid.copy()\n",
      "for i in xrange(pred_times_actual.shape[0]):\n",
      "    if(df_labels_valid.label[i] == 0):\n",
      "        pred_times_actual[i]=-1\n",
      "    if(df_labels_valid.label[i]==1):\n",
      "        pred_times_actual[i]=max(0, pred_times_valid[i])\n",
      "pred_times_actual[pred_times_actual>=0].shape\n",
      "np.median(pred_times_actual[pred_times_actual>=0])\n",
      "np.median(pred_times_actual[pred_times_actual>0])\n",
      "\n",
      "l = get_prediction_times_all_patients(list_y_preds_val, patients_valid, time_ind, icu_combined[ind_valid])\n",
      "print 'median:', np.median(l[l>0]/3600), ', min:', np.min(l[l>0]/3600)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "y_prob_valid = get_proba(forests_final_1, stats_patients_valid, sort=True)\n",
      "y_valid = np.array(y_prob_valid[:, 0] > 0.5, dtype=int)\n",
      "get_ss(confusion_matrix(labels_combined[ind_valid], y_valid))\n",
      "y_prob_train = get_proba(forests_final_1, stats_patients_train, sort=True)\n",
      "y_train = np.array(y_prob_train[:, 0] > 0.5, dtype=int)\n",
      "get_ss(confusion_matrix(labels_combined[ind_train], y_train))\n",
      "list_probs_train = get_probs_all_windows(patients_train, n_windows, stats, forests_final_1, time=time_ind,\n",
      "                                         list_of_icu=icu_combined[ind_train], cols=cols_feat,\n",
      "                                         labels_for_icu_bias=None, mean=take_mean)\n",
      "list_probs_valid = get_probs_all_windows(patients_valid, n_windows, stats, forests_final_1, time=time_ind,\n",
      "                                         list_of_icu=icu_combined[ind_valid], cols=cols_feat,\n",
      "                                         labels_for_icu_bias=None, mean=take_mean)\n",
      "print list_probs_valid.shape, list_probs_valid[0].shape\n",
      "list_probs_test = get_probs_all_windows(patients_test, n_windows, stats, forests_final_1, time=time_ind,\n",
      "                                         list_of_icu=icu_combined[ind_test], cols=cols_feat,\n",
      "                                         labels_for_icu_bias=None, mean=take_mean)\n",
      "print list_probs_test.shape, list_probs_test[0].shape\n",
      "#### evidence for range :Pk\n",
      "sfp = []\n",
      "for probs in list_probs_train[ind_fp[:, 0]]:\n",
      "    minp = probs[:, 0]\n",
      "    sfp.append(np.mean((probs[:, n_train_splits-1] - probs[:, 0])[minp>0.5]))\n",
      "print np.min(stp), np.min(sfp)\n",
      "print np.median(stp), np.median(sfp)\n",
      "print np.mean(stp), np.mean(sfp)\n",
      "### RANDOM FOREST USING ONLY MIN AND RANGES\n",
      "def get_transormed_array(list_of_arrays):\n",
      "    r = []\n",
      "    for l in list_of_arrays:\n",
      "        r.append(np.hstack((np.min(l, axis=1).reshape((l.shape[0], 1)),\n",
      "                            (np.max(l[:, :6], axis=1)-np.min(l[:, :6], axis=1)).reshape((l.shape[0], 1)),\n",
      "                            np.max(l[:, :6], axis=1).reshape((l.shape[0], 1))\n",
      "                            )\n",
      "                          )\n",
      "                 )\n",
      "                 \n",
      "    r = np.array(r)\n",
      "    return r\n",
      "prob_min_max_train = get_transormed_array(list_probs_train)\n",
      "prob_min_max_val = get_transormed_array(list_probs_valid)\n",
      "prob_min_stacked_val, ind_windows_stacked_val = get_stacked_windows_ind(prob_min_max_val)\n",
      "ind_windows_stacked_val = np.array(ind_windows_stacked_val, dtype=int)\n",
      "#### TRAIN ON COMBINED TRAINING AND VALIDATION SETS\n",
      "prob_min_stacked_combined = np.vstack((prob_min_stacked_val, prob_min_stacked_train))\n",
      "labels_stacked_combined = np.vstack((labels_combined[ind_valid][ind_windows_stacked_val],\n",
      "                                     labels_combined[ind_train][ind_windows_stacked_train]))\n",
      "forest_big_m = RandomForestClassifier(n_estimators=100, class_weight={0:1, 1:1}, max_features=None,\n",
      "                                      n_jobs=-1, max_depth=None)\n",
      "forest_big_m.fit(prob_min_stacked_val, labels_combined[ind_valid][ind_windows_stacked_val][:, 0])\n",
      "y_probs_stacked = forest_big_m.predict_proba(prob_min_stacked_val)\n",
      "y_any_m, list_y_preds_m = get_unstacked_predictions_from_probs(y_probs_stacked, ind_windows_stacked_val, 0.8) \n",
      "get_ss(confusion_matrix(labels_combined[ind_valid], y_any_m))\n",
      "prob_min_stacked_test = get_transormed_array(list_probs_test)\n",
      "prob_min_stacked_test, ind_windows_stacked_test = get_stacked_windows_ind(prob_min_stacked_test)\n",
      "y_probs_stacked = forest_big_m.predict_proba(prob_min_stacked_test)\n",
      "y_any_m, list_y_preds_m = get_unstacked_predictions_from_probs(y_probs_stacked, ind_windows_stacked_test, 0.999) \n",
      "get_ss(confusion_matrix(labels_combined[ind_test], y_any_m))\n",
      "list_probs_test.shape\n",
      "prob_min_max_Valid = get_transormed_array(list_probs_Valid)\n",
      "prob_min_stacked_test, ind_windows_stacked_Valid = get_stacked_windows_ind(prob_min_max_Valid)\n",
      "ind_windows_stacked_Valid = np.array(ind_windows_stacked_Valid, dtype=int)\n",
      "y_probs_stacked_test = forest_big_m.predict_proba(prob_min_stacked_test)\n",
      "y_any_test, list_y_preds_test = get_unstacked_predictions_from_probs(y_probs_stacked_test, ind_windows_stacked_Valid, 0.97)\n",
      "get_ss(confusion_matrix(df_labels_valid.label, y_any_test))\n",
      "forest_big_m = RandomForestClassifier(n_estimators=100, class_weight={0:1, 1:1}, max_features=None,\n",
      "                                      n_jobs=-1, max_depth=None)\n",
      "forest_big_m.fit(prob_min_stacked_val, labels_combined[ind_valid][ind_windows_stacked_val][:, 0])\n",
      "path = mkdirs('test_min_max_range'); list_probs = list_probs_test; icu=icu_combined_val\n",
      "labels = labels_combined[ind_valid]; y_any = y_any_m\n",
      "list_probs = list_probs_valid\n",
      "icu = icu_combined[ind_valid]\n",
      "list_big_probs = get_list_of_prediction_arrays(y_probs_stacked, ind_windows_stacked_val)\n",
      "[ind_fp, ind_fn, ind_tp, ind_tn] =  get_confusion_inds(labels, y_any)\n",
      "types= get_str_type(ind_fp, ind_tp, ind_fn, ind_tn)\n",
      "ind_fp = np.array(ind_fp, dtype=bool); ind_tp = np.array(ind_tp, dtype=bool)\n",
      "ind_tn = np.array(ind_tn, dtype=bool); ind_fn = np.array(ind_fn, dtype=bool)\n",
      "labels = df_labels_valid.label; y_any = y_any_test\n",
      "list_probs = list_probs_test\n",
      "icu = icu_combined_val\n",
      "list_big_probs = get_list_of_prediction_arrays(y_probs_stacked_test, ind_windows_stacked_test)\n",
      "[ind_fp, ind_fn, ind_tp, ind_tn] =  get_confusion_inds(labels, y_any)\n",
      "types= get_str_type(ind_fp, ind_tp, ind_fn, ind_tn)\n",
      "ind_fp = np.array(ind_fp, dtype=bool); ind_tp = np.array(ind_tp, dtype=bool)\n",
      "ind_tn = np.array(ind_tn, dtype=bool); ind_fn = np.array(ind_fn, dtype=bool)\n",
      "plot_all_probs(ind_fp, path, icu, list_probs, max_plots=30, list_big_prob=list_big_probs,\n",
      "               types_test=types)\n",
      "plot_all_probs(ind_tp, path, icu, list_probs, max_plots=30, list_big_prob=list_big_probs,\n",
      "               types_test=types)\n",
      "plot_all_probs(ind_tn, path, icu, list_probs, max_plots=30, list_big_prob=list_big_probs,\n",
      "               types_test=types)\n",
      "plot_all_probs(ind_fn, path, icu, list_probs, max_plots=30,list_big_prob=list_big_probs,\n",
      "               types_test=types)\n",
      "#### RF USING ALL SORTED PROBS\n",
      "probs_stacked_train, ind_windows_stacked_train = get_stacked_windows_ind(list_probs_train)\n",
      "ind_windows_stacked_train = np.array(ind_windows_stacked_train, dtype=int)\n",
      "probs_stacked_valid, ind_windows_stacked_valid = get_stacked_windows_ind(list_probs_valid)\n",
      "ind_windows_stacked_valid = np.array(ind_windows_stacked_valid, dtype=int)\n",
      "probs_stacked_test, ind_windows_stacked_test = get_stacked_windows_ind(list_probs_test)\n",
      "ind_windows_stacked_test = np.array(ind_windows_stacked_test, dtype=int)\n",
      "print ind_windows_stacked_train.shape, probs_stacked_train.shape\n",
      "print probs_stacked_valid.shape, ind_windows_stacked_val.shape\n",
      "#### TRAIN ON COMBINED TRAINING AND VALIDATION SETS\n",
      "probs_combined = np.vstack((probs_stacked_valid, probs_stacked_train))\n",
      "labels_stacked_combined = np.vstack((labels_combined[ind_valid][ind_windows_stacked_val],\n",
      "                                     labels_combined[ind_train][ind_windows_stacked_train]))\n",
      "probs_combined.shape\n",
      "forest_big_m = RandomForestClassifier(n_estimators=100, class_weight={0:0.05, 1:1}, max_features=6,\n",
      "                                      n_jobs=-1, max_depth=5)\n",
      "####forest_big_m.fit(probs_combined[:, :6], labels_stacked_combined[:, 0])\n",
      "forest_big_m.fit(probs_stacked_valid[:, :6], labels_combined[ind_valid][ind_windows_stacked_valid][:, 0])\n",
      "y_probs_stacked = forest_big_m.predict_proba(probs_stacked_test[:, :6])\n",
      "y_any_m, list_y_preds_m = get_unstacked_predictions_from_probs(y_probs_stacked, ind_windows_stacked_test, 0.93) \n",
      "get_ss(confusion_matrix(labels_combined[ind_test], y_any_m))\n",
      "probs_stacked_val, ind_windows_stacked_val = get_stacked_windows_ind(list_probs_valid)\n",
      "y_probs_stacked = forest_big_m.predict_proba(probs_stacked_val[:, :6])\n",
      "y_any_m, list_y_preds_m = get_unstacked_predictions_from_probs(y_probs_stacked, ind_windows_stacked_val, 0.93) \n",
      "get_ss(confusion_matrix(labels_combined[ind_valid], y_any_m))\n",
      "probs_stacked_test, ind_windows_stacked_test = get_stacked_windows_ind(list_probs_test)\n",
      "y_probs_stacked_test = forest_big_m.predict_proba(probs_stacked_test[:, :6])\n",
      "y_any_m, list_y_preds_m = get_unstacked_predictions_from_probs(y_probs_stacked_test, ind_windows_stacked_test, 0.93) \n",
      "get_ss(confusion_matrix(df_labels_valid.label, y_any_m))\n",
      "prob_min_max_train = get_transormed_array(list_probs_train)\n",
      "prob_min_stacked_train, ind_stacked_train = get_stacked_windows_ind(prob_min_max_train)\n",
      "ind_stacked_train = np.array(ind_stacked_train, dtype=int)\n",
      "y_probs_stacked = forest_big_m.predict_proba(prob_min_stacked_train)\n",
      "y_any_m, list_y_preds_m = get_unstacked_predictions_from_probs(y_probs_stacked, ind_stacked_train, 0.8) \n",
      "get_ss(confusion_matrix(labels_combined[ind_train], y_any_m))"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}