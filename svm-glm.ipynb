{
 "metadata": {
  "name": "",
  "signature": "sha256:41742a5d18a11aa4487dbcdbd97aeeab27c9355a7eb47cb06b79a9c16a817893"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "%reset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "col_labs =[\n",
      "\"Systolic Blood Pressure in mmHg\",\n",
      "\"Diastolic Blood Pressure in mmHg\", \n",
      "\"Heart Rate in bpm\", \n",
      "\"Respiration Rate in bpm\",\n",
      "\"Oxygen Saturation in %\",\n",
      "\"Temperature in Celsius\",\n",
      "\"Arterial blood PH in ph\",\n",
      "\"Partial Pressure of Carbon dioxide (PaCO2) in mmHg\",\n",
      "\"Partial Pressure of Oxygen (PaO2) in mmHg\",\n",
      "\"Sodium in mmol/L\",\n",
      "\"Potassium in mmol/L\",\n",
      "\"Bicarbonate in mmol/L\",\n",
      "\"Blood Urea Nitrogen in mg/dL\",\n",
      "\"Serum Creatinine in mg/dL\",\n",
      "\"WBC Count in x 103/\u00b5L\",\n",
      "\"Hematocrit %\",\n",
      "\"Platelet Count in x 103/\u00b5L\",\n",
      "\"Bilirubin in mg/dL\",\n",
      "\"Urine Output in ml\",\n",
      "\"LDL Cholesterol in mg/dL\",\n",
      "\"Lactic Acid in mmol/L\",\n",
      "\"Troponin I in ng/ml\",\n",
      "\"Troponin T in ng/ml\",\n",
      "\"Random Blood Glucose in mg/dL\",\n",
      "\"Fasting Blood Glucose in mg/dL\",\n",
      "\"Fraction of Inspired Oxygen (FiO2) in %\",\n",
      "\"Albumin in g/dl\",\n",
      "\"Alkaline Phosphatase in IU/L\",\n",
      "\"Alanine in IU/L\",\n",
      "\"HDL Cholesterol in mg/dL\",\n",
      "\"Magnesium in mg/dL\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pysal\n",
      "from pysal import *\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import svm\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from math import *\n",
      "from scipy.stats import *\n",
      "import re\n",
      "import pandas\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import Series, DataFrame\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.stats import norm\n",
      "from sklearn.linear_model import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(precision=5, suppress=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_age = pd.read_csv('data_train/id_age_train.csv')\n",
      "df_labels = pd.read_csv('data_train/id_label_train.csv')\n",
      "df_vitals = pd.read_csv('data_train/id_time_vitals_train.csv')\n",
      "df_labs = pd.read_csv('data_train/id_time_labs_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_norm_df():\n",
      "\n",
      "    ### Normalize following the procedure in the paper\n",
      "\n",
      "    #### Find the xL, xU, w1, w2, w3 vars\n",
      "\n",
      "    df_combined = df_vitals.drop('ICU', axis=1).copy()\n",
      "\n",
      "    df_combined = df_combined.join(df_labs.drop(['ID', 'TIME'], axis=1))\n",
      "    df_combined.drop(['ID', 'TIME'], axis=1, inplace=True)\n",
      "\n",
      "    ### Process the entire data using this process\n",
      "\n",
      "    # transform one element given range and W\n",
      "    def norm_transform(x, x_range, W):\n",
      "        if(x<x_range[0]):\n",
      "            x=x_range[0]\n",
      "        if(x>x_range[1]):\n",
      "            x=x_range[1]\n",
      "\n",
      "        return np.dot(W,\n",
      "                      [1, x, log(1+x)])\n",
      "\n",
      "    ###\n",
      "    x_range = np.zeros((n_features, 2))\n",
      "    W = np.zeros((n_features, 3))\n",
      "    for i in xrange(n_features):\n",
      "    #for i in xrange(1):\n",
      "        vals = df_combined.ix[df_combined.ix[:, i].notnull(), i]\n",
      "        vals = np.sort(vals)\n",
      "\n",
      "        # find the quantiles\n",
      "        N = vals.shape[0]\n",
      "        q = np.array([(j-0.5)/N for j in xrange(N)])\n",
      "\n",
      "        i_l = np.min(np.arange(q.shape[0])[q>0.01])\n",
      "        i_u = np.max(np.arange(q.shape[0])[q<0.99])\n",
      "\n",
      "        x_range[i, 0] = vals[i_l]\n",
      "        x_range[i, 1] = vals[i_u]\n",
      "\n",
      "        vals = vals[i_l: i_u+1]\n",
      "        q=norm.ppf(q[i_l: i_u+1]) / 3\n",
      "\n",
      "        X = np.ones((vals.shape[0], 3))\n",
      "        X[:, 1] = vals\n",
      "        X[:, 2] = np.log(1 + vals)\n",
      "\n",
      "        W[i, :] = np.dot(np.linalg.pinv(np.dot(X.T, X)),\n",
      "                         np.dot(X.T, q)\n",
      "                         )\n",
      "    print x_range[0], W[0], norm_transform(100, x_range[0], W[0])\n",
      "\n",
      "    ###############################################################normalize!\n",
      "    df_norm = df_combined.copy()\n",
      "    for i in xrange(n_features):\n",
      "        df_norm.ix[:, i] = df_norm.ix[:, i].apply(lambda x:norm_transform(x, x_range[i], W[i]))\n",
      "    df_norm[df_norm.isnull()] = 0\n",
      "\n",
      "    df_norm.to_csv(path='/root/code/xerox/windows/svm_norm_data.csv')\n",
      "\n",
      "    return df_norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_norm_patients_from_df(df):\n",
      "    patient_combined = [np.array(df.ix[df_vitals['ID'] == ID, :]) for ID in df_labels['ID'].unique()]\n",
      "\n",
      "    # split into living and dead\n",
      "    patient_combined_dead = [patient_combined[ID-1] for ID in df_labels['ID']\n",
      "                                                          if df_labels.ix[ID - 1, 'LABEL'] == 1]\n",
      "    patient_combined_living = [patient_combined[ID-1] for ID in df_labels['ID']\n",
      "                                                          if df_labels.ix[ID - 1, 'LABEL'] == 0]\n",
      "    age_combined = np.array(df_age.AGE)\n",
      "\n",
      "    return patient_combined, patient_combined_dead, patient_combined_living"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_features = 31"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "df_norm.to_csv('/root/code/xerox/windows/svm_norm_data.csv')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "## Read the valus directly from the files\n",
      "#df_norm = get_norm_df()\n",
      "df_norm = pd.read_csv('/root/code/xerox/windows/svm_norm_data.csv')\n",
      "df_norm.drop(['Unnamed: 0'], axis=1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_norm['TIME'] = df_vitals.TIME"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_ind = 31"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[patient_combined, patient_combined_dead, patient_combined_living] = get_norm_patients_from_df(df_norm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "age_combined = np.array(df_age.AGE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "icu_combined = np.array([np.array(df_vitals.ICU[df_vitals['ID']==i]) for i in df_labels['ID'].unique()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_combined = np.array(patient_combined)\n",
      "labels_combined = np.array(df_labels.LABEL)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_n_windows(ts, n_windows, stats, time_=None):\n",
      "    if time_ is not None:\n",
      "        cols = [i for i in np.arange(ts.shape[1]) if i != time_]\n",
      "        n_features = ts.shape[1] - 1\n",
      "    else:\n",
      "        cols = np.arange(ts.shape[1])\n",
      "        n_features = ts.shape[1]\n",
      "    \n",
      "    #print n_features\n",
      "    l = np.zeros((n_windows, len(stats) * n_features))\n",
      "    n = int(ts.shape[0] / n_windows)\n",
      "    \n",
      "    # get windows\n",
      "    for j in xrange(0, n_windows):\n",
      "        if (j==n_windows-1):\n",
      "            window = ts[j*n :, :] \n",
      "        else:\n",
      "            window = ts[j*n : (j+1)*n, :] \n",
      "\n",
      "        # apply stats to the window and append into a row\n",
      "        for k in xrange(len(stats)):\n",
      "            f = stats[k]\n",
      "            if f.func_name == '<lambda>':\n",
      "                if time_ is None:\n",
      "                    l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], None)\n",
      "                else:\n",
      "                    l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], window[:, time_])\n",
      "            else:\n",
      "                l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], axis=0)\n",
      "    return l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def get_windows_data(data, n_windows, stats):\n",
      "    window_stats = []\n",
      "    for i in xrange(len(data)):\n",
      "        ts = data[i]\n",
      "\n",
      "        if(ts.shape[0] < n_windows):\n",
      "            #window_stats.append(None)    # We want to keep 1-1 mapping with patients..\n",
      "            n = int(np.ceil(1.0 * n_windows / ts.shape[0]))\n",
      "            t = np.zeros((ts.shape[0] * n, ts.shape[1]))\n",
      "            for i in xrange(ts.shape[0]):\n",
      "                for k in xrange(n):\n",
      "                    t[n*i + k, :] = ts[i, :]\n",
      "            \n",
      "            ts = t\n",
      "\n",
      "        l = get_n_windows(ts, n_windows, stats)\n",
      "        window_stats.append(l)\n",
      "        \n",
      "    return window_stats"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Given list of patient time series, give a matrix with one row for each patient containing all windows\n",
      "def get_rows_data(data, n_windows, stats, time=None):\n",
      "    n_features = data[0].shape[1]\n",
      "    if time is not None:\n",
      "        n_features = n_features - 1\n",
      "    data_windows = np.zeros((len(data), n_windows*n_features*len(stats)))\n",
      "    for i in xrange(len(data)):\n",
      "        ts = data[i]\n",
      "\n",
      "        if(ts.shape[0] < n_windows):\n",
      "            #window_stats.append(None)    # We want to keep 1-1 mapping with patients..\n",
      "            n = int(np.ceil(1.0 * n_windows / ts.shape[0]))\n",
      "            t = np.zeros((ts.shape[0] * n, ts.shape[1]))\n",
      "            for i in xrange(ts.shape[0]):\n",
      "                for k in xrange(n):\n",
      "                    t[n*i + k, :] = ts[i, :]\n",
      "            \n",
      "            ts = t\n",
      "            continue\n",
      "\n",
      "        l = get_n_windows(ts, n_windows, stats, time)\n",
      "        data_windows[i, :] = np.hstack(l)\n",
      "        \n",
      "    return data_windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## For ONLINE prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get windows starting with zero upto end for the time series 'ts', ONLY for which icu=1 (If provided)\n",
      "def get_online_windows(ts, icu=None):\n",
      "    if icu is None:\n",
      "        p_windows = np.array([ts[:i+1, :] for i in xrange(ts.shape[0])])\n",
      "    else:   # inclue only if icu[i] == 1\n",
      "        p_windows = np.array([ts[:i+1, :] for i in xrange(ts.shape[0]) if icu[i]==1])\n",
      "    return p_windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get stats of a given ts for all possible windows starting with 1 element\n",
      "def get_all_window_stats(ts, n_windows, stats, time=None, icu=None):\n",
      "    p_windows = get_online_windows(ts, icu)\n",
      "    p_all_window_stats = get_rows_data(p_windows, n_windows, stats, time)\n",
      "    return p_all_window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Given a LIST of patient time series, give back a list of matrices, one for each time series, where each row is window 0..i\n",
      "def get_list_all_window_stats(data, n_windows, stats, time=None, list_of_icu=None):\n",
      "    all_window_stats = []\n",
      "    for i, d in enumerate(data):\n",
      "        if list_of_icu is None:\n",
      "            all_window_stats.append(get_all_window_stats(d, n_windows, stats, time))\n",
      "        else:\n",
      "            all_window_stats.append(get_all_window_stats(d, n_windows, stats, time, list_of_icu[i]))\n",
      "    \n",
      "    return all_window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### For testing online ones!\n",
      "ts = patients_valid[0:2]\n",
      "ts[1].shape\n",
      "p_windows = get_online_windows(ts[1])\n",
      "p_windows[10].shape\n",
      "p_stats = get_all_window_stats(ts[1], n_windows, stats)\n",
      "p_stats.shape\n",
      "p_all = get_list_all_window_stats(ts, n_windows, stats)\n",
      "p_all[1].shape"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Confusion!\n",
      "def get_ss(confusion):\n",
      "    tn = confusion[0, 0]  # label=0, pred=0\n",
      "    fp = confusion[0, 1]  # label=0, pred=1\n",
      "    \n",
      "    fn = confusion[1, 0]  # label=1, pred=0\n",
      "    tp = confusion[1, 1]  # label=1, pred=1\n",
      "    \n",
      "    sens = (1.0*tp/(tp+fn))\n",
      "    spec = (1.0*tn/(tn+fp))\n",
      "    \n",
      "    #print confusion\n",
      "    #print\n",
      "    #prittp, fp, fn, tn, sens, spec\n",
      "    #print 'Sensitiviy: ', sens, '\\nSpecificity: ', spec\n",
      "    return sens, spec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Split Data!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_train_valid_test(data_combined, labels_combined, icu_combined, age_combined, split=[0.6, 0.2]):\n",
      "    \n",
      "    ind = np.arange(0, len(labels_combined))\n",
      "    np.random.shuffle(ind)\n",
      "    \n",
      "    N = len(ind)\n",
      "    N_train = int(split[0] * N)\n",
      "    N_valid = int((split[1]+split[0]) * N)\n",
      "    \n",
      "    ind_train = ind[:N_train]\n",
      "    ind_valid = ind[N_train:N_valid]\n",
      "    ind_test = ind[N_valid:]\n",
      "    \n",
      "    data_combined = np.array(data_combined)\n",
      "    labels_combined = np.array(labels_combined)\n",
      "    \n",
      "    data_train = data_combined[ind_train]\n",
      "    labels_train = labels_combined[ind_train]\n",
      "    age_train = age_combined[ind_train]\n",
      "    icu_train = icu_combined[ind_train]\n",
      "    \n",
      "    age_valid = age_combined[ind_valid]\n",
      "    icu_valid = icu_combined[ind_valid]\n",
      "    labels_valid = labels_combined[ind_valid]\n",
      "    data_valid = data_combined[ind_valid]\n",
      "\n",
      "    age_test = age_combined[ind_test]\n",
      "    icu_test = icu_combined[ind_test]\n",
      "    labels_test = labels_combined[ind_test]\n",
      "    data_test = data_combined[ind_test]\n",
      "    \n",
      "    return [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "            #ind_train, ind_valid, ind_test]\n",
      "            icu_train, icu_valid, icu_test,\n",
      "            age_train, age_valid, age_test, ind_train, ind_valid, ind_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Separate dead and alive in train and validation sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def separate_living_dead(data, labels):\n",
      "    data_living = data[labels == 0]\n",
      "    data_dead = data[labels == 1]\n",
      "    return [data_living, data_dead]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Find number of dead and alive patients in train and validation sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sizes(data_living, data_dead):\n",
      "    n_dead = data_dead.shape[0]\n",
      "    n_living = data_living.shape[0]\n",
      "    n_combined = n_dead + n_living\n",
      "    \n",
      "    return n_dead, n_living, n_combined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GET DATA!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data(patient_combined, labels_combined, age_combined, icu_combined, n_windows, stats, split, time=None):\n",
      "    ### Generate windowed data\n",
      "    data_windows_combined = get_rows_data(patient_combined, n_windows, stats, time)\n",
      "    #data_windows_combined = np.hstack((data_windows_combined, age_combined))\n",
      "\n",
      "    print data_windows_combined.shape\n",
      "    ### split into train and validation sets, living and dead\n",
      "    [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "     icu_train, icu_valid, icu_test,\n",
      "     age_train, age_valid, age_test, ind_train, ind_valid, ind_test] = split_train_valid_test(data_windows_combined,\n",
      "     #ind_train, ind_valid, ind_test] = split_train_valid_test(data_windows_combined,\n",
      "                                                                         labels_combined, icu_combined,\n",
      "                                                                         age_combined, split=split)\n",
      "    \n",
      "    print data_train.shape\n",
      "    [data_train_living, data_train_dead] = separate_living_dead(data_train, labels_train)\n",
      "    [data_valid_living, data_valid_dead] = separate_living_dead(data_valid, labels_valid)\n",
      "    [data_test_living, data_test_dead] = separate_living_dead(data_test, labels_test)\n",
      "    \n",
      "    [age_train_living, age_train_dead] = separate_living_dead(age_train, labels_train)\n",
      "    [age_valid_living, age_valid_dead] = separate_living_dead(age_valid, labels_valid)\n",
      "    [age_test_living, age_test_dead] = separate_living_dead(age_test, labels_test)\n",
      "    [icu_train_living, icu_train_dead] = separate_living_dead(icu_train, labels_train)\n",
      "    [icu_valid_living, icu_valid_dead] = separate_living_dead(icu_valid, labels_valid)\n",
      "    [icu_test_living, icu_test_dead] = separate_living_dead(icu_test, labels_test)\n",
      "    \n",
      "    labels_train = labels_train.reshape((labels_train.shape[0], 1))\n",
      "    labels_valid = labels_valid.reshape((labels_valid.shape[0], 1))\n",
      "    labels_test = labels_test.reshape((labels_test.shape[0], 1))\n",
      "    \n",
      "    print data_train.shape\n",
      "    n_train_dead, n_train_living, n_train_combined = get_sizes(data_train_living, data_train_dead)\n",
      "    n_valid_dead, n_valid_living, n_valid_combined = get_sizes(data_valid_living, data_valid_dead)\n",
      "    n_test_dead, n_test_living, n_test_combined = get_sizes(data_test_living, data_test_dead)\n",
      "    \n",
      "    print 'Train:', n_train_dead, n_train_living, labels_train.shape[0]\n",
      "    print 'Valid:', n_valid_dead, n_valid_living, labels_valid.shape[0]\n",
      "    print 'Test:', n_test_dead, n_test_living, labels_test.shape[0]\n",
      "\n",
      "    ### Split into balacned sets!\n",
      "    n_train_splits = int (n_train_living / n_train_dead)\n",
      "    train_split = int (n_train_living / n_train_splits)\n",
      "    print 'Train Splits', n_train_splits, train_split, n_train_dead + n_train_splits * train_split, n_train_combined\n",
      "    print data_train.shape\n",
      "    print data_train[1].shape\n",
      "    \n",
      "    return [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "            data_train_living, data_train_dead, data_valid_living, data_valid_dead, data_test_living, data_test_dead,\n",
      "            age_train_living, age_train_dead, age_valid_living, age_valid_dead, age_test_living, age_test_dead,\n",
      "            icu_train_living, icu_train_dead, icu_valid_living, icu_valid_dead, icu_test_living, icu_test_dead,\n",
      "            train_split, ind_train, ind_valid, ind_test, n_train_splits, train_split]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Classify!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train balanced models!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_balanced(models, data_living, data_dead):\n",
      "    C_train = []\n",
      "    for i in xrange(n_train_splits):\n",
      "        # NO RANDOM SHUFFLE NOW!\n",
      "        data_bal = np.vstack((data_living[i * train_split: (i+1) * train_split, :],\n",
      "                              data_dead[:, :]) )\n",
      "        \n",
      "        label_bal = np.vstack((np.zeros((train_split, 1)),\n",
      "                               np.ones((data_dead.shape[0], 1))))\n",
      "\n",
      "        models[i].fit(data_bal, label_bal[:, 0])\n",
      "        C_train.append(confusion_matrix(label_bal[:,], models[i].predict(data_bal)))\n",
      "        \n",
      "    return C_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### GIVES THE SCORES OF EACH MODEL ON THE DATA\n",
      "def score_models(models, data_valid, labels_valid):\n",
      "    C_valid = []\n",
      "    for i in xrange(n_train_splits):\n",
      "        y = models[i].predict(data_valid)\n",
      "        C_valid.append(confusion_matrix(labels_valid[:], y))\n",
      "        #get_ss(C_valid[i])\n",
      "    return C_valid    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train GLM:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_proba(models_bal, data, sort=False):\n",
      "    probs = np.zeros((data.shape[0], len(models_bal)))\n",
      "        \n",
      "    probs = np.array([model.predict_proba(data)[:, 1] for model in models_bal]).T\n",
      "    if sort:\n",
      "        probs = np.sort(probs)\n",
      "    return probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def train_glm(models_bal, glm):\n",
      "   ##### find the probability estimates of each of the balanced models on the training set \n",
      "    \n",
      "    probs_train = get_proba(models_bal, data_train)\n",
      "    glm.fit(probs_train, labels_train)\n",
      "    \n",
      "    print 'Training data:'\n",
      "    get_ss(confusion_matrix(labels_train, glm.predict(probs_train)))\n",
      "    print 'Validation data:'\n",
      "    get_ss(confusion_matrix(labels_valid, glm.predict(get_proba(models_bal, data_valid))))"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Train glm and find threshold for max sens given specificity > 0.99"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_probit_reg(models, data, labels):\n",
      "    probs = get_proba(models, data)\n",
      "    pr = spreg.probit.Probit(y=labels, x=probs)\n",
      "    return pr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pr_probs(data, pr, models):\n",
      "    y_prob = norm.cdf(np.dot(np.hstack((np.ones((data.shape[0], 1)), \n",
      "                                        get_proba(models, data)\n",
      "                                        )\n",
      "                                       ), pr.betas\n",
      "                             )\n",
      "                      )\n",
      "    return y_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pr_prob_predictions(y_prob, theta):\n",
      "    return y_prob>theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## CHECK\n",
      "def get_pr_predictions(data, pr, theta_max, models):\n",
      "    y_prob = get_pr_probs(data, pr, models)\n",
      "    return get_pr_prob_predictions(y_prob, theta_max)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find theta that maximises the sens at 99% spec on (data, labels)\n",
      "def train_theta_max_sens(models, data, labels, pr=None, N=100, verbose=False):\n",
      "    sens = []\n",
      "    spec = []\n",
      "    theta_arr = []\n",
      "    if pr!=None:\n",
      "        y_prob = get_pr_probs(data, pr, models)\n",
      "    else:\n",
      "        y_prob = get_model_sum_probs(data, models)\n",
      "        \n",
      "    for t in xrange(1, N):\n",
      "        theta = t*(1.0 / (N-1))\n",
      "        if pr!= None:\n",
      "            y = get_pr_prob_predictions(y_prob, theta)\n",
      "        else:\n",
      "            y = get_model_prob_predictions(y_prob, theta)\n",
      "        \n",
      "        se, sp = get_ss(confusion_matrix(labels, y))\n",
      "        sens.append(se); spec.append(sp); theta_arr.append(theta)\n",
      "\n",
      "    sens = np.array(sens); spec = np.array(spec); theta_arr = np.array(theta_arr);\n",
      "    \n",
      "    # Check if atleast one has >0.99 spec and non zero sens\n",
      "    if (sens[spec>0.99] > 0).any():   # take max spec for which sens>0\n",
      "        ind = spec>0.99\n",
      "        max_ind = np.argmax(sens[ind]) # take max sens for spec>0.99\n",
      "    elif (sens>0).any():\n",
      "        ind = sens>0\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "    else:\n",
      "        ind = np.arange(spec.shape[0])\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        \n",
      "    sens_ = sens[ind][max_ind]\n",
      "    spec_ = spec[ind][max_ind]\n",
      "    theta = theta_arr[ind][max_ind]\n",
      "    \n",
      "    if verbose==True:\n",
      "        print sens, spec\n",
      "        \n",
      "    #print max_ind, sens_, spec_\n",
      "    #print sens[max_ind], spec[max_ind]\n",
      "    return theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 345
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Train glm using training data, and then return the performance on the validation set!\n",
      "def score_with_glm(models, data_train, labels_train, data_train_living, data_train_dead, data_valid, labels_valid, cols=None):\n",
      "    if cols == None:\n",
      "        cols = np.arange(data_train_living.shape[1])\n",
      "        \n",
      "    c_train = train_balanced(models, data_train_living[:, cols], data_train_dead[:, cols]) # train models on subsets of the training data\n",
      "    print '1'\n",
      "    probit_reg = train_probit_reg(models, data_train[:, cols], labels_train)      # Probit reg on all the training data\n",
      "    print '2'\n",
      "    theta_max = train_theta_max_sens(models, data_valid[:, cols], labels_valid,\n",
      "                                     probit_reg)                                # find Optimal theta ON THE VALIDATION SET\n",
      "    \n",
      "    print '3'\n",
      "    y_train = get_pr_predictions(data_train[:, cols], probit_reg, theta_max, models)\n",
      "    y_valid = get_pr_predictions(data_valid[:, cols], probit_reg, theta_max, models)\n",
      "    y_test = get_pr_predictions(data_test[:, cols], probit_reg, theta_max, models)\n",
      "    return [probit_reg, theta_max,\n",
      "            [get_ss(confusion_matrix(labels_train, y_train)),\n",
      "             get_ss(confusion_matrix(labels_valid, y_valid)),\n",
      "             get_ss(confusion_matrix(labels_test, y_test))]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Feature selection!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Get col name, window, stats\n",
      "def get_col_stat_window(c):\n",
      "    i = c % (n_features)\n",
      "    f = col_labs[i]\n",
      "    w = int(c / (n_features * len(stats)))\n",
      "    s = stats[int((c % (n_features * len(stats))) / (n_features))].func_name\n",
      "    \n",
      "    return i, f, s, w"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_str(col):\n",
      "    return '-'.join([str(x) for x in get_col_stat_window(col)[1:-1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Following functions for finding mean prediction with threshold (rather than glm)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_model_sum_probs(data, models):\n",
      "    prob_sum = np.zeros((data.shape[0], 2))\n",
      "    for m in models:\n",
      "        p = m.predict_proba(data)\n",
      "        prob_sum = prob_sum + p\n",
      "\n",
      "    return prob_sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_model_prob_predictions(prob_sum, theta):\n",
      "    y =  prob_sum[:, 1] - prob_sum[:, 0] > theta\n",
      "    return y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_model_mean_predictions(data, models, theta):\n",
      "    prob_sum = get_model_sum_probs(data, models)\n",
      "    return get_model_prob_predictions(prob_sum, theta)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Version with prediction on the validation set\n",
      "##### Train classifier by finding the mean probabilities, and return sens and spec\n",
      "def train_and_score_cols(models, cols, data_train_living=data_train_living,\n",
      "                         data_train_dead=data_train_dead, data_valid=data_valid, labels_valid=labels_valid):\n",
      "    \n",
      "    if cols==None:\n",
      "        cols = np.arange(data_train_living.shape[1])\n",
      "    train_balanced(models, data_train_living[:, cols], data_train_dead[:, cols]);\n",
      "    \n",
      "    theta_max = train_theta_max_sens(models, data_valid[:, cols], labels_valid, verbose=False)\n",
      "    y = get_model_mean_predictions(data_valid[:, cols], models, theta_max)\n",
      "    \n",
      "    se, sp = get_ss(confusion_matrix(labels_valid, y))\n",
      "    #print se, sp\n",
      "    return se, sp, theta_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get the column sensitivity and specificity scores\n",
      "def get_col_se_sp(models, data_train_living, data_train_dead, data_valid, labels_valid):\n",
      "    n = data_train_living.shape[1]\n",
      "    se = np.zeros((n,1))\n",
      "    sp = np.zeros((n,1))\n",
      "    \n",
      "    for i in xrange(n):\n",
      "        se[i], sp[i], t = train_and_score_cols(models, [i], data_train_living, data_train_dead, data_valid, labels_valid)\n",
      "    return se, sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## All feature+stats pairs, taken together to train the models\n",
      "def get_feature_stat_se_sp(models):\n",
      "    n = data_train_living.shape[1] / n_windows\n",
      "    se = np.zeros((n,1))\n",
      "    sp = np.zeros((n,1))\n",
      "    \n",
      "    for i in xrange(n):\n",
      "        cols = [i + j*n for j in xrange(n_windows)]\n",
      "        print cols\n",
      "        se[i], sp[i], t = train_and_score_cols(models, [i], data_train_living, data_train_dead, data_valid, labels_valid)\n",
      "    return se, sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Given cols in first window, train for all windows of that col\n",
      "def train_score_col_windows(models, cols):\n",
      "    n = data_train_living.shape[1] / n_windows\n",
      "    cols_all_windows = np.zeros((1, len(cols)*n_windows))\n",
      "    \n",
      "    for i in xrange(0, n_windows):\n",
      "        cols_all_windows[0, i*len(cols):(i+1)*len(cols)] = [j + i*n for j in cols]\n",
      "        \n",
      "    cols_ =  np.array(cols_all_windows[0, :], dtype=int).tolist()\n",
      "    print cols_\n",
      "    se, sp, t = train_and_score_cols(models, cols_, data_train_living, data_train_dead, data_valid, labels_valid)\n",
      "    return se, sp, t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GO ONLINE!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- get validation patients\n",
      "- get list of (all windows) of each patient\n",
      "- stack the windows up for whatever data you want to classify\n",
      "    - maintain an index to get back separate patients\n",
      "    - Classify windows\n",
      "- get back classifications for each patient separately\n",
      "- define \"some\" metric to classify the entire series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_stacked_windows_ind(list_of_window_arrays):\n",
      "    data_all_windows_stacked = np.vstack(list_of_window_arrays)\n",
      "    ind_all_windows_stacked = np.vstack([np.ones((x.shape[0], 1)) * i for i, x in enumerate(list_of_window_arrays) ])\n",
      "    return data_all_windows_stacked, ind_all_windows_stacked[:, 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Takes list of patient time series, and creates windows starting at zero\n",
      "def get_stacked_windows_from_ts(list_of_patient_ts, n_windows, stats, time=None, list_of_icu=None):\n",
      "    list_of_window_arrays = get_list_all_window_stats(list_of_patient_ts, n_windows, stats, time, list_of_icu)\n",
      "    data_all_windows_stacked, ind_all_windows_stacked = get_stacked_windows_ind(list_of_window_arrays)\n",
      "   \n",
      "    return data_all_windows_stacked, ind_all_windows_stacked"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def get_list_of_prediction_arrays(data, ind_stacked):\n",
      "    inds = np.unique(ind_stacked)\n",
      "    list_y_preds = [data[ind_stacked==i, :].copy() for i in inds]\n",
      "    return np.array(list_y_preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def view_series_random(list_y, n=10):\n",
      "    ind = np.arange(list_y.shape[0])\n",
      "    np.random.shuffle(ind)\n",
      "    for i, l in enumerate(list_y[ind[:n]]):\n",
      "        print i, l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# TS!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_in_inds(p):\n",
      "    if (ind_train==p).any():\n",
      "        print \"train\"\n",
      "    if (ind_valid==p).any():\n",
      "        print \"valid\"\n",
      "    if (ind_test==p).any():\n",
      "        print \"test\"\n",
      "def get_confusion_inds(labels, y):\n",
      "    ind_fn = np.array([((not y[i]) & (labels[i] != y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_fp = np.array([(y[i] & (labels[i] != y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_tp = np.array([(labels[i] & (labels[i] == y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_tn = np.array([((not labels[i]) & (labels[i] == y[i])) for i in xrange(labels.shape[0])])\n",
      "    return [ind_fp, ind_fn, ind_tp, ind_tn]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## FOR THE COMPLEX MODEL!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_probs_all_windows(list_of_time_series, n_windows, stats, models, time, list_of_val_series=None):\n",
      "    # Get stacked windows of all patients, and an ind of which patitent has which rows\n",
      "    data_windows_stacked, ind_windows_stacked = get_stacked_windows_from_ts(list_of_time_series, n_windows,\n",
      "                                                                            stats, time, list_of_val_series)\n",
      "    # Get probability estimates for all windows (of all patients) using the forests\n",
      "    dead_probs_stacked = get_proba(models, data_windows_stacked)\n",
      "    \n",
      "    # Append MEAN of all column predictions as a feature\n",
      "    dead_probs_stacked = np.hstack((dead_probs_stacked,\n",
      "                                    np.mean(dead_probs_stacked, axis=1).reshape(dead_probs_stacked.shape[0], 1)))\n",
      "    #dead_probs_stacked = np.mean(dead_probs_stacked, axis=1).reshape(dead_probs_stacked.shape[0], 1)\n",
      "    \n",
      "    # separate the probabilities paitient wise \n",
      "    list_probs = get_list_of_prediction_arrays(dead_probs_stacked, ind_windows_stacked)\n",
      "    return list_probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# takes in the probability matrix for the data, and threshold theta, returns final predictions, \n",
      "def get_unstacked_predictions_from_probs(y_prob_stacked, ind_stacked, theta):\n",
      "    y_pred_stacked = get_model_prob_predictions(y_prob_stacked, theta)\n",
      "    y_pred_stacked = y_pred_stacked.reshape((y_pred_stacked.shape[0], 1))\n",
      "    \n",
      "    list_y_preds = get_list_of_prediction_arrays(y_pred_stacked, ind_stacked)\n",
      "    y_any = np.array([(list_y_preds[i] == True).any() for i in xrange(list_y_preds.shape[0])])\n",
      "    return y_any, list_y_preds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 327
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find theta that maximises the sens at 99% spec on (data, labels)\n",
      "def train_theta_max_sens_stacked(y_prob, ind_stacked, labels, N=100, verbose=False):\n",
      "    sens = []; spec = []; theta_arr = []\n",
      "\n",
      "    for t in xrange(1, N):\n",
      "        theta = t*(1.0 / (N-1))\n",
      "        y, l = get_unstacked_predictions_from_probs(y_prob, ind_stacked, theta)\n",
      "        se, sp = get_ss(confusion_matrix(labels, y))\n",
      "        sens.append(se); spec.append(sp); theta_arr.append(theta)\n",
      "\n",
      "    sens = np.array(sens); spec = np.array(spec); theta_arr = np.array(theta_arr);\n",
      "    \n",
      "    # Check if atleast one has >0.99 spec and non zero sens\n",
      "    if (sens[spec>0.99] > 0).any():   # take max spec for which sens>0\n",
      "        ind = spec>0.99\n",
      "        max_ind = np.argmax(sens[ind]) # take max sens for spec>0.99\n",
      "    elif (sens>0).any():\n",
      "        ind = sens>0\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "    else:\n",
      "        ind = np.arange(spec.shape[0])\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        \n",
      "    sens_ = sens[ind][max_ind]\n",
      "    spec_ = spec[ind][max_ind]\n",
      "    theta = theta_arr[ind][max_ind]\n",
      "    \n",
      "    if verbose==True:\n",
      "        print sens, spec\n",
      "        \n",
      "    #print max_ind, sens_, spec_\n",
      "    #print sens[max_ind], spec[max_ind]\n",
      "    return theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 306
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def slope(X):\n",
      "    sl = np.zeros((X.shape[1],))\n",
      "    y = np.arange(X.shape[0])     # SHOULD BE TIME HERE\n",
      "    for i, x in enumerate(X.T):\n",
      "        A = np.vstack([x, np.ones(len(x))]).T\n",
      "        m, c = np.linalg.lstsq(A, y)[0]\n",
      "        #print m,c\n",
      "        sl[i] = m\n",
      "    return sl"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def slope(x, time_):\n",
      "    n = x.shape[0]; nc = x.shape[1]\n",
      "    \n",
      "    #sl = np.zeros((1,))\n",
      "    if time_ is None:\n",
      "        y = np.arange(n).reshape((n, 1))   # SHOULD BE TIMESTAMPS\n",
      "    else:\n",
      "        y = time_.reshape((time_.shape[0], 1))\n",
      "    \n",
      "    xy = np.sum(x*y, axis=0)\n",
      "    xm = np.mean(x, axis=0)\n",
      "    ym = np.mean(y, axis=0)\n",
      "    x2 = np.sum(x*x, axis=0)\n",
      "    \n",
      "    sl = 1.0*(xy - n*xm*ym) / (x2 - n*xm*xm)\n",
      "    sl[np.isnan(sl)] = 0\n",
      "    sl[np.isinf(sl)] = 0\n",
      "    return sl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Just return teh timestamp\n",
      "def get_prediction_timestamp(y_preds, patient_ts, time_ind, icu_ts):\n",
      "    if not (y_preds==1).any():\n",
      "        return -1\n",
      "    \n",
      "    times = patient_ts[:, time_ind]\n",
      "    icu = np.array(icu_ts, dtype=bool)\n",
      "    y = np.array(y_preds[:,0], dtype=bool)\n",
      "    \n",
      "    return times[icu][y][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For one patient, if no 1s, return -1\n",
      "def get_prediction_time(y_preds, patient_ts, time_ind, icu_ts):\n",
      "    if not (y_preds==1).any():\n",
      "        return -1\n",
      "    \n",
      "    times = patient_ts[:, time_ind]\n",
      "    icu = np.array(icu_ts, dtype=bool)\n",
      "    y = np.array(y_preds[:,0], dtype=bool)\n",
      "    \n",
      "    return (times[times.shape[0]-1] - times[icu][y][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_prediction_times_all_patients(list_y_preds, list_of_patients, time_ind, list_of_icu_times):\n",
      "    pred_times = [get_prediction_time(list_y_preds[i], list_of_patients[i], time_ind, list_of_icu_times[i]) for i in \n",
      "                  xrange(list_y_preds.shape[0])]\n",
      "    return np.array(pred_times)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# WORKSPACE!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Find the se and sp for all feature+stat pairs\n",
      "se_f, sp_f = get_feature_stat_se_sp(forests)\n",
      "## Find the se and sp for all feature+stat pairs\n",
      "se_s, sp_s = get_feature_stat_se_sp(svms)\n",
      "\n",
      "out = np.hstack((np.arange(se_f.shape[0]).reshape((se_f.shape[0], 1)), se_f, sp_f, np.abs(sp_f - se_f)))\n",
      "cols = [get_str(i) for i in np.array(out[:, 0], dtype=int)]\n",
      "\n",
      "df_feat = pd.DataFrame(data=out, columns=['ind', 'sens', 'spec', 'diff'])\n",
      "df_feat['name'] = cols\n",
      "\n",
      "# SAVE!\n",
      "\n",
      "pd.save(df_feat, '/root/code/xerox/windows/df_feat_forest')\n",
      "\n",
      "#################################################################\n",
      "\n",
      "### Features selected:\n",
      "- HDL Cholesterol - 91\n",
      "\n",
      "\n",
      "### Current scheme: ignore those features that lead to biased sens / spec\n",
      "- 18\n",
      "\n",
      "n = df_feat.ind.count()\n",
      "\n",
      "score_with_glm(forests, data_train, data_train_living, data_train_dead, data_valid, labels_valid,\n",
      "               cols = [i ofr i in xrange(18) if i not in [18]])\n",
      "\n",
      "train_score_col_windows(forests, [i for i in xrange(n) if i not in ind])\n",
      "\n",
      "get_cols_stat_se_sp(forests, [29, ])\n",
      "\n",
      "ind = df_feat[df_feat.ix[:, 'diff'] > 0.2].ind\n",
      "print [i for i in xrange(n) if i not in ind].append([1, 2])\n",
      "\n",
      "df_feat.sort(columns=['diff', 'spec'], ascending=False)   # Diff, sp\n",
      "df_feat\n",
      "df_feat.sort(columns=['sens', 'spec'], ascending=False)   # Sensitivity, sp\n",
      "df_feat.sort(columns=[ 'spec', 'sens'], ascending=False)   # Specifity, se\n",
      "\n",
      "### Dhruv's features!\n",
      "- las sys\n",
      "- llas dias\n",
      "\n",
      "- mean oxyge\n",
      "- max lac\n",
      "- max hr\n",
      "- sum bicarb\n",
      "- sum resp rate"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The bigger classifier!\n",
      "\n",
      "- training data row - stats of the entire ts\n",
      "- train random forests on the training data in parts\n",
      "- On the full training data\n",
      "    - use the rfs to get probs of each patient ts\n",
      "    - get stats of the probs\n",
      "    - classify the prob stats using non-linear model\n",
      "- On validation data:\n",
      "    - get windows starting from time 0\n",
      "    - classify each window using the learnt non-linear model\n",
      "    \n",
      "### Problems:\n",
      "- train - train data?\n",
      "- if valid data for nlm, less data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_combined = np.array(patient_combined)\n",
      "patient_combined = np.array(patient_combined)\n",
      "np.random.seed(132)\n",
      "\n",
      "### BIG FOREST PARAMS\n",
      "stats_big = [np.mean, np.var, np.min, np.max,\n",
      "             lambda x, axis:x[x.shape[0]-1],    # first element\n",
      "             lambda x, axis:x[0],               # last element\n",
      "             lambda x, time_: slope(x, time_)]          # slope of the window\n",
      "n_windows_big = 2\n",
      "\n",
      "### NOTE: If n<n_windows, ignored!\n",
      "n_windows = 2\n",
      "split = [0.60, 0.20]    # train%, validation%, (test%)\n",
      "#stats = [np.nanmean, np.nanmax , np.nanvar, np.nanmin, lambda x, axis:x.shape[0], lambda x, axis:x[x.shape[0]-1]]\n",
      "stats = [np.mean, np.var, np.min, np.max,\n",
      "         lambda x, axis:x[x.shape[0]-1],    # first element\n",
      "         lambda x, axis:x[0],               # last element\n",
      "         lambda x, time_: slope(x, time_)]          # slope of the window\n",
      "\n",
      "# Get the data from the patients\n",
      "[data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      " data_train_living, data_train_dead, data_valid_living, data_valid_dead, data_test_living, data_test_dead,\n",
      " icu_train_living, icu_train_dead, icu_valid_living, icu_valid_dead, icu_test_living, icu_test_dead,\n",
      " age_train_living, age_train_dead, age_valid_living, age_valid_dead, age_test_living, age_test_dead,\n",
      " train_split, ind_train, ind_valid, ind_test, n_train_splits, train_split] = get_data(patient_combined,\n",
      "                                                            labels_combined, age_combined,\n",
      "                                                            icu_combined, n_windows, stats, split, time=time_ind)\n",
      "\n",
      "patients_train = patient_combined[ind_train]\n",
      "patients_valid = patient_combined[ind_valid]\n",
      "patients_test = patient_combined[ind_test]    # Data_combined = patient_combined\n",
      "\n",
      "#icu_combined = icu_combined.reshape((icu_combined.shape[0],))\n",
      "age_combined = age_combined.reshape((age_combined.shape[0], 1))\n",
      "age_train = age_combined[ind_train]\n",
      "age_valid = age_combined[ind_valid]\n",
      "age_test = age_combined[ind_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3594, 434)\n",
        "(2156, 434)\n",
        "(2156, 434)\n",
        "Train: 149 2007 2156\n",
        "Valid: 54 665 719\n",
        "Test: 42 677 719\n",
        "Train Splits 13 154 2151 2156\n",
        "(2156, 434)\n",
        "(434,)\n"
       ]
      }
     ],
     "prompt_number": 342
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forests_final_1 = [RandomForestClassifier(n_estimators=300, class_weight=None, max_features=None,\n",
      "                                      n_jobs=-1, max_depth=None\n",
      "                                      ) for i in xrange(n_train_splits)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 343
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_and_score_cols(forests_final_1, None, data_train_living, data_train_dead, data_valid, labels_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 346,
       "text": [
        "(0.8888888888888888, 0.9278195488721804, 0.94949494949494961)"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_probs_train = get_probs_all_windows(patients_train, n_windows, stats, forests_final_1, time=time_ind)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###### INCLUDE ICU! Make ONE entry with the stats of all windows\n",
      "# Again, make n_windows_big windwows using the entire time series (n_train, n_windows_big * len(stats_big) * n_train_splits)\n",
      "train_prob_stats = get_rows_data(list_probs_train, n_windows_big, stats_big)\n",
      "#train_prob_stats =  np.hstack((train_prob_stats, age_train))   # Append the age column here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forest_big = RandomForestClassifier(n_estimators=300, class_weight={0:1, 1:0.01}, max_features=None,\n",
      "                                      n_jobs=-1, max_depth=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forest_big.fit(train_prob_stats, labels_train[:, 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### train a new ensemble of random forests, and \n",
      "train_prob_stats_living, train_prob_stats_dead = separate_living_dead(train_prob_stats, labels_train[:, 0])\n",
      "train_balanced(forests_big, train_prob_stats_living, train_prob_stats_living);"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## now train a threshold for controlling sensitivity and specificity on the validation set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get probs of only windows that are in the ICU for each patient\n",
      "list_probs = get_probs_all_windows(patients_valid, n_windows, stats, forests_final_1, time_ind, icu_combined[ind_valid])\n",
      "# Get rows (online) for each time series of probabilities\n",
      "prob_windows_stacked_val, ind_windows_stacked_val = get_stacked_windows_from_ts(list_probs, n_windows_big, stats_big)\n",
      "ind_windows_stacked_val = np.array(ind_windows_stacked_val, dtype=int)\n",
      "#prob_windows_stacked_val = np.hstack((prob_windows_stacked_val, age_valid[ind_windows_stacked_val])) # Stack AGE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_prob_stacked_val = forest_big.predict_proba(prob_windows_stacked_val)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "theta_max = train_theta_max_sens_stacked(y_prob_stacked_val, ind_stacked_val, labels_valid, verbose=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_any_valid, list_y_preds_val = get_unstacked_predictions_from_probs(y_prob_stacked_val, ind_windows_stacked_val, theta_max)\n",
      "get_ss((confusion_matrix(labels_valid, y_any_valid)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 339,
       "text": [
        "(0.35185185185185186, 0.98796992481203)"
       ]
      }
     ],
     "prompt_number": 339
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Prediction times"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = get_prediction_times_all_patients(list_y_preds_val, patients_valid, time_ind, icu_combined[ind_valid])\n",
      "print 'median:', np.median(l[l>0]/3600), ', min:', np.min(l[l>0]/3600)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "median: 47.0934722222 , min: 0.0447222222222\n"
       ]
      }
     ],
     "prompt_number": 340
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Get predictions for all windows (of probs) using the forest\n",
      "y_pred_stacked = forest_big.predict(prob_windows_stacked_val)\n",
      "y_pred_stacked = y_pred_stacked.reshape((y_pred_stacked.shape[0], 1))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "confusion_matrix(labels_valid, y_any_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 304,
       "text": [
        "array([[657,   8],\n",
        "       [ 35,  19]])"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print np.arange(y_any_valid.shape[0])[y_any_valid]  # all valid indices with at least one 1\n",
      "# find the indices at which 1 was predicted, and the label\n",
      "# i = 31\n",
      "#print np.arange(list_y_preds_val[i].shape[0])[list_y_preds_val[i][:, 0] == 1], labels_valid[i]\n",
      "#print labels_valid[y_any_valid != (l>0)]    # TRUE LABELS WHERE THE PREDICTION 1 WAS MADE AT TIME 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 312
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Testing\n",
      "\n",
      "- 0.6875, 0.923923923923924: 3, 3 windows, all stats in 2nd\n",
      "- (0.84, 0.8117529880478087): 1, 1 windows, max_features=28\n",
      "- (0.76, 0.853585657370518)): max_features=28, WITHOUT AGE, only in ICU\n",
      "- (0.7333333333333333, 0.8705179282868526): \", NO Age, Everywhere\n",
      "- 0.7733333333333333, 0.8077689243027888): \", with age, only in ICU"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## TEST DATA!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get probs of only windows that are in the ICU for each patient\n",
      "list_probs = get_probs_all_windows(patients_test, n_windows, stats, forests_final_1, time_ind, icu_combined[ind_test])\n",
      "# Get rows (online) for each time series of probabilities\n",
      "prob_windows_stacked_test, ind_windows_stacked_test = get_stacked_windows_from_ts(list_probs, n_windows_big, stats_big)\n",
      "ind_windows_stacked_test = np.array(ind_windows_stacked_test, dtype=int)\n",
      "#prob_windows_stacked_val = np.hstack((prob_windows_stacked_val, age_valid[ind_windows_stacked_val])) # Stack AGE\n",
      "y_prob_stacked_test = forest_big.predict_proba(prob_windows_stacked_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 325
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_any_test, list_y_preds_test = get_unstacked_predictions_from_probs(y_prob_stacked_test,\n",
      "                                                                     ind_windows_stacked_test, theta_max)\n",
      "get_ss((confusion_matrix(labels_test, y_any_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 335,
       "text": [
        "(0.2857142857142857, 0.9748892171344166)"
       ]
      }
     ],
     "prompt_number": 335
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l_test = get_prediction_times_all_patients(list_y_preds_test, patients_test, time_ind, icu_combined[ind_test])\n",
      "print 'median:', np.median(l_test[l_test>0]/3600), ', min:', np.min(l_test[l_test>0]/3600)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "median: 146.499722222 , min: 0.251388888889\n"
       ]
      }
     ],
     "prompt_number": 341
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## others"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# random run no age, only on icu,\n",
      "y_any_valid = np.array([(list_y_preds_val[i] == True).any() for i in xrange(list_y_preds_val.shape[0])])\n",
      "get_ss(confusion_matrix(labels_valid, y_any_valid))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1322,
       "text": [
        "(0.8309859154929577, 0.8630952380952381)"
       ]
      }
     ],
     "prompt_number": 1322
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_y_preds_val = get_list_of_prediction_arrays(y_prob_stacked, ind_windows_stacked_val)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 599
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "confusion_matrix(labels_valid, y_any_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 629,
       "text": [
        "array([[469, 198],\n",
        "       [  4,  48]])"
       ]
      }
     ],
     "prompt_number": 629
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ind_fp_val, ind_fn_val, ind_tp_val, ind_tn_val] = get_confusion_inds(labels_valid, y_any_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 603
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, p in enumerate(patients_valid[:10]):\n",
      "    if(ind_fp_val[i]):\n",
      "        patient_windows = get_all_window_stats(patients_valid[i], n_windows, stats, time=time_ind)\n",
      "        prob_mod = get_model_sum_probs(patient_windows, forests_final_1) / n_train_splits\n",
      "        #print get_pr_predictions(patient_windows, probit_reg, theta_max, forests_final)\n",
      "        #prob_reg = get_pr_probs(patient_windows, probit_reg, forests_final)\n",
      "        figure()\n",
      "        ylim([0, 1])\n",
      "        \n",
      "        plot(prob_mod[:, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x92QpDm/JRpOAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f47110ea690>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f470b678410>"
       ]
      }
     ],
     "prompt_number": 610
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## MISCLASSIFIED PATIENTS!\n",
      "l = np.array([x.shape[0] for x in patient_combined])\n",
      "l[[689, 694, 699, 695, 705, 715]]\n",
      "np.arange(3594)[argsort(l)==2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 934
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Things that did not work"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The one with glm\n",
      "\n",
      "forests_final = [RandomForestClassifier(n_estimators=300, class_weight=None, max_features=None,\n",
      "                                      n_jobs=-1, max_depth=None\n",
      "                                      ) for i in xrange(n_train_splits)]\n",
      "data_all_windows_stacked, ind_all_windows_stacked = get_stacked_windows_from_ts(patients_valid, n_windows, stats)\n",
      "[probit_reg, theta_max, s] = score_with_glm(forests_final, data_train, labels_train, data_train_living,\n",
      "                                            data_train_dead, data_valid, labels_valid, cols=None)\n",
      "y_pred_stacked = get_pr_predictions(data_all_windows_stacked, probit_reg, theta_max, forests_final)\n",
      "list_y_preds = get_list_of_prediction_arrays(y_pred_stacked, ind_all_windows_stacked)\n",
      "list_y_preds_dead = list_y_preds[labels_valid[:, 0] == 1]\n",
      "list_y_preds_alive = list_y_preds[labels_valid[:, 0] == 0]\n",
      "y_any_valid = np.array([(list_y_preds[i] == True).any() for i in xrange(list_y_preds.shape[0])])\n",
      "get_ss(confusion_matrix(labels_valid, y_any_valid))"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Weird svms combination\n",
      "svms = [svm.NuSVC(nu=0.10, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.10, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.10, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.10, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.10, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.10, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.10, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.5, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.9, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.8, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.8, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True),\n",
      "        svm.NuSVC(nu=0.8, kernel='poly', degree=2, gamma=10**(-1.7), coef0=100, probability=True)\n",
      "        ]\n",
      "c_train, c_valid = train_balanced(svms)\n",
      "probit_reg_svm, theta_max_svm = train_pr_max_sens(svms, data_train, labels_train)\n",
      "\n",
      "svms = [svm.NuSVC(nu=0.52, kernel='poly', degree=2, gamma=10**(-1.7), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.52, kernel='poly', degree=2, gamma=10**(-1.3), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.40, kernel='poly', degree=2, gamma=10**(-1.1), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.50, kernel='poly', degree=2, gamma=10**(-0.9), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.56, kernel='poly', degree=2, gamma=10**(-0.7), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.62, kernel='poly', degree=2, gamma=10**(-2), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.62, kernel='poly', degree=2, gamma=10**(-2), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.44, kernel='poly', degree=2, gamma=10**(-0.1), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.90, kernel='poly', degree=2, gamma=10**(-0.1), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.45, kernel='poly', degree=2, gamma=10**(-1.4), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.60, kernel='poly', degree=2, gamma=10**(-1.7), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.90, kernel='poly', degree=2, gamma=10**(-1.1), coef0=1, probability=True),\n",
      "        svm.NuSVC(nu=0.51, kernel='poly', degree=2, gamma=10**(-1.7), coef0=1, probability=True)\n",
      "        ]"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}