{
 "metadata": {
  "name": "",
  "signature": "sha256:d9f538ab5825db3a8379bd284ad8861a4bcc99b50e8a858168c83f0451be45c9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pysal\n",
      "from pysal import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 669
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import svm\n",
      "from sklearn.metrics import confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from math import *\n",
      "from scipy.stats import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import pandas\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import Series, DataFrame\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1449
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 368
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_age = pd.read_csv('data_train/id_age_train.csv')\n",
      "df_labels = pd.read_csv('data_train/id_label_train.csv')\n",
      "df_vitals = pd.read_csv('data_train/id_time_vitals_train.csv')\n",
      "df_labs = pd.read_csv('data_train/id_time_labs_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Normalize following the procedure in the paper\n",
      "\n",
      "#### Find the xL, xU, w1, w2, w3 vars"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_combined = df_vitals.drop('ICU', axis=1).copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_combined = df_combined.join(df_labs.drop(['ID', 'TIME'], axis=1))\n",
      "df_combined.drop(['ID', 'TIME'], axis=1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_features = 31"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_range = np.zeros((n_features, 2))\n",
      "W = np.zeros((n_features, 3))\n",
      "for i in xrange(n_features):\n",
      "#for i in xrange(1):\n",
      "    vals = df_combined.ix[df_combined.ix[:, i].notnull(), i]\n",
      "    vals = np.sort(vals)\n",
      "\n",
      "    # find the quantiles\n",
      "    N = vals.shape[0]\n",
      "    q = np.array([(j-0.5)/N for j in xrange(N)])\n",
      "    \n",
      "    i_l = np.min(np.arange(q.shape[0])[q>0.01])\n",
      "    i_u = np.max(np.arange(q.shape[0])[q<0.99])\n",
      "    \n",
      "    x_range[i, 0] = vals[i_l]\n",
      "    x_range[i, 1] = vals[i_u]\n",
      "\n",
      "    vals = vals[i_l: i_u+1]\n",
      "    q=norm.ppf(q[i_l: i_u+1]) / 3\n",
      "\n",
      "    X = np.ones((vals.shape[0], 3))\n",
      "    X[:, 1] = vals\n",
      "    X[:, 2] = np.log(1 + vals)\n",
      "\n",
      "    W[i, :] = np.dot(np.linalg.pinv(np.dot(X.T, X)),\n",
      "                     np.dot(X.T, q)\n",
      "                     )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print x_range[0], W[0], norm_transform(100, x_range[0], W[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "array([  77.,  184.])"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Process the entire data using this process"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# transform one element given range and W\n",
      "def norm_transform(x, x_range, W):\n",
      "    if(x<x_range[0]):\n",
      "        x=x_range[0]\n",
      "    if(x>x_range[1]):\n",
      "        x=x_range[1]\n",
      "        \n",
      "    return np.dot(W,\n",
      "                  [1, x, log(1+x)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_norm = df_combined.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(n_features):\n",
      "    df_norm.ix[:, i] = df_norm.ix[:, i].apply(lambda x:norm_transform(x, x_range[i], W[i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_norm[df_norm.isnull()] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_norm.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>V1</th>\n",
        "      <th>V2</th>\n",
        "      <th>V3</th>\n",
        "      <th>V4</th>\n",
        "      <th>V5</th>\n",
        "      <th>V6</th>\n",
        "      <th>L1</th>\n",
        "      <th>L2</th>\n",
        "      <th>L3</th>\n",
        "      <th>L4</th>\n",
        "      <th>...</th>\n",
        "      <th>L16</th>\n",
        "      <th>L17</th>\n",
        "      <th>L18</th>\n",
        "      <th>L19</th>\n",
        "      <th>L20</th>\n",
        "      <th>L21</th>\n",
        "      <th>L22</th>\n",
        "      <th>L23</th>\n",
        "      <th>L24</th>\n",
        "      <th>L25</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 423137.000000</td>\n",
        "      <td> 423038.000000</td>\n",
        "      <td> 455161.000000</td>\n",
        "      <td> 430491.000000</td>\n",
        "      <td> 435631.000000</td>\n",
        "      <td> 157943.000000</td>\n",
        "      <td> 12471.000000</td>\n",
        "      <td> 12790.000000</td>\n",
        "      <td> 12831.000000</td>\n",
        "      <td> 32719.000000</td>\n",
        "      <td>...</td>\n",
        "      <td> 4709.000000</td>\n",
        "      <td> 104.000000</td>\n",
        "      <td> 106199.000000</td>\n",
        "      <td> 1484.000000</td>\n",
        "      <td> 6330.000000</td>\n",
        "      <td> 13184.000000</td>\n",
        "      <td> 10879.000000</td>\n",
        "      <td> 5775.000000</td>\n",
        "      <td> 459.000000</td>\n",
        "      <td> 16990.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>     -0.000802</td>\n",
        "      <td>     -0.000518</td>\n",
        "      <td>      0.000193</td>\n",
        "      <td>      0.000262</td>\n",
        "      <td>     -0.003010</td>\n",
        "      <td>     -0.001436</td>\n",
        "      <td>     0.001861</td>\n",
        "      <td>    -0.001999</td>\n",
        "      <td>    -0.001785</td>\n",
        "      <td>    -0.000847</td>\n",
        "      <td>...</td>\n",
        "      <td>   -0.000726</td>\n",
        "      <td>  -0.004222</td>\n",
        "      <td>     -0.001889</td>\n",
        "      <td>   -0.002667</td>\n",
        "      <td>   -0.003260</td>\n",
        "      <td>    -0.000022</td>\n",
        "      <td>    -0.001577</td>\n",
        "      <td>   -0.001157</td>\n",
        "      <td>  -0.004562</td>\n",
        "      <td>    -0.000263</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>      0.327613</td>\n",
        "      <td>      0.328750</td>\n",
        "      <td>      0.326887</td>\n",
        "      <td>      0.328365</td>\n",
        "      <td>      0.310592</td>\n",
        "      <td>      0.335399</td>\n",
        "      <td>     0.326107</td>\n",
        "      <td>     0.332202</td>\n",
        "      <td>     0.323635</td>\n",
        "      <td>     0.338183</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.297590</td>\n",
        "      <td>   0.265866</td>\n",
        "      <td>      0.329994</td>\n",
        "      <td>    0.319238</td>\n",
        "      <td>    0.307946</td>\n",
        "      <td>     0.326704</td>\n",
        "      <td>     0.324033</td>\n",
        "      <td>    0.325643</td>\n",
        "      <td>   0.334086</td>\n",
        "      <td>     0.331819</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>     -0.823122</td>\n",
        "      <td>     -0.832645</td>\n",
        "      <td>     -0.757585</td>\n",
        "      <td>     -0.814802</td>\n",
        "      <td>     -0.693755</td>\n",
        "      <td>     -1.039356</td>\n",
        "      <td>    -0.699635</td>\n",
        "      <td>    -0.986676</td>\n",
        "      <td>    -0.803858</td>\n",
        "      <td>    -1.063083</td>\n",
        "      <td>...</td>\n",
        "      <td>   -0.378839</td>\n",
        "      <td>  -0.219519</td>\n",
        "      <td>     -0.926135</td>\n",
        "      <td>   -0.722979</td>\n",
        "      <td>   -0.801997</td>\n",
        "      <td>    -0.758326</td>\n",
        "      <td>    -0.783260</td>\n",
        "      <td>   -0.800160</td>\n",
        "      <td>  -0.946023</td>\n",
        "      <td>    -0.888026</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>     -0.232650</td>\n",
        "      <td>     -0.215903</td>\n",
        "      <td>     -0.234004</td>\n",
        "      <td>     -0.178394</td>\n",
        "      <td>     -0.242745</td>\n",
        "      <td>     -0.188750</td>\n",
        "      <td>    -0.220671</td>\n",
        "      <td>    -0.192651</td>\n",
        "      <td>    -0.187963</td>\n",
        "      <td>    -0.166365</td>\n",
        "      <td>...</td>\n",
        "      <td>   -0.224691</td>\n",
        "      <td>  -0.180796</td>\n",
        "      <td>     -0.216556</td>\n",
        "      <td>   -0.240028</td>\n",
        "      <td>   -0.177055</td>\n",
        "      <td>    -0.228905</td>\n",
        "      <td>    -0.223231</td>\n",
        "      <td>   -0.199659</td>\n",
        "      <td>  -0.195983</td>\n",
        "      <td>    -0.217783</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>     -0.007559</td>\n",
        "      <td>     -0.001985</td>\n",
        "      <td>     -0.003235</td>\n",
        "      <td>      0.019892</td>\n",
        "      <td>     -0.018887</td>\n",
        "      <td>      0.002622</td>\n",
        "      <td>     0.012262</td>\n",
        "      <td>    -0.005978</td>\n",
        "      <td>    -0.019656</td>\n",
        "      <td>    -0.008838</td>\n",
        "      <td>...</td>\n",
        "      <td>   -0.038657</td>\n",
        "      <td>  -0.121243</td>\n",
        "      <td>     -0.005452</td>\n",
        "      <td>   -0.033856</td>\n",
        "      <td>   -0.084112</td>\n",
        "      <td>     0.001487</td>\n",
        "      <td>    -0.017543</td>\n",
        "      <td>    0.017752</td>\n",
        "      <td>  -0.019236</td>\n",
        "      <td>    -0.007321</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>      0.229670</td>\n",
        "      <td>      0.213289</td>\n",
        "      <td>      0.218119</td>\n",
        "      <td>      0.191199</td>\n",
        "      <td>      0.245840</td>\n",
        "      <td>      0.181659</td>\n",
        "      <td>     0.223407</td>\n",
        "      <td>     0.195469</td>\n",
        "      <td>     0.200614</td>\n",
        "      <td>     0.184304</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.101068</td>\n",
        "      <td>   0.029716</td>\n",
        "      <td>      0.217963</td>\n",
        "      <td>    0.225265</td>\n",
        "      <td>    0.244771</td>\n",
        "      <td>     0.221762</td>\n",
        "      <td>     0.216481</td>\n",
        "      <td>    0.202394</td>\n",
        "      <td>   0.197205</td>\n",
        "      <td>     0.217760</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>      0.743244</td>\n",
        "      <td>      0.781180</td>\n",
        "      <td>      0.777265</td>\n",
        "      <td>      0.841406</td>\n",
        "      <td>      0.393024</td>\n",
        "      <td>      0.896911</td>\n",
        "      <td>     0.847445</td>\n",
        "      <td>     0.800909</td>\n",
        "      <td>     0.636214</td>\n",
        "      <td>     0.984638</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.723557</td>\n",
        "      <td>   0.758355</td>\n",
        "      <td>      0.738847</td>\n",
        "      <td>    0.642935</td>\n",
        "      <td>    0.495006</td>\n",
        "      <td>     0.767727</td>\n",
        "      <td>     0.659725</td>\n",
        "      <td>    0.731318</td>\n",
        "      <td>   0.895594</td>\n",
        "      <td>     0.872130</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 31 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "                  V1             V2             V3             V4  \\\n",
        "count  423137.000000  423038.000000  455161.000000  430491.000000   \n",
        "mean       -0.000802      -0.000518       0.000193       0.000262   \n",
        "std         0.327613       0.328750       0.326887       0.328365   \n",
        "min        -0.823122      -0.832645      -0.757585      -0.814802   \n",
        "25%        -0.232650      -0.215903      -0.234004      -0.178394   \n",
        "50%        -0.007559      -0.001985      -0.003235       0.019892   \n",
        "75%         0.229670       0.213289       0.218119       0.191199   \n",
        "max         0.743244       0.781180       0.777265       0.841406   \n",
        "\n",
        "                  V5             V6            L1            L2            L3  \\\n",
        "count  435631.000000  157943.000000  12471.000000  12790.000000  12831.000000   \n",
        "mean       -0.003010      -0.001436      0.001861     -0.001999     -0.001785   \n",
        "std         0.310592       0.335399      0.326107      0.332202      0.323635   \n",
        "min        -0.693755      -1.039356     -0.699635     -0.986676     -0.803858   \n",
        "25%        -0.242745      -0.188750     -0.220671     -0.192651     -0.187963   \n",
        "50%        -0.018887       0.002622      0.012262     -0.005978     -0.019656   \n",
        "75%         0.245840       0.181659      0.223407      0.195469      0.200614   \n",
        "max         0.393024       0.896911      0.847445      0.800909      0.636214   \n",
        "\n",
        "                 L4      ...               L16         L17            L18  \\\n",
        "count  32719.000000      ...       4709.000000  104.000000  106199.000000   \n",
        "mean      -0.000847      ...         -0.000726   -0.004222      -0.001889   \n",
        "std        0.338183      ...          0.297590    0.265866       0.329994   \n",
        "min       -1.063083      ...         -0.378839   -0.219519      -0.926135   \n",
        "25%       -0.166365      ...         -0.224691   -0.180796      -0.216556   \n",
        "50%       -0.008838      ...         -0.038657   -0.121243      -0.005452   \n",
        "75%        0.184304      ...          0.101068    0.029716       0.217963   \n",
        "max        0.984638      ...          0.723557    0.758355       0.738847   \n",
        "\n",
        "               L19          L20           L21           L22          L23  \\\n",
        "count  1484.000000  6330.000000  13184.000000  10879.000000  5775.000000   \n",
        "mean     -0.002667    -0.003260     -0.000022     -0.001577    -0.001157   \n",
        "std       0.319238     0.307946      0.326704      0.324033     0.325643   \n",
        "min      -0.722979    -0.801997     -0.758326     -0.783260    -0.800160   \n",
        "25%      -0.240028    -0.177055     -0.228905     -0.223231    -0.199659   \n",
        "50%      -0.033856    -0.084112      0.001487     -0.017543     0.017752   \n",
        "75%       0.225265     0.244771      0.221762      0.216481     0.202394   \n",
        "max       0.642935     0.495006      0.767727      0.659725     0.731318   \n",
        "\n",
        "              L24           L25  \n",
        "count  459.000000  16990.000000  \n",
        "mean    -0.004562     -0.000263  \n",
        "std      0.334086      0.331819  \n",
        "min     -0.946023     -0.888026  \n",
        "25%     -0.195983     -0.217783  \n",
        "50%     -0.019236     -0.007321  \n",
        "75%      0.197205      0.217760  \n",
        "max      0.895594      0.872130  \n",
        "\n",
        "[8 rows x 31 columns]"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(df_norm.V6.values, bins=50);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fbfa2eaf8d0>"
       ]
      }
     ],
     "prompt_number": 653
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df_norm\n",
      "\n",
      "patient_combined = [np.array(df.ix[df_vitals['ID'] == ID, :]) for ID in df_labels['ID'].unique()]\n",
      "\n",
      "# split into living and dead\n",
      "patient_combined_dead = [patient_combined[ID-1] for ID in df_labels['ID']\n",
      "                                                      if df_labels.ix[ID - 1, 'LABEL'] == 1]\n",
      "patient_combined_living = [patient_combined[ID-1] for ID in df_labels['ID']\n",
      "                                                      if df_labels.ix[ID - 1, 'LABEL'] == 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "age_combined = np.array(df_age.AGE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 852
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patient_combined_living[0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 855,
       "text": [
        "(1956, 31)"
       ]
      }
     ],
     "prompt_number": 855
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_n_windows(ts, n_windows, stats):\n",
      "    n_features = ts.shape[1]\n",
      "    l = np.zeros((n_windows, len(stats) * n_features))\n",
      "    \n",
      "    n = int(ts.shape[0] / n_windows)\n",
      "    for j in xrange(0, n_windows):\n",
      "        if (j==n_windows-1):\n",
      "            window = ts[j*n :, :] \n",
      "        else:\n",
      "            window = ts[j*n : (j+1)*n, :] \n",
      "    \n",
      "        for k in xrange(len(stats)):\n",
      "            f = stats[k]\n",
      "            l[j, k*n_features:(k+1)*n_features] = f(window, axis=0)\n",
      "    return l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_windows_data(data, n_windows, stats):\n",
      "    window_stats = []\n",
      "    for i in xrange(len(data)):\n",
      "        ts = data[i]\n",
      "\n",
      "        if(ts.shape[0] < n_windows):\n",
      "            #window_stats.append(None)    # We want to keep 1-1 mapping with patients..\n",
      "            n = int(np.ceil(1.0 * n_windows / ts.shape[0]))\n",
      "            t = np.zeros((ts.shape[0] * n, ts.shape[1]))\n",
      "            for i in xrange(ts.shape[0]):\n",
      "                for k in xrange(n):\n",
      "                    t[n*i + k, :] = ts[i, :]\n",
      "            \n",
      "            ts = t\n",
      "\n",
      "        l = get_n_windows(ts, n_windows, stats)\n",
      "        window_stats.append(l)\n",
      "        \n",
      "    return window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1047
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Given list of patient time series, give a matrix with one row for each patient containing all windows\n",
      "def get_rows_data(data, n_windows, stats):\n",
      "    data_windows = np.zeros((len(data), n_windows*data[0].shape[1]*len(stats)))\n",
      "    for i in xrange(len(data)):\n",
      "        ts = data[i]\n",
      "\n",
      "        if(ts.shape[0] < n_windows):\n",
      "            #window_stats.append(None)    # We want to keep 1-1 mapping with patients..\n",
      "            n = int(np.ceil(1.0 * n_windows / ts.shape[0]))\n",
      "            t = np.zeros((ts.shape[0] * n, ts.shape[1]))\n",
      "            for i in xrange(ts.shape[0]):\n",
      "                for k in xrange(n):\n",
      "                    t[n*i + k, :] = ts[i, :]\n",
      "            \n",
      "            ts = t\n",
      "            continue\n",
      "\n",
      "        l = get_n_windows(ts, n_windows, stats)\n",
      "        data_windows[i, :] = np.hstack(l)\n",
      "        \n",
      "    return data_windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1350
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## For ONLINE prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get windows starting with zero upto end for the time series 'ts'\n",
      "def get_online_windows(ts):\n",
      "    p_windows = np.array([ts[:i+1, :] for i in xrange(ts.shape[0])])\n",
      "    return p_windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1351
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get stats of a given ts for all possible windows starting with 1 element\n",
      "def get_all_window_stats(ts, n_windows, stats):\n",
      "    p_windows = get_online_windows(ts)\n",
      "    p_all_window_stats = get_rows_data(p_windows, n_windows, stats)\n",
      "    return p_all_window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1359
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Given a LIST of patient time series, give back a list of matrices\n",
      "def get_list_all_window_stats(data, n_windows, stats):\n",
      "    all_window_stats = []\n",
      "    for d in data:\n",
      "        all_window_stats.append(get_all_window_stats(d, n_windows, stats))\n",
      "    \n",
      "    return all_window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1398
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### For testing online ones!\n",
      "ts = patients_valid[0:2]\n",
      "ts[1].shape\n",
      "p_windows = get_online_windows(ts[1])\n",
      "p_windows[10].shape\n",
      "p_stats = get_all_window_stats(ts[1], n_windows, stats)\n",
      "p_stats.shape\n",
      "p_all = get_list_all_window_stats(ts, n_windows, stats)\n",
      "p_all[1].shape"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Confusion!\n",
      "def get_ss(confusion):\n",
      "    tn = confusion[0, 0]  # label=0, pred=0\n",
      "    fp = confusion[0, 1]  # label=0, pred=1\n",
      "    \n",
      "    fn = confusion[1, 0]  # label=1, pred=0\n",
      "    tp = confusion[1, 1]  # label=1, pred=1\n",
      "    \n",
      "    sens = (1.0*tp/(tp+fn))\n",
      "    spec = (1.0*tn/(tn+fp))\n",
      "    \n",
      "    #print confusion\n",
      "    #print\n",
      "    #prittp, fp, fn, tn, sens, spec\n",
      "    #print 'Sensitiviy: ', sens, '\\nSpecificity: ', spec\n",
      "    return sens, spec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1006
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Split Data!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_train_valid(data_combined, labels_combined, age_combined, split=0.8):\n",
      "    \n",
      "    ind = np.arange(0, len(labels_combined))\n",
      "    np.random.shuffle(ind)\n",
      "    \n",
      "    N = len(ind)\n",
      "    N_train = int(split * N)\n",
      "    \n",
      "    ind_train = ind[:N_train]\n",
      "    ind_valid = ind[N_train:]\n",
      "    \n",
      "    data_combined = np.array(data_combined)\n",
      "    labels_combined = np.array(labels_combined)\n",
      "    age_combined = np.array(age_combined)\n",
      "    \n",
      "    data_train = data_combined[ind_train]\n",
      "    labels_train = labels_combined[ind_train]\n",
      "    age_train = age_combined[ind_train]\n",
      "    \n",
      "    age_valid = age_combined[ind_valid]\n",
      "    labels_valid = labels_combined[ind_valid]\n",
      "    data_valid = data_combined[ind_valid]\n",
      "\n",
      "    \n",
      "    return data_train, labels_train, data_valid, labels_valid, age_train, age_valid, ind_train, ind_valid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1297
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Single forest on all the data\n",
      "forest = RandomForestClassifier(n_estimators=10000, max_depth=None, oob_score=False, n_jobs=-1)\n",
      "forest.fit(data_train, labels_train)\n",
      "get_ss(confusion_matrix(labels_valid, forest.predict(data_valid)))\n",
      "get_ss(confusion_matrix(labels_train, forest.predict(data_train)))"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Separate dead and alive in train and validation sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def separate_living_dead(data_train, labels_train, data_valid, labels_valid, age_train, age_valid):\n",
      "    data_train_living = data_train[labels_train == 0]\n",
      "    data_train_dead = data_train[labels_train == 1]\n",
      "    data_valid_living = data_valid[labels_valid == 0]\n",
      "    data_valid_dead = data_valid[labels_valid == 1]\n",
      "    \n",
      "    age_train_living = age_train[labels_train == 0]\n",
      "    age_train_dead = age_train[labels_train == 1]\n",
      "    age_valid_living = age_valid[labels_valid == 0]\n",
      "    age_valid_dead = age_valid[labels_valid == 1]\n",
      "    return [data_train_living, data_train_dead, data_valid_living, data_valid_dead,\n",
      "            age_train_living, age_train_dead, age_valid_living, age_valid_dead]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 861
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Find number of dead and alive patients in train and validation sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sizes(data_train_living, data_train_dead, data_valid_living, data_valid_dead):\n",
      "    n_train_dead = data_train_dead.shape[0]\n",
      "    n_train_living = data_train_living.shape[0]\n",
      "    n_train_combined = n_train_dead + n_train_living\n",
      "    n_valid_dead = data_valid_dead.shape[0]\n",
      "    n_valid_living = data_valid_living.shape[0]\n",
      "    n_valid_combined = n_valid_living + n_valid_dead\n",
      "    \n",
      "    return n_train_dead, n_train_living, n_train_combined, n_valid_dead, n_valid_living, n_valid_combined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 862
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GET DATA!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train_living.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 874,
       "text": [
        "(2674, 1395)"
       ]
      }
     ],
     "prompt_number": 874
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(patient_combined)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3594\n"
       ]
      }
     ],
     "prompt_number": 1258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data(patient_combined, labels_combined, age_combined, n_windows, stats, split):\n",
      "    ### Generate windowed data\n",
      "    data_windows_combined = get_rows_data(patient_combined, n_windows, stats)\n",
      "    #data_windows_combined = np.hstack((data_windows_combined, age_combined))\n",
      "\n",
      "    print data_windows_combined.shape\n",
      "    ### split into train and validation sets, living and dead\n",
      "    [data_train, labels_train, data_valid, labels_valid,\n",
      "         age_train, age_valid, ind_train, ind_valid] = split_train_valid(data_windows_combined,\n",
      "                                                                         labels_combined, age_combined, split=split)\n",
      "    \n",
      "    print data_train.shape\n",
      "    [data_train_living, data_train_dead, data_valid_living, data_valid_dead,\n",
      "         age_train_living, age_train_dead, age_valid_living, age_valid_dead] = separate_living_dead(data_train, labels_train,\n",
      "                                                                                                  data_valid, labels_valid,\n",
      "                                                                                                  age_train, age_valid)\n",
      "    print data_train.shape\n",
      "    [n_train_dead, n_train_living, n_train_combined, n_valid_dead, \n",
      "                         n_valid_living, n_valid_combined] = get_sizes(data_train_living, data_train_dead, \n",
      "                                                                       data_valid_living, data_valid_dead)\n",
      "    print 'Train:', n_train_dead, n_train_living, labels_train.shape[0]\n",
      "    print 'Valid:', n_valid_dead, n_valid_living, labels_valid.shape[0]\n",
      "\n",
      "    ### Split into balacned sets!\n",
      "    n_train_splits = int (n_train_living / n_train_dead)\n",
      "    train_split = int (n_train_living / n_train_splits)\n",
      "    print 'Train Splits', n_train_splits, train_split, n_train_dead + n_train_splits * train_split, n_train_combined\n",
      "    print data_train.shape\n",
      "    print data_train[1].shape\n",
      "    \n",
      "    return [data_train, labels_train, data_valid, labels_valid, data_train_living, data_train_dead,\n",
      "            data_valid_living, data_valid_dead, n_train_dead, n_train_living, n_train_combined, n_valid_dead,\n",
      "            n_valid_living, n_valid_combined, n_train_splits, train_split, age_train_living, age_train_dead,\n",
      "            age_valid_living, age_valid_dead]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1301
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Classify!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train balanced models!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_balanced(models):\n",
      "    C_train = []\n",
      "    C_valid = []\n",
      "    #y_valid = np.zeros((n_valid_combined, n_train_splits))\n",
      "    for i in xrange(n_train_splits):\n",
      "        # NO RANDOM SHUFFLE NOW!\n",
      "        data_bal = np.vstack((data_train_living[i * train_split: (i+1) * train_split, :],\n",
      "                              data_train_dead[:, :]) )\n",
      "        \n",
      "        label_bal = np.vstack((np.zeros((train_split, 1)),\n",
      "                               np.ones((n_train_dead, 1))))\n",
      "\n",
      "        models[i].fit(data_bal, label_bal[:, 0])\n",
      "\n",
      "        C_train.append(confusion_matrix(label_bal[:,], models[i].predict(data_bal)))\n",
      "        y = models[i].predict(data_valid)\n",
      "        C_valid.append(confusion_matrix(labels_valid[:], y))\n",
      "        #get_ss(C_valid[i])\n",
      "        \n",
      "    return C_train, C_valid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 995
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_proba(models_bal, data):\n",
      "    # Returns negative log probability of dying / ALL\n",
      "    \n",
      "    probs = np.zeros((data.shape[0], len(models_bal)))\n",
      "        \n",
      "    probs = np.array([model.predict_proba(data)[:, 1] for model in models_bal]).T\n",
      "    probs = np.sort(probs)\n",
      "    return probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1296
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_glm(models_bal, glm):\n",
      "   # find the probability estimates of each of the balanced models on the training set \n",
      "    \n",
      "    probs_train = get_proba(models_bal, data_train)\n",
      "    glm.fit(probs_train, labels_train)\n",
      "    \n",
      "    print 'Training data:'\n",
      "    get_ss(confusion_matrix(labels_train, glm.predict(probs_train)))\n",
      "    print 'Validation data:'\n",
      "    get_ss(confusion_matrix(labels_valid, glm.predict(get_proba(models_bal, data_valid))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 918
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_pr_max_sens(pr, data, labels):\n",
      "    probs = get_proba(models, data)\n",
      "    pr = spreg.probit.Probit(y=labels, x=probs)\n",
      "    N = 100\n",
      "    sens = []\n",
      "    spec = []\n",
      "    theta_arr = []\n",
      "    for t in xrange(1, N):\n",
      "        theta = t*(1.0 / (N-1))\n",
      "        y = pr.predy > theta\n",
      "        #print 'theta:', theta\n",
      "        se, sp = get_ss(confusion_matrix(labels, y))\n",
      "        sens.append(se)\n",
      "        spec.append(sp)\n",
      "        theta_arr.append(theta)\n",
      "        #print se, sp\n",
      "\n",
      "    sens = np.array(sens)\n",
      "    spec = np.array(spec)\n",
      "    max_ind = np.argmax(spec>0.99)\n",
      "    print sens[max_ind], spec[max_ind]\n",
      "    return pr, theta_arr[max_ind]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1463
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_combined = np.array(patient_combined)\n",
      "labels_combined = np.array(df_labels.LABEL)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1310
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(111)\n",
      "\n",
      "### NOTE: If n<n_windows, ignored!\n",
      "n_windows = 20\n",
      "stats = [np.nanmean, np.nanmin, np.nanmax]\n",
      "split = 0.8\n",
      "#stats = [np.nanmean, np.nanmin, np.nanmax, lambda x:x.shape[0]]\n",
      "\n",
      "# Get the data from the patients\n",
      "[data_train, labels_train, data_valid, labels_valid, data_train_living, data_train_dead,\n",
      " data_vaild_living, data_valid_dead, n_train_dead, n_train_living, n_train_combined, n_valid_dead,\n",
      " n_valid_living, n_valid_combined, n_train_splits, train_split, age_train_living, age_train_dead,\n",
      " age_valid_living, age_valid_dead] = get_data(patient_combined, labels_combined, age_combined,\n",
      "                                                                           n_windows, stats, split)\n",
      "\n",
      "labels_valid = np.reshape(labels_valid, (labels_valid.shape[0], 1))\n",
      "labels_train = np.reshape(labels_train, (labels_train.shape[0], 1))\n",
      "\n",
      "patients_train = data_combined[ind_train]\n",
      "patients_valid = data_combined[ind_valid]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3594, 1860)\n",
        "(2875, 1860)\n",
        "(2875, 1860)\n",
        "Train: 203 2672 2875\n",
        "Valid: 42 677 719\n",
        "Train Splits 13 205 2868 2875\n",
        "(2875, 1860)\n",
        "(1860,)\n"
       ]
      }
     ],
     "prompt_number": 1421
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Models for balanced training\n",
      "svms = [svm.NuSVC(kernel='poly', degree=2, gamma=10**(-1.7), probability=True) for i in xrange(n_train_splits)]\n",
      "forests = [RandomForestClassifier(n_estimators=300, class_weight=None, max_features=18,\n",
      "                                  n_jobs=-1, max_depth=None, random_state=14\n",
      "                                  ) for i in xrange(n_train_splits)]\n",
      "\n",
      "# GLMs\n",
      "glm = [LogisticRegression(), LogisticRegressionCV(), SGDClassifier()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1442
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred = norm.cdf(np.dot(np.hstack((np.ones((data_valid.shape[0], 1)), \n",
      "                          get_proba(forests, data_valid)))\n",
      "                          , pr.betas)) > theta_max_forest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1456
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_ss(confusion_matrix(labels_valid, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1457,
       "text": [
        "(0.8571428571428571, 0.9276218611521418)"
       ]
      }
     ],
     "prompt_number": 1457
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_train, c_valid = train_balanced(forests)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1444
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pr_predictions(pr, data):"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_train, c_valid = train_balanced(forests)\n",
      "pr, theta_max_forest = max_sens(forests, glm[0], data_train, labels_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "max_sens() takes exactly 3 arguments (4 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1438-64e8e495e99e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mc_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_balanced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta_max_forest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_sens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforests\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mTypeError\u001b[0m: max_sens() takes exactly 3 arguments (4 given)"
       ]
      }
     ],
     "prompt_number": 1438
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_glm_model(model, )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theta_max_forest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1413,
       "text": [
        "0.5454545454545455"
       ]
      }
     ],
     "prompt_number": 1413
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "0.809523809524 0.991137370753, 14\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=1276417875, splitter='best')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_train, c_valid = train_balanced(svms)\n",
      "theta_max_svm = max_sens(svms, data_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GO ONLINE!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Takes list of patient time series, and creates windows starting at zero, and then gives seq of predictions\n",
      "def get_pred_seqs(data, n_windows, stats):\n",
      "    data_all_windows = get_list_all_window_stats(data, n_windows, stats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1401
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_patient_pred_seq(patient_all_windows):\n",
      "    probs = get_proba(models, patient_all_windows)\n",
      "    pr = spreg.probit.Probit(y=labels_valid, x=probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_all_windows_valid = get_list_all_window_stats(patients_valid, n_windows, stats)\n",
      "print data_all_windows_valid[1].shape, len(data_all_windows_valid), patients_valid.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(37, 1860) (719,)\n"
       ]
      }
     ],
     "prompt_number": 1399
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}