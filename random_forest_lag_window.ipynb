{
 "metadata": {
  "name": "",
  "signature": "sha256:4f7ad419e28c488e3b3f0db56c10a324157f1f740c33943cc443825be420ed05"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "%reset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "col_labs =[\n",
      "\"Systolic Blood Pressure in mmHg\",\n",
      "\"Diastolic Blood Pressure in mmHg\", \n",
      "\"Heart Rate in bpm\", \n",
      "\"Respiration Rate in bpm\",\n",
      "\"Oxygen Saturation in %\",\n",
      "\"Temperature in Celsius\",\n",
      "\"Arterial blood PH in ph\",\n",
      "\"Partial Pressure of Carbon dioxide (PaCO2) in mmHg\",\n",
      "\"Partial Pressure of Oxygen (PaO2) in mmHg\",\n",
      "\"Sodium in mmol/L\",\n",
      "\"Potassium in mmol/L\",\n",
      "\"Bicarbonate in mmol/L\",\n",
      "\"Blood Urea Nitrogen in mg/dL\",\n",
      "\"Serum Creatinine in mg/dL\",\n",
      "\"WBC Count in x 103/\u00b5L\",\n",
      "\"Hematocrit %\",\n",
      "\"Platelet Count in x 103/\u00b5L\",\n",
      "\"Bilirubin in mg/dL\",\n",
      "\"Urine Output in ml\",\n",
      "\"LDL Cholesterol in mg/dL\",\n",
      "\"Lactic Acid in mmol/L\",\n",
      "\"Troponin I in ng/ml\",\n",
      "\"Troponin T in ng/ml\",\n",
      "\"Random Blood Glucose in mg/dL\",\n",
      "\"Fasting Blood Glucose in mg/dL\",\n",
      "\"Fraction of Inspired Oxygen (FiO2) in %\",\n",
      "\"Albumin in g/dl\",\n",
      "\"Alkaline Phosphatase in IU/L\",\n",
      "\"Alanine in IU/L\",\n",
      "\"HDL Cholesterol in mg/dL\",\n",
      "\"Magnesium in mg/dL\"]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pysal\n",
      "from pysal import *\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import svm\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from math import *\n",
      "from scipy.stats import *\n",
      "import re\n",
      "import pandas\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import Series, DataFrame\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.stats import norm\n",
      "from sklearn.linear_model import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(precision=5, suppress=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_labels = pd.read_csv('data_train/id_label_train.csv')\n",
      "df_vitals = pd.read_csv('data_train/id_time_vitals_train.csv')\n",
      "df_labs = pd.read_csv('data_train/id_time_labs_train.csv')\n",
      "df_age = pd.read_csv('data_train/id_age_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_df_combined(df_vitals, df_labs):\n",
      "    df_combined = df_vitals.drop('ICU', axis=1).copy()\n",
      "    df_combined = df_combined.join(df_labs.drop(['ID', 'TIME'], axis=1))\n",
      "    df_combined.drop(['ID', 'TIME'], axis=1, inplace=True)\n",
      "    ### Process the entire data using this process\n",
      "    return df_combined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def norm_transform(x, x_range, W):\n",
      "    if(x<x_range[0]):\n",
      "        x=x_range[0]\n",
      "    if(x>x_range[1]):\n",
      "        x=x_range[1]\n",
      "    return np.dot(W, [1, x, log(1+x)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_x_w(df_combined, n_features=31):\n",
      "    x_range = np.zeros((n_features, 2))\n",
      "    W = np.zeros((n_features, 3))\n",
      "    for i in xrange(n_features):\n",
      "    #for i in xrange(1):\n",
      "        vals = df_combined.ix[df_combined.ix[:, i].notnull(), i]\n",
      "        vals = np.sort(vals)\n",
      "\n",
      "        # find the quantiles\n",
      "        N = vals.shape[0]\n",
      "        q = np.array([(j-0.5)/N for j in xrange(N)])\n",
      "\n",
      "        i_l = np.min(np.arange(q.shape[0])[q>0.01])\n",
      "        i_u = np.max(np.arange(q.shape[0])[q<0.99])\n",
      "\n",
      "        x_range[i, 0] = vals[i_l]\n",
      "        x_range[i, 1] = vals[i_u]\n",
      "\n",
      "        vals = vals[i_l: i_u+1]\n",
      "        q=norm.ppf(q[i_l: i_u+1]) / 3\n",
      "\n",
      "        X = np.ones((vals.shape[0], 3))\n",
      "        X[:, 1] = vals\n",
      "        X[:, 2] = np.log(1 + vals)\n",
      "\n",
      "        W[i, :] = np.dot(np.linalg.pinv(np.dot(X.T, X)),\n",
      "                         np.dot(X.T, q)\n",
      "                         )\n",
      "    \n",
      "    return [x_range, W]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_norm_df(df_vitals, df_labs, x_range, W, path=None):\n",
      "    df_combined = get_df_combined(df_vitals, df_labs)\n",
      "    ### Normalize following the procedure in the paper\n",
      "    #### Find the xL, xU, w1, w2, w3 vars\n",
      "    # transform one element given range and W\n",
      "    df_norm = df_combined\n",
      "    for i in xrange(n_features):\n",
      "        df_norm.ix[:, i] = df_norm.ix[:, i].apply(lambda x:norm_transform(x, x_range[i], W[i]))\n",
      "    df_norm[df_norm.isnull()] = 0\n",
      "    \n",
      "    df_norm['TIME'] = df_vitals.TIME\n",
      "\n",
      "    if path is not None:\n",
      "        df_norm.to_csv(path=path)\n",
      "    return df_norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_norm_patients_from_df(df_vitals, df_labs, df_age, x_range, W, path=None):\n",
      "    df = get_norm_df(df_vitals, df_labs, x_range, W, path)\n",
      "    \n",
      "    patient_combined = [np.array(df.ix[df_vitals['ID'] == ID, :]) for ID in df_vitals['ID'].unique()]\n",
      "\n",
      "\n",
      "    age_combined = np.array(df_age.AGE)\n",
      "    icu_combined = np.array([np.array(df_vitals.ICU[df_vitals['ID']==i]) for i in df_vitals['ID'].unique()])\n",
      "    return [patient_combined, age_combined, icu_combined]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_patients_living_dead(patient_combined):\n",
      "    # split into living and dead\n",
      "    patient_combined_dead = [patient_combined[ID-1] for ID in df_age['ID']\n",
      "                                                          if df_labels.ix[ID - 1, 'LABEL'] == 1]\n",
      "    patient_combined_living = [patient_combined[ID-1] for ID in df_labels['ID']\n",
      "                                                          if df_labels.ix[ID - 1, 'LABEL'] == 0]\n",
      "    return [patient_combined_living, patient_combined_dead]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_combined = np.array(df_labels.LABEL)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Read the valus directly from the files\n",
      "#df_norm = get_norm_df()\n",
      "df_norm = pd.read_csv('/root/code/xerox/windows/svm_norm_data.csv')\n",
      "df_norm.drop(['Unnamed: 0'], axis=1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_features = 31"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_ind = 31"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_combined = get_df_combined(df_vitals, df_labs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_range, W = get_x_w(df_combined)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print x_range[0], W[0], norm_transform(100, x_range[0], W[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  77.  184.] [-9.50483 -0.00169  2.02252] -0.339251822373\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[patient_combined, age_combined, icu_combined] = get_norm_patients_from_df(df_vitals, df_labs,\n",
      "                                                         df_age, x_range, W, path=None)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Save the np arrays for speed and load from here\n",
      "np.save('/root/code/xerox/patient_combined_train', patient_combined)\n",
      "np.save('/root/code/xerox/age_combined_train', age_combined)\n",
      "np.save('/root/code/xerox/icu_combined_train', icu_combined)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Normalize the ages\n",
      "x_range_age, W_age = get_x_w(df_age, 2)\n",
      "x_range_age = x_range_age[1]; W_age = W_age[1, :];\n",
      "age_combined = np.array([norm_transform(x, x_range_age, W_age) for x in age_combined]).reshape((age_combined.shape[0], 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del df_norm, df_age, df_combined, df_labels, df_vitals, df_labs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Save the np arrays for speed and load from here\n",
      "patient_combined = np.load('/root/code/xerox/patient_combined_train.npy')\n",
      "age_combined = np.load('/root/code/xerox/age_combined_train.npy')\n",
      "icu_combined = np.load('/root/code/xerox/icu_combined_train.npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_combined = np.array(patient_combined)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_n_windows(ts, n_windows, stats, time_=None):\n",
      "    if time_ is not None:\n",
      "        cols = [i for i in np.arange(ts.shape[1]) if i != time_]\n",
      "        n_features = ts.shape[1] - 1\n",
      "    else:\n",
      "        cols = np.arange(ts.shape[1])\n",
      "        n_features = ts.shape[1]\n",
      "    \n",
      "    #print n_features\n",
      "    l = np.zeros((n_windows, len(stats) * n_features))\n",
      "    n = int(ts.shape[0] / n_windows)\n",
      "    \n",
      "    # get windows\n",
      "    for j in xrange(0, n_windows):\n",
      "        if (j==n_windows-1):\n",
      "            window = ts[j*n :, :] \n",
      "        else:\n",
      "            window = ts[j*n : (j+1)*n, :] \n",
      "\n",
      "        # apply stats to the window and append into a row\n",
      "        for k in xrange(len(stats)):\n",
      "            f = stats[k]\n",
      "            if f.func_name == '<lambda>':\n",
      "                if time_ is None:\n",
      "                    l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], None)\n",
      "                else:\n",
      "                    l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], window[:, time_])\n",
      "            else:\n",
      "                l[j, k*n_features:(k+1)*n_features] = f(window[:, cols], axis=0)\n",
      "    return l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Given list of patient time series, give a matrix with one row for each patient containing all windows\n",
      "def get_rows_data(data, n_windows, stats, time=None):\n",
      "    n_features = data[0].shape[1]\n",
      "    if time is not None:\n",
      "        n_features = n_features - 1\n",
      "    data_windows = np.zeros((len(data), n_windows*n_features*len(stats)))\n",
      "    for i in xrange(len(data)):\n",
      "        ts = data[i]\n",
      "\n",
      "        if(ts.shape[0] < n_windows):\n",
      "            #window_stats.append(None)    # We want to keep 1-1 mapping with patients..\n",
      "            n = int(np.ceil(1.0 * n_windows / ts.shape[0]))\n",
      "            t = np.zeros((ts.shape[0] * n, ts.shape[1]))\n",
      "            for i in xrange(ts.shape[0]):\n",
      "                for k in xrange(n):\n",
      "                    t[n*i + k, :] = ts[i, :]\n",
      "            \n",
      "            ts = t\n",
      "            continue\n",
      "\n",
      "        l = get_n_windows(ts, n_windows, stats, time)\n",
      "        data_windows[i, :] = np.hstack(l)\n",
      "        \n",
      "    return data_windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## For ONLINE prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get windows starting with zero upto end for the time series 'ts', ONLY for which icu=1 (If provided)\n",
      "def get_online_windows(ts, icu=None, window_size=None):\n",
      "    if window_size is None:\n",
      "        if icu is None:\n",
      "            p_windows = np.array([ts[:i+1, :] for i in xrange(ts.shape[0])])\n",
      "        else:   # inclue only if icu[i] == 1\n",
      "            p_windows = np.array([ts[:i+1, :] for i in xrange(ts.shape[0]) if icu[i]==1])\n",
      "    else:   # Taking sliding window of fixed size if window size is se\n",
      "        if icu is None:\n",
      "            p_windows = np.array([ts[max(i-window_size+1, 0):i+1, :] for i in xrange(ts.shape[0])])\n",
      "        else:   # inclue only if icu[i] == 1\n",
      "            p_windows = np.array([ts[max(i-window_size+1, 0):i+1, :] for i in xrange(ts.shape[0]) if icu[i]==1])\n",
      "    return p_windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_online_windows(np.array([[1], [2], [3], [4], [5]]), window_size=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "array([array([[1]]), array([[1],\n",
        "       [2]]),\n",
        "       array([[1],\n",
        "       [2],\n",
        "       [3]]),\n",
        "       array([[2],\n",
        "       [3],\n",
        "       [4]]),\n",
        "       array([[3],\n",
        "       [4],\n",
        "       [5]])], dtype=object)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class a:\n",
      "    icu_bias = False\n",
      "    icu = None\n",
      "    time = None\n",
      "    window_size = None\n",
      "    list_of_icu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 399
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a1.icu_bias = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 405
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a2.icu_bias"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 409,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 409
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a1 = a\n",
      "a2 = a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 402
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get stats of a given ts for all possible windows starting with 1 element\n",
      "def get_all_window_stats(ts, n_windows, stats, time=None, icu=None, window_size=None, icu_bias=False):\n",
      "    p_windows = get_online_windows(ts, icu, window_size=window_size)\n",
      "    p_all_window_stats = get_rows_data(p_windows, n_windows, stats, time, icu_bias=icu_bias)\n",
      "    return p_all_window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 397
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Given a LIST of patient time series, give back a list of matrices, one for each time series, where each row is a SLIDING window 0..i\n",
      "def get_list_all_window_stats(data, n_windows, stats, time=None, list_of_icu=None, window_size=None, icu_bias=False):\n",
      "    all_window_stats = []\n",
      "    for i, d in enumerate(data):\n",
      "        if list_of_icu is None:\n",
      "            all_window_stats.append(get_all_window_stats(d, n_windows, stats, time, window_size=window_size, icu_bias=icu_bias))\n",
      "        else:\n",
      "            all_window_stats.append(get_all_window_stats(d, n_windows, stats, time, list_of_icu[i],\n",
      "                                                         window_size=window_size, icu_bias=icu_bias))\n",
      "    \n",
      "    return all_window_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 394
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### For testing online ones!\n",
      "ts = patients_valid[0:2]\n",
      "ts[1].shape\n",
      "p_windows = get_online_windows(ts[1])\n",
      "p_windows[10].shape\n",
      "p_stats = get_all_window_stats(ts[1], n_windows, stats)\n",
      "p_stats.shape\n",
      "p_all = get_list_all_window_stats(ts, n_windows, stats)\n",
      "p_all[1].shape"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Confusion!\n",
      "def get_ss(confusion):\n",
      "    tn = confusion[0, 0]  # label=0, pred=0\n",
      "    fp = confusion[0, 1]  # label=0, pred=1\n",
      "    \n",
      "    fn = confusion[1, 0]  # label=1, pred=0\n",
      "    tp = confusion[1, 1]  # label=1, pred=1\n",
      "    \n",
      "    sens = (1.0*tp/(tp+fn))\n",
      "    spec = (1.0*tn/(tn+fp))\n",
      "    \n",
      "    #print confusion\n",
      "    #print\n",
      "    #prittp, fp, fn, tn, sens, spec\n",
      "    #print 'Sensitiviy: ', sens, '\\nSpecificity: ', spec\n",
      "    return sens, spec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Split Data!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_ind_split(N, split):\n",
      "    ind = np.arange(0, N)\n",
      "    np.random.shuffle(ind)\n",
      "    \n",
      "    N = len(ind)\n",
      "    N_train = int(split[0] * N)\n",
      "    N_valid = int((split[1]+split[0]) * N)\n",
      "    \n",
      "    ind_train = ind[:N_train]\n",
      "    ind_valid = ind[N_train:N_valid]\n",
      "    ind_test = ind[N_valid:]\n",
      "    \n",
      "    return [ind_train, ind_valid, ind_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_train_valid_test(data_combined, labels_combined, icu_combined, age_combined, split=[0.6, 0.2]):\n",
      "    \n",
      "    N = len(labels_combined)\n",
      "    ind_train, ind_valid, ind_test = get_ind_split(N, split)\n",
      "    \n",
      "    data_combined = np.array(data_combined)\n",
      "    labels_combined = np.array(labels_combined)\n",
      "    \n",
      "    data_train = data_combined[ind_train]\n",
      "    labels_train = labels_combined[ind_train]\n",
      "    age_train = age_combined[ind_train]\n",
      "    icu_train = icu_combined[ind_train]\n",
      "    \n",
      "    age_valid = age_combined[ind_valid]\n",
      "    icu_valid = icu_combined[ind_valid]\n",
      "    labels_valid = labels_combined[ind_valid]\n",
      "    data_valid = data_combined[ind_valid]\n",
      "\n",
      "    age_test = age_combined[ind_test]\n",
      "    icu_test = icu_combined[ind_test]\n",
      "    labels_test = labels_combined[ind_test]\n",
      "    data_test = data_combined[ind_test]\n",
      "    \n",
      "    return [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "            #ind_train, ind_valid, ind_test]\n",
      "            icu_train, icu_valid, icu_test,\n",
      "            age_train, age_valid, age_test, ind_train, ind_valid, ind_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Separate dead and alive in train and validation sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def separate_living_dead(data, labels):\n",
      "    data_living = data[labels == 0]\n",
      "    data_dead = data[labels == 1]\n",
      "    return [data_living, data_dead]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Find number of dead and alive patients in train and validation sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sizes(data_living, data_dead):\n",
      "    n_dead = data_dead.shape[0]\n",
      "    n_living = data_living.shape[0]\n",
      "    n_combined = n_dead + n_living\n",
      "    \n",
      "    return n_dead, n_living, n_combined"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GET DATA!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data(patient_combined, labels_combined, age_combined, icu_combined, n_windows, stats, split, time=None):\n",
      "    ### Generate windowed data\n",
      "    data_windows_combined = get_rows_data(patient_combined, n_windows, stats, time)\n",
      "    #data_windows_combined = np.hstack((data_windows_combined, age_combined))\n",
      "\n",
      "    print data_windows_combined.shape\n",
      "    ### split into train and validation sets, living and dead\n",
      "    [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "     icu_train, icu_valid, icu_test,\n",
      "     age_train, age_valid, age_test, ind_train, ind_valid, ind_test] = split_train_valid_test(data_windows_combined,\n",
      "     #ind_train, ind_valid, ind_test] = split_train_valid_test(data_windows_combined,\n",
      "                                                                         labels_combined, icu_combined,\n",
      "                                                                         age_combined, split=split)\n",
      "    \n",
      "    print data_train.shape\n",
      "    [data_train_living, data_train_dead] = separate_living_dead(data_train, labels_train)\n",
      "    [data_valid_living, data_valid_dead] = separate_living_dead(data_valid, labels_valid)\n",
      "    [data_test_living, data_test_dead] = separate_living_dead(data_test, labels_test)\n",
      "    \n",
      "    [age_train_living, age_train_dead] = separate_living_dead(age_train, labels_train)\n",
      "    [age_valid_living, age_valid_dead] = separate_living_dead(age_valid, labels_valid)\n",
      "    [age_test_living, age_test_dead] = separate_living_dead(age_test, labels_test)\n",
      "    [icu_train_living, icu_train_dead] = separate_living_dead(icu_train, labels_train)\n",
      "    [icu_valid_living, icu_valid_dead] = separate_living_dead(icu_valid, labels_valid)\n",
      "    [icu_test_living, icu_test_dead] = separate_living_dead(icu_test, labels_test)\n",
      "    \n",
      "    labels_train = labels_train.reshape((labels_train.shape[0], 1))\n",
      "    labels_valid = labels_valid.reshape((labels_valid.shape[0], 1))\n",
      "    labels_test = labels_test.reshape((labels_test.shape[0], 1))\n",
      "    \n",
      "    print data_train.shape\n",
      "    n_train_dead, n_train_living, n_train_combined = get_sizes(data_train_living, data_train_dead)\n",
      "    n_valid_dead, n_valid_living, n_valid_combined = get_sizes(data_valid_living, data_valid_dead)\n",
      "    n_test_dead, n_test_living, n_test_combined = get_sizes(data_test_living, data_test_dead)\n",
      "    \n",
      "    print 'Train:', n_train_dead, n_train_living, labels_train.shape[0]\n",
      "    print 'Valid:', n_valid_dead, n_valid_living, labels_valid.shape[0]\n",
      "    print 'Test:', n_test_dead, n_test_living, labels_test.shape[0]\n",
      "\n",
      "    ### Split into balacned sets!\n",
      "    n_train_splits = int (n_train_living / n_train_dead)\n",
      "    train_split = int (n_train_living / n_train_splits)\n",
      "    print 'Train Splits', n_train_splits, train_split, n_train_dead + n_train_splits * train_split, n_train_combined\n",
      "    print data_train.shape\n",
      "    print data_train[1].shape\n",
      "    \n",
      "    return [data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      "            data_train_living, data_train_dead, data_valid_living, data_valid_dead, data_test_living, data_test_dead,\n",
      "            age_train_living, age_train_dead, age_valid_living, age_valid_dead, age_test_living, age_test_dead,\n",
      "            icu_train_living, icu_train_dead, icu_valid_living, icu_valid_dead, icu_test_living, icu_test_dead,\n",
      "            train_split, ind_train, ind_valid, ind_test, n_train_splits, train_split]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Classify!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train balanced models!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_balanced(models, data, labels, verbose=True):\n",
      "    data_living, data_dead = separate_living_dead(data, labels[:, 0])\n",
      "    n_train_splits = len(models)\n",
      "    train_split = int(data_living.shape[0] / n_train_splits)\n",
      "    if verbose:\n",
      "        print n_train_splits, train_split, data_living.shape[0]\n",
      "        \n",
      "    C_train = []\n",
      "    for i in xrange(n_train_splits):\n",
      "        # NO RANDOM SHUFFLE NOW!\n",
      "        data_bal = np.vstack((data_living[i * train_split: (i+1) * train_split, :],\n",
      "                              data_dead[:, :]) )\n",
      "        \n",
      "        label_bal = np.vstack((np.zeros((train_split, 1)),\n",
      "                               np.ones((data_dead.shape[0], 1))))\n",
      "\n",
      "        models[i].fit(data_bal, label_bal[:, 0])\n",
      "        C_train.append(confusion_matrix(label_bal[:,], models[i].predict(data_bal)))\n",
      "        \n",
      "    return C_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### GIVES THE SCORES OF EACH MODEL ON THE DATA\n",
      "def score_models(models, data_valid, labels_valid):\n",
      "    C_valid = []\n",
      "    for i in xrange(n_train_splits):\n",
      "        y = models[i].predict(data_valid)\n",
      "        C_valid.append(confusion_matrix(labels_valid[:], y))\n",
      "        #get_ss(C_valid[i])\n",
      "    return C_valid    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_proba(models_bal, data, sort=False):\n",
      "    probs = np.zeros((data.shape[0], len(models_bal)))\n",
      "        \n",
      "    probs = np.array([model.predict_proba(data)[:, 1] for model in models_bal]).T\n",
      "    if sort:\n",
      "        probs = np.sort(probs)\n",
      "    return probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find theta that maximises the sens at 99% spec on (data, labels)\n",
      "def train_theta_max_sens(models, data, labels, pr=None, N=100, verbose=False):\n",
      "    sens = []\n",
      "    spec = []\n",
      "    theta_arr = []\n",
      "    if pr!=None:\n",
      "        y_prob = get_pr_probs(data, pr, models)\n",
      "    else:\n",
      "        y_prob = get_model_sum_probs(data, models)\n",
      "        \n",
      "    for t in xrange(1, N):\n",
      "        theta = t*(1.0 / (N-1))\n",
      "        if pr!= None:\n",
      "            y = get_pr_prob_predictions(y_prob, theta)\n",
      "        else:\n",
      "            y = get_model_prob_predictions(y_prob, theta)\n",
      "        \n",
      "        se, sp = get_ss(confusion_matrix(labels, y))\n",
      "        sens.append(se); spec.append(sp); theta_arr.append(theta)\n",
      "\n",
      "    sens = np.array(sens); spec = np.array(spec); theta_arr = np.array(theta_arr);\n",
      "    \n",
      "    # Check if atleast one has >0.99 spec and non zero sens\n",
      "    if (sens[spec>0.99] > 0).any():   # take max spec for which sens>0\n",
      "        ind = spec>0.99\n",
      "        max_ind = np.argmax(sens[ind]) # take max sens for spec>0.99\n",
      "    elif (sens>0).any():\n",
      "        ind = sens>0\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "    else:\n",
      "        ind = np.arange(spec.shape[0])\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        \n",
      "    sens_ = sens[ind][max_ind]\n",
      "    spec_ = spec[ind][max_ind]\n",
      "    theta = theta_arr[ind][max_ind]\n",
      "    \n",
      "    if verbose==True:\n",
      "        print sens, spec\n",
      "        \n",
      "    #print max_ind, sens_, spec_\n",
      "    #print sens[max_ind], spec[max_ind]\n",
      "    return theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Feature selection!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Get col name, window, stats\n",
      "def get_col_stat_window(c):\n",
      "    i = c % (n_features)\n",
      "    f = col_labs[i]\n",
      "    w = int(c / (n_features * len(stats)))\n",
      "    s = stats[int((c % (n_features * len(stats))) / (n_features))].func_name\n",
      "    \n",
      "    return i, f, s, w"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_str(col):\n",
      "    return '-'.join([str(x) for x in get_col_stat_window(col)[1:-1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Following functions for finding mean prediction with threshold (rather than glm)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## NAME IS MISLEADING, IT GIVES MEAN PROB!\n",
      "def get_model_sum_probs(data, models):\n",
      "    prob_sum = np.zeros((data.shape[0], 2))\n",
      "    for m in models:\n",
      "        p = m.predict_proba(data)\n",
      "        prob_sum = prob_sum + p\n",
      "    \n",
      "    prob_sum = prob_sum / len(models)\n",
      "\n",
      "    return prob_sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_model_prob_predictions(prob_sum, theta):\n",
      "    y =  prob_sum[:, 1] - prob_sum[:, 0] > theta\n",
      "    return y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_model_mean_predictions(data, models, theta, verbose=False):\n",
      "    prob_sum = get_model_sum_probs(data, models)\n",
      "    if verbose:\n",
      "        print prob_sum\n",
      "    return get_model_prob_predictions(prob_sum, theta)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train=None\n",
      "labels_train=None\n",
      "data_valid = None\n",
      "labels_valid=None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Version with prediction on the validation set\n",
      "##### Train classifier by finding the mean probabilities, and return sens and spec\n",
      "def train_and_score_cols(models, cols, data_train=data_train, labels_train=labels_train,\n",
      "                         data_valid=data_valid, labels_valid=labels_valid, verbose=False):\n",
      "    \n",
      "    data_train_living, data_train_dead = separate_living_dead(data_train, labels_train[:, 0])\n",
      "    \n",
      "    if cols==None:\n",
      "        cols = np.arange(data_train_living.shape[1])\n",
      "    #print cols\n",
      "    #print data_train_living.shape, data_train_dead.shape\n",
      "    print 'Training balanced..'\n",
      "    train_balanced(models, data_train[:, cols], labels_train);\n",
      "    \n",
      "    print 'Finding theta'\n",
      "    theta_max = train_theta_max_sens(models, data_valid[:, cols], labels_valid, verbose=verbose)\n",
      "    y = get_model_mean_predictions(data_valid[:, cols], models, theta_max, verbose=verbose)\n",
      "    \n",
      "    se, sp = get_ss(confusion_matrix(labels_valid, y))\n",
      "    #print se, sp\n",
      "    return se, sp, theta_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Get the column sensitivity and specificity scores\n",
      "def get_col_se_sp(models, data_train, data_valid, labels_valid):\n",
      "    n = data_train_living.shape[1]\n",
      "    se = np.zeros((n,1))\n",
      "    sp = np.zeros((n,1))\n",
      "    \n",
      "    for i in xrange(n):\n",
      "        se[i], sp[i], t = train_and_score_cols(models, [i], data_train, labels_train, data_valid, labels_valid)\n",
      "    return se, sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## All feature+stats pairs, taken together to train the models\n",
      "def get_feature_stat_se_sp(models, data_train, labels_train, data_valid, labels_valid):\n",
      "    n = data_train_living.shape[1] / n_windows\n",
      "    se = np.zeros((n,1))\n",
      "    sp = np.zeros((n,1))\n",
      "    \n",
      "    for i in xrange(n):\n",
      "        cols = [i + j*n for j in xrange(n_windows)]\n",
      "        print cols\n",
      "        se[i], sp[i], t = train_and_score_cols(models, [i], data_train, labels_train, data_valid, labels_valid)\n",
      "    return se, sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Given cols in first window, train for all windows of that col\n",
      "def train_score_col_windows(models, cols, verbose=False):\n",
      "    n = data_train_living.shape[1] / n_windows\n",
      "    cols_all_windows = np.zeros((1, len(cols)*n_windows))\n",
      "    \n",
      "    for i in xrange(0, n_windows):\n",
      "        cols_all_windows[0, i*len(cols):(i+1)*len(cols)] = [j + i*n for j in cols]\n",
      "        \n",
      "    cols_ =  np.array(cols_all_windows[0, :], dtype=int).tolist()\n",
      "    print cols_\n",
      "    se, sp, t = train_and_score_cols(models, cols_, data_train_living, data_train_dead, data_valid, labels_valid,\n",
      "                                     verbose)\n",
      "    return se, sp, t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_df(se_f, sp_f):\n",
      "    out = np.hstack((np.arange(se_f.shape[0]).reshape((se_f.shape[0], 1)), se_f, sp_f, np.abs(sp_f - se_f)))\n",
      "    cols = [get_str(i) for i in np.array(out[:, 0], dtype=int)]\n",
      "\n",
      "    df_feat = pd.DataFrame(data=out, columns=['ind', 'sens', 'spec', 'diff'])\n",
      "    df_feat['name'] = cols\n",
      "    return df_feat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GO ONLINE!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_stacked_windows_ind(list_of_window_arrays):\n",
      "    data_all_windows_stacked = np.vstack(list_of_window_arrays)\n",
      "    ind_all_windows_stacked = np.vstack([np.ones((x.shape[0], 1)) * i for i, x in enumerate(list_of_window_arrays) ])\n",
      "    return data_all_windows_stacked, ind_all_windows_stacked[:, 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- get validation patients\n",
      "- get list of (all windows) of each patient\n",
      "- stack the windows up for whatever data you want to classify\n",
      "    - maintain an index to get back separate patients\n",
      "    - Classify windows\n",
      "- get back classifications for each patient separately\n",
      "- define \"some\" metric to classify the entire series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Takes list of patient time series, and creates windows starting at zero\n",
      "def get_stacked_windows_from_ts(list_of_patient_ts, n_windows, stats, time=None, list_of_icu=None, cols=None,\n",
      "                                window_size=None, icu_bias=False):\n",
      "    list_of_window_arrays = get_list_all_window_stats(list_of_patient_ts, n_windows, stats, time, list_of_icu,\n",
      "                                                      window_size=window_size, icu_bias=icu_bias)\n",
      "    data_all_windows_stacked, ind_all_windows_stacked = get_stacked_windows_ind(list_of_window_arrays)\n",
      "    ind_all_windows_stacked = np.array(ind_all_windows_stacked, dtype=int)\n",
      "   \n",
      "    if cols is None:\n",
      "        return data_all_windows_stacked, ind_all_windows_stacked\n",
      "    else:\n",
      "        return data_all_windows_stacked[:, cols], ind_all_windows_stacked"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 384
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def get_list_of_prediction_arrays(data, ind_stacked):\n",
      "    inds = np.unique(ind_stacked)\n",
      "    list_y_preds = [data[ind_stacked==i, :].copy() for i in inds]\n",
      "    return np.array(list_y_preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 385
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def view_series_random(list_y, n=10):\n",
      "    ind = np.arange(list_y.shape[0])\n",
      "    np.random.shuffle(ind)\n",
      "    for i, l in enumerate(list_y[ind[:n]]):\n",
      "        print i, l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 386
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# TS!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_in_inds(p):\n",
      "    if (ind_train==p).any():\n",
      "        print \"train\"\n",
      "    if (ind_valid==p).any():\n",
      "        print \"valid\"\n",
      "    if (ind_test==p).any():\n",
      "        print \"test\"\n",
      "def get_confusion_inds(labels, y):\n",
      "    ind_fn = np.array([((not y[i]) & (labels[i] != y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_fp = np.array([(y[i] & (labels[i] != y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_tp = np.array([(labels[i] & (labels[i] == y[i])) for i in xrange(labels.shape[0])])\n",
      "    ind_tn = np.array([((not labels[i]) & (labels[i] == y[i])) for i in xrange(labels.shape[0])])\n",
      "    return [ind_fp, ind_fn, ind_tp, ind_tn]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 387
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## FOR THE COMPLEX MODEL!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_probs_all_windows(list_of_time_series, n_windows, stats, models, time, list_of_val_series=None, cols=None,\n",
      "                          window_size=None, icu_bias=False):\n",
      "    # Get stacked windows of all patients, and an ind of which patitent has which rows\n",
      "    data_windows_stacked, ind_windows_stacked = get_stacked_windows_from_ts(list_of_time_series, n_windows,\n",
      "                                                                            stats, time, list_of_val_series, cols,\n",
      "                                                                            window_size=window_size, icu_bias=icu_bias)\n",
      "    # Get probability estimates for all windows (of all patients) using the forests\n",
      "    dead_probs_stacked = get_proba(models, data_windows_stacked)\n",
      "    \n",
      "    # Append MEAN of all column predictions as a feature\n",
      "    dead_probs_stacked = np.hstack((dead_probs_stacked,\n",
      "                                    np.mean(dead_probs_stacked, axis=1).reshape(dead_probs_stacked.shape[0], 1)))\n",
      "    #dead_probs_stacked = np.mean(dead_probs_stacked, axis=1).reshape(dead_probs_stacked.shape[0], 1)\n",
      "    \n",
      "    # separate the probabilities paitient wise \n",
      "    list_probs = get_list_of_prediction_arrays(dead_probs_stacked, ind_windows_stacked)\n",
      "    return list_probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 388
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# takes in the probability matrix for the data, and threshold theta, returns final predictions, \n",
      "def get_unstacked_predictions_from_probs(y_prob_stacked, ind_stacked, theta):\n",
      "    y_pred_stacked = get_model_prob_predictions(y_prob_stacked, theta)\n",
      "    y_pred_stacked = y_pred_stacked.reshape((y_pred_stacked.shape[0], 1))\n",
      "    \n",
      "    list_y_preds = get_list_of_prediction_arrays(y_pred_stacked, ind_stacked)\n",
      "    y_any = np.array([(list_y_preds[i] == True).any() for i in xrange(list_y_preds.shape[0])])\n",
      "    return y_any, list_y_preds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 389
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# takes in the probability matrix for the data, and threshold theta, returns final predictions, \n",
      "def get_unstacked_predictions_from_probs_only_y(y_prob_stacked, ind_stacked, theta):\n",
      "    y_any, l = get_unstacked_predictions_from_probs(y_prob_stacked, ind_stacked, theta)\n",
      "    return y_any"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 390
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find theta that maximises the sens at 99% spec on (data, labels)\n",
      "def train_theta_max_sens_stacked(y_prob, labels, pred_func, ind_stacked=None, N=100, verbose=False, TH=0.99):\n",
      "    sens = []; spec = []; theta_arr = []\n",
      "\n",
      "    for t in xrange(1, N):\n",
      "        theta = t*(1.0 / (N-1))\n",
      "        if ind_stacked is None:\n",
      "            print 'sf'\n",
      "        else:\n",
      "            y = pred_func(y_prob, ind_stacked, theta)\n",
      "        se, sp = get_ss(confusion_matrix(labels, y))\n",
      "        sens.append(se); spec.append(sp); theta_arr.append(theta)\n",
      "\n",
      "    sens = np.array(sens); spec = np.array(spec); theta_arr = np.array(theta_arr);\n",
      "    \n",
      "    # Check if atleast one has >0.99 spec and non zero sens\n",
      "    print sens[spec>TH]\n",
      "    if (sens[spec>TH] > 0).any():   # take max spec for which sens>0\n",
      "        ind = spec>TH\n",
      "        max_ind = np.argmax(sens[ind]) # take max sens for spec>0.99\n",
      "        print '1'\n",
      "    elif (sens>0).any():\n",
      "        ind = sens>0\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        print '2'\n",
      "    else:\n",
      "        ind = np.arange(spec.shape[0])\n",
      "        max_ind = np.argmax(spec[ind])\n",
      "        print '3'\n",
      "        \n",
      "    sens_ = sens[ind][max_ind]\n",
      "    spec_ = spec[ind][max_ind]\n",
      "    theta = theta_arr[ind][max_ind]\n",
      "    \n",
      "    if verbose==True:\n",
      "        print sens, spec\n",
      "        \n",
      "    #print max_ind, sens_, spec_\n",
      "    #print sens[max_ind], spec[max_ind]\n",
      "    return theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 391
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def slope(X):\n",
      "    sl = np.zeros((X.shape[1],))\n",
      "    y = np.arange(X.shape[0])     # SHOULD BE TIME HERE\n",
      "    for i, x in enumerate(X.T):\n",
      "        A = np.vstack([x, np.ones(len(x))]).T\n",
      "        m, c = np.linalg.lstsq(A, y)[0]\n",
      "        #print m,c\n",
      "        sl[i] = m\n",
      "    return sl"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def slope(x, time_):\n",
      "    n = x.shape[0]; nc = x.shape[1]\n",
      "    \n",
      "    #sl = np.zeros((1,))\n",
      "    if time_ is None:\n",
      "        y = np.arange(n).reshape((n, 1))   # SHOULD BE TIMESTAMPS\n",
      "    else:\n",
      "        y = time_.reshape((time_.shape[0], 1))\n",
      "    \n",
      "    xy = np.sum(x*y, axis=0)\n",
      "    xm = np.mean(x, axis=0)\n",
      "    ym = np.mean(y, axis=0)\n",
      "    x2 = np.sum(x*x, axis=0)\n",
      "    \n",
      "    sl = 1.0*(xy - n*xm*ym) / (x2 - n*xm*xm)\n",
      "    sl[np.isnan(sl)] = 0\n",
      "    sl[np.isinf(sl)] = 0\n",
      "    return sl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Time"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Just return teh timestamp\n",
      "def get_prediction_timestamp(y_preds, patient_ts, time_ind, icu_ts):\n",
      "    if not (y_preds==1).any():\n",
      "        return -1\n",
      "    \n",
      "    times = patient_ts[:, time_ind]\n",
      "    icu = np.array(icu_ts, dtype=bool)\n",
      "    y = np.array(y_preds[:,0], dtype=bool)\n",
      "    \n",
      "    return times[icu][y][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For one patient, if no 1s, return -1\n",
      "def get_prediction_time(y_preds, patient_ts, time_ind, icu_ts):\n",
      "    if not (y_preds==1).any():\n",
      "        return -1\n",
      "    \n",
      "    times = patient_ts[:, time_ind]\n",
      "    icu = np.array(icu_ts, dtype=bool)\n",
      "    y = np.array(y_preds[:,0], dtype=bool)\n",
      "    \n",
      "    return (times[times.shape[0]-1] - times[icu][y][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 379
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_prediction_times_all_patients(list_y_preds, list_of_patients, time_ind, list_of_icu_times):\n",
      "    pred_times = [get_prediction_time(list_y_preds[i], list_of_patients[i], time_ind, list_of_icu_times[i]) for i in \n",
      "                  xrange(list_y_preds.shape[0])]\n",
      "    return np.array(pred_times)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 380
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_stacked_windows_labels_from_ts(list_of_patients, labels, n_windows, stats, time=None, list_of_icu=None,\n",
      "                                       cols=None, window_size=None, icu_bias=False):\n",
      "    windows_stacked, ind_windows_stacked = get_stacked_windows_from_ts(list_of_patients, n_windows,\n",
      "                                                                        stats, time=time, list_of_icu=list_of_icu,\n",
      "                                                                        #stats, time=time_ind, list_of_icu=None,\n",
      "                                                                        cols=cols, window_size=window_size, icu_bias=icu_bias)\n",
      "    labels_stacked = np.vstack([np.ones((np.sum(ind_windows_stacked==i), 1))*labels[i] for i in\n",
      "                                      np.unique(ind_windows_stacked)])\n",
      "    return windows_stacked, ind_windows_stacked, labels_stacked"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 381
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get list of strings denoting the type of classification\n",
      "def get_str_type(ind_fp, ind_tp, ind_fn, ind_tn):\n",
      "    l = []\n",
      "    for i in xrange(ind_fp.shape[0]):\n",
      "        if ind_fp[i]:\n",
      "            l.append('fp')\n",
      "        if ind_tn[i]:\n",
      "            l.append('tn')\n",
      "        if ind_fn[i]:\n",
      "            l.append('fn')\n",
      "        if ind_tp[i]:\n",
      "            l.append('tp')\n",
      "            \n",
      "    return l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 382
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# WORKSPACE!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "se_f, sp_f = get_feature_stat_se_sp(forests_final_1)\n",
      "\n",
      "#### Load /save\n",
      "pdf_feat_f = pd.load('/root/code/xerox/windows/df_feat_f')\n",
      "pdf_feat_c = pd.load('/root/code/xerox/windows/df_feat_c')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "se_f, sp_f = get_col_se_sp(forests_final_1, data_train_living, data_train_dead, data_valid, labels_valid)\n",
      "df_feat_f = get_df(se_f, sp_f)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Load /save\n",
      "df_feat_f = pd.load('/root/code/xerox/windows/df_feat_f')\n",
      "### df_feat_c = pd.load('/root/code/xerox/windows/df_feat_c')\n",
      "\n",
      "### df_feat_f.save('/root/code/xerox/windows/df_leaf_f')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.max_rows', 200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "forests = [RandomForestClassifier(n_estimators=100, class_weight={0:1, 0:1}, max_features=1,\n",
      "                                      n_jobs=-1, max_depth=4\n",
      "                                      ) for i in xrange(n_train_splits)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "l = df_feat_f.sort(columns=['name', 'spec'], ascending=False).to_html()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "df_feat_f[150:200]\n",
      "df_feat_f.sort(columns=['spec', 'diff'], ascending=False)[100:150]   # Diff, sp\n",
      "df_feat_f\n",
      "df_feat_f.sort(columns=[ 'spec', 'sens'], ascending=False)[50:100]   # Specifity, se\n",
      "df_feat_f.sort(columns=['sens', 'spec'], ascending=False) #Sensitivity, sp\n",
      "df_feat_f.sort(columns=['name', 'spec'], ascending=False) #Sensitivity, sp\n",
      "df_feat_f.sort(columns=['diff', 'spec'], ascending=False)   # Diff, sp"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "df_feat_c\n",
      "df_feat_c.sort(columns=['diff', 'spec'], ascending=False)   # Diff, sp\n",
      "df_feat_c\n",
      "df_feat_c.sort(columns=['sens', 'spec'], ascending=False)   # Sensitivity, sp\n",
      "df_feat_c.sort(columns=[ 'spec', 'sens'], ascending=False)   # Specifity, se"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The bigger classifier!\n",
      "\n",
      "- get all SLIDING windows on the training data\n",
      "- label all windows depending on the patients label\n",
      "- train random forests on the sliding windows\n",
      "- training data row - stats of the entire ts\n",
      "- train random forests on the training data in parts\n",
      "- On the full training data\n",
      "    - use the rfs to get probs of each patient ts\n",
      "    - get stats of the probs\n",
      "    - classify the prob stats using non-linear model\n",
      "- On validation data:\n",
      "    - get windows starting from time 0\n",
      "    - classify each window using the learnt non-linear model\n",
      "    \n",
      "### Problems:\n",
      "- train - train data?\n",
      "- if valid data for nlm, less data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_combined = np.array(patient_combined)\n",
      "age_combined = age_combined.reshape((age_combined.shape[0], 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patient_combined = np.array(patient_combined)\n",
      "np.random.seed(2)\n",
      "\n",
      "### BIG FOREST PARAMS\n",
      "#stats_big = [np.mean, np.var, np.min, np.max,\n",
      "             #lambda x, axis:x[x.shape[0]-1],    # first element\n",
      "             #lambda x, axis:x[0],               # last element\n",
      "             #lambda x, time_: slope(x, time_)]  # slope of the window\n",
      "#n_windows_big = 1\n",
      "\n",
      "n_windows = 1\n",
      "split = [0.80, 0.20]    # train%, validation%, (test%)\n",
      "[ind_train, ind_valid, ind_test] = get_ind_split(age_combined.shape[0], split)\n",
      "\n",
      "#stats = [np.nanmean, np.nanmax , np.nanvar, np.nanmin, lambda x, axis:x.shape[0], lambda x, axis:x[x.shape[0]-1]]\n",
      "stats = [np.mean, np.var, np.min, np.max,\n",
      "         lambda x, axis:x[x.shape[0]-1],    # first element\n",
      "         lambda x, axis:x[0],               # last element\n",
      "         lambda x, time_: slope(x, time_)]          # slope of the window"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patients_train = patient_combined[ind_train]\n",
      "patients_valid = patient_combined[ind_valid]\n",
      "patients_test = patient_combined[ind_test]    # Data_combined = patient_combined\n",
      "\n",
      "print patients_train.shape, patients_valid.shape, patients_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2875,) (719,) (0,)\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Get the data from the patients\n",
      "[data_train, labels_train, data_valid, labels_valid, data_test, labels_test,\n",
      " data_train_living, data_train_dead, data_valid_living, data_valid_dead, data_test_living, data_test_dead,\n",
      " icu_train_living, icu_train_dead, icu_valid_living, icu_valid_dead, icu_test_living, icu_test_dead,\n",
      " age_train_living, age_train_dead, age_valid_living, age_valid_dead, age_test_living, age_test_dead,\n",
      " train_split, ind_train, ind_valid, ind_test, n_train_splits, train_split] = get_data(patient_combined,\n",
      "                                                            labels_combined, age_combined,\n",
      "                                                            icu_combined, n_windows, stats, split, time=time_ind)\n",
      "\n",
      "\n",
      "###icu_combined = icu_combined.reshape((icu_combined.shape[0],))\n",
      "age_train = age_combined[ind_train]\n",
      "age_valid = age_combined[ind_valid]\n",
      "age_test = age_combined[ind_test]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "window_size=10\n",
      "cols_feat = None\n",
      "#cols_feat = [63, 96, 62, 64, 65, 93, 94, 95, 67, 98, 66, 97]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# get stacked windows of all Training patients at all time stamps\n",
      "windows_stacked_train, ind_windows_stacked_train, labels_stacked_train = get_stacked_windows_labels_from_ts(patients_train,\n",
      "                        labels_combined[ind_train], n_windows, stats, time=time_ind,\n",
      "                        list_of_icu=icu_combined[ind_train], cols=cols_feat, window_size=window_size, icu_bias=True)\n",
      "np.save('/root/code/xerox/windows_stacked_train', windows_stacked_train)\n",
      "np.save('/root/code/xerox/labels_stacked_train', labels_stacked_train)\n",
      "np.save('/root/code/xerox/ind_stacked_train', ind_windows_stacked_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "get_stacked_windows_labels_from_ts() got an unexpected keyword argument 'icu_bias'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-377-0368b9475f2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m windows_stacked_train, ind_windows_stacked_train, labels_stacked_train = get_stacked_windows_labels_from_ts(patients_train,\n\u001b[0;32m      3\u001b[0m                         \u001b[0mlabels_combined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_windows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_ind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                         list_of_icu=icu_combined[ind_train], cols=cols_feat, window_size=window_size, icu_bias=True)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/root/code/xerox/windows_stacked_train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindows_stacked_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/root/code/xerox/labels_stacked_train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_stacked_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: get_stacked_windows_labels_from_ts() got an unexpected keyword argument 'icu_bias'"
       ]
      }
     ],
     "prompt_number": 377
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# no. of forests to use, depending on the ratio of living to dead windows found in the data\n",
      "n_train_splits = np.sum(labels_stacked_train==0) / np.sum(labels_stacked_train==1)\n",
      "forests_final_1 = [RandomForestClassifier(n_estimators=300, class_weight={0:1, 1:1}, max_features=5,\n",
      "                                      n_jobs=-1, max_depth=4) for i in xrange(n_train_splits)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train the set of forests on all the training windows\n",
      "train_balanced(forests_final_1, windows_stacked_train, labels_stacked_train, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6 58512 351077\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "[array([[47643, 10869],\n",
        "        [21029, 35131]]), array([[45761, 12751],\n",
        "        [20177, 35983]]), array([[44169, 14343],\n",
        "        [21042, 35118]]), array([[46724, 11788],\n",
        "        [21149, 35011]]), array([[45772, 12740],\n",
        "        [18563, 37597]]), array([[43800, 14712],\n",
        "        [20716, 35444]])]"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "windows_stacked_train = np.load('/root/code/xerox/windows_stacked_train.npy')\n",
      "probs_stacked_train = get_proba(forests_final_1, windows_stacked_train)\n",
      "del windows_stacked_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print probs_stacked_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.48498  0.46049  0.50842  0.44092  0.42579  0.44344]\n",
        " [ 0.47088  0.44481  0.48767  0.44149  0.41287  0.43856]\n",
        " [ 0.45122  0.44312  0.45794  0.43748  0.40663  0.44248]\n",
        " ..., \n",
        " [ 0.42204  0.36027  0.36984  0.38829  0.3409   0.37368]\n",
        " [ 0.40187  0.34247  0.35659  0.37391  0.324    0.35655]\n",
        " [ 0.47857  0.45925  0.4744   0.4451   0.45643  0.45324]]\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Big forest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind_windows_stacked_train = np.load('/root/code/xerox/ind_stacked_train.npy')\n",
      "probs_stacked_train = np.load('/root/code/xerox/probs_stacked_train.npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_stacked_train = np.hstack((probs_stacked_train, age_combined[ind_train][ind_windows_stacked_train]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print probs_stacked_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(407237, 7)\n"
       ]
      }
     ],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forest_big = RandomForestClassifier(n_estimators=100, class_weight={0:0.1428, 1:1}, max_features=n_train_splits,\n",
      "                                      n_jobs=-1, max_depth=None, bootstrap=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels_stacked_train = np.load('/root/code/xerox/labels_stacked_train.npy')\n",
      "forest_big.fit(probs_stacked_train, labels_stacked_train[:, 0])\n",
      "del labels_stacked_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 257
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "np.save('/root/code/xerox/probs_stacked_train', probs_stacked_train)\n",
      "del probs_stacked_train, ind_windows_stacked_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'ind_windows_stacked_train' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-136-30ecc53e7348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/root/code/xerox/probs_stacked_train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_stacked_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mprobs_stacked_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind_windows_stacked_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_stacked_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'ind_windows_stacked_train' is not defined"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get stacked windows of all Val patients for all time stamps\n",
      "windows_stacked_val, ind_windows_stacked_val, labels_stacked_val = get_stacked_windows_labels_from_ts(patients_valid,\n",
      "                        labels_combined[ind_valid], n_windows, stats, time=time_ind,\n",
      "                        list_of_icu=icu_combined[ind_valid], cols=cols_feat,\n",
      "                        window_size=window_size)\n",
      "np.save('/root/code/xerox/windows_stacked_val.npy', windows_stacked_val)\n",
      "np.save('/root/code/xerox/labels_stacked_val', labels_stacked_val)\n",
      "np.save('/root/code/xerox/ind_stacked_val', ind_windows_stacked_val)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "windows_stacked_val = np.load('/root/code/xerox/windows_stacked_val.npy')\n",
      "probs_stacked_val = get_proba(forests_final_1, windows_stacked_val)\n",
      "del windows_stacked_val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_stacked_val.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 260,
       "text": [
        "(101868, 7)"
       ]
      }
     ],
     "prompt_number": 260
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_stacked_val = np.hstack((probs_stacked_val, age_combined[ind_valid][ind_windows_stacked_val]))\n",
      "probs_stacked_val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 231
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "probs_big_val = forest_big.predict_proba(probs_stacked_val)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 263
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs_big_val[:1000, 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 264,
       "text": [
        "array([ 0.06,  0.14,  0.12,  0.1 ,  0.08,  0.01,  0.07,  0.06,  0.04,\n",
        "        0.  ,  0.03,  0.26,  0.16,  0.15,  0.17,  0.09,  0.07,  0.15,\n",
        "        0.19,  0.15,  0.09,  0.15,  0.1 ,  0.21,  0.13,  0.11,  0.29,\n",
        "        0.21,  0.22,  0.02,  0.21,  0.21,  0.17,  0.15,  0.01,  0.12,\n",
        "        0.15,  0.14,  0.19,  0.32,  0.18,  0.02,  0.1 ,  0.01,  0.04,\n",
        "        0.01,  0.07,  0.  ,  0.02,  0.01,  0.03,  0.01,  0.04,  0.07,\n",
        "        0.17,  0.08,  0.12,  0.1 ,  0.03,  0.05,  0.06,  0.04,  0.14,\n",
        "        0.15,  0.34,  0.31,  0.13,  0.05,  0.1 ,  0.09,  0.06,  0.05,\n",
        "        0.01,  0.14,  0.14,  0.07,  0.26,  0.  ,  0.03,  0.03,  0.16,\n",
        "        0.09,  0.08,  0.04,  0.05,  0.11,  0.08,  0.16,  0.06,  0.08,\n",
        "        0.12,  0.11,  0.  ,  0.07,  0.04,  0.  ,  0.05,  0.05,  0.01,\n",
        "        0.06,  0.08,  0.03,  0.04,  0.07,  0.06,  0.18,  0.01,  0.12,\n",
        "        0.01,  0.18,  0.05,  0.37,  0.14,  0.02,  0.02,  0.01,  0.02,\n",
        "        0.09,  0.  ,  0.  ,  0.07,  0.  ,  0.03,  0.02,  0.  ,  0.08,\n",
        "        0.02,  0.03,  0.01,  0.01,  0.02,  0.02,  0.01,  0.  ,  0.  ,\n",
        "        0.  ,  0.  ,  0.  ,  0.01,  0.  ,  0.  ,  0.  ,  0.04,  0.03,\n",
        "        0.  ,  0.  ,  0.05,  0.02,  0.03,  0.03,  0.05,  0.02,  0.01,\n",
        "        0.02,  0.14,  0.12,  0.04,  0.09,  0.12,  0.1 ,  0.04,  0.14,\n",
        "        0.07,  0.  ,  0.07,  0.  ,  0.08,  0.04,  0.04,  0.02,  0.01,\n",
        "        0.03,  0.04,  0.07,  0.01,  0.04,  0.05,  0.09,  0.11,  0.  ,\n",
        "        0.  ,  0.07,  0.04,  0.05,  0.05,  0.01,  0.  ,  0.  ,  0.  ,\n",
        "        0.  ,  0.01,  0.  ,  0.  ,  0.  ,  0.03,  0.  ,  0.09,  0.06,\n",
        "        0.01,  0.06,  0.11,  0.19,  0.07,  0.05,  0.06,  0.04,  0.03,\n",
        "        0.14,  0.04,  0.  ,  0.  ,  0.01,  0.  ,  0.  ,  0.01,  0.08,\n",
        "        0.  ,  0.  ,  0.01,  0.02,  0.04,  0.  ,  0.07,  0.01,  0.07,\n",
        "        0.03,  0.02,  0.03,  0.03,  0.01,  0.01,  0.05,  0.  ,  0.  ,\n",
        "        0.02,  0.04,  0.  ,  0.08,  0.02,  0.01,  0.  ,  0.03,  0.  ,\n",
        "        0.  ,  0.  ,  0.02,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
        "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.02,  0.05,  0.  ,\n",
        "        0.01,  0.01,  0.  ,  0.  ,  0.06,  0.02,  0.05,  0.02,  0.02,\n",
        "        0.02,  0.01,  0.  ,  0.01,  0.07,  0.08,  0.06,  0.03,  0.01,\n",
        "        0.01,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
        "        0.  ,  0.  ,  0.  ,  0.02,  0.02,  0.01,  0.04,  0.16,  0.03,\n",
        "        0.08,  0.02,  0.08,  0.06,  0.13,  0.07,  0.11,  0.05,  0.01,\n",
        "        0.04,  0.08,  0.02,  0.12,  0.33,  0.01,  0.01,  0.04,  0.05,\n",
        "        0.1 ,  0.06,  0.11,  0.01,  0.13,  0.09,  0.04,  0.02,  0.04,\n",
        "        0.02,  0.01,  0.01,  0.03,  0.01,  0.48,  0.45,  0.21,  0.38,\n",
        "        0.4 ,  0.53,  0.19,  0.19,  0.2 ,  0.25,  0.4 ,  0.39,  0.35,\n",
        "        0.32,  0.36,  0.27,  0.53,  0.41,  0.28,  0.42,  0.65,  0.37,\n",
        "        0.25,  0.39,  0.29,  0.12,  0.33,  0.5 ,  0.57,  0.4 ,  0.4 ,\n",
        "        0.35,  0.49,  0.36,  0.65,  0.32,  0.31,  0.56,  0.33,  0.44,\n",
        "        0.21,  0.13,  0.13,  0.29,  0.32,  0.48,  0.45,  0.26,  0.23,\n",
        "        0.17,  0.3 ,  0.35,  0.05,  0.09,  0.11,  0.2 ,  0.13,  0.06,\n",
        "        0.12,  0.07,  0.03,  0.04,  0.  ,  0.02,  0.04,  0.05,  0.09,\n",
        "        0.1 ,  0.03,  0.03,  0.14,  0.03,  0.04,  0.08,  0.03,  0.08,\n",
        "        0.05,  0.02,  0.07,  0.28,  0.18,  0.18,  0.52,  0.37,  0.4 ,\n",
        "        0.49,  0.4 ,  0.36,  0.3 ,  0.22,  0.48,  0.25,  0.38,  0.29,\n",
        "        0.17,  0.17,  0.15,  0.11,  0.26,  0.33,  0.36,  0.09,  0.24,\n",
        "        0.22,  0.28,  0.13,  0.17,  0.06,  0.07,  0.04,  0.08,  0.11,\n",
        "        0.02,  0.02,  0.17,  0.04,  0.23,  0.16,  0.13,  0.2 ,  0.24,\n",
        "        0.23,  0.34,  0.04,  0.1 ,  0.05,  0.03,  0.04,  0.03,  0.05,\n",
        "        0.14,  0.09,  0.07,  0.19,  0.08,  0.05,  0.3 ,  0.18,  0.37,\n",
        "        0.15,  0.19,  0.07,  0.11,  0.04,  0.08,  0.09,  0.05,  0.03,\n",
        "        0.1 ,  0.04,  0.  ,  0.01,  0.02,  0.05,  0.03,  0.04,  0.  ,\n",
        "        0.04,  0.05,  0.  ,  0.01,  0.06,  0.  ,  0.06,  0.07,  0.07,\n",
        "        0.03,  0.72,  0.94,  0.91,  0.73,  0.55,  0.58,  0.37,  0.31,\n",
        "        0.58,  0.42,  0.26,  0.64,  0.51,  0.82,  0.89,  0.91,  0.8 ,\n",
        "        0.49,  0.61,  0.85,  0.87,  0.49,  0.8 ,  0.8 ,  0.48,  0.63,\n",
        "        0.57,  0.75,  0.7 ,  0.44,  0.6 ,  0.35,  0.37,  0.21,  0.33,\n",
        "        0.6 ,  0.45,  0.23,  0.24,  0.29,  0.2 ,  0.22,  0.21,  0.11,\n",
        "        0.11,  0.17,  0.04,  0.23,  0.3 ,  0.29,  0.32,  0.42,  0.43,\n",
        "        0.89,  0.65,  0.74,  0.7 ,  0.66,  0.67,  0.54,  0.63,  0.47,\n",
        "        0.5 ,  0.13,  0.38,  0.33,  0.26,  0.42,  0.53,  0.54,  0.1 ,\n",
        "        0.29,  0.31,  0.26,  0.09,  0.17,  0.49,  0.03,  0.13,  0.06,\n",
        "        0.05,  0.11,  0.19,  0.12,  0.25,  0.1 ,  0.31,  0.47,  0.47,\n",
        "        0.33,  0.23,  0.32,  0.41,  0.28,  0.32,  0.17,  0.21,  0.4 ,\n",
        "        0.2 ,  0.33,  0.2 ,  0.44,  0.16,  0.17,  0.12,  0.11,  0.39,\n",
        "        0.1 ,  0.25,  0.35,  0.22,  0.11,  0.13,  0.29,  0.19,  0.29,\n",
        "        0.14,  0.23,  0.12,  0.23,  0.34,  0.51,  0.71,  0.31,  0.49,\n",
        "        0.16,  0.36,  0.27,  0.23,  0.35,  0.11,  0.21,  0.13,  0.39,\n",
        "        0.3 ,  0.19,  0.11,  0.13,  0.3 ,  0.18,  0.2 ,  0.2 ,  0.22,\n",
        "        0.28,  0.19,  0.23,  0.13,  0.1 ,  0.19,  0.17,  0.16,  0.04,\n",
        "        0.09,  0.08,  0.06,  0.01,  0.29,  0.26,  0.18,  0.15,  0.27,\n",
        "        0.32,  0.35,  0.21,  0.43,  0.29,  0.27,  0.35,  0.26,  0.3 ,\n",
        "        0.4 ,  0.32,  0.12,  0.26,  0.29,  0.28,  0.33,  0.61,  0.32,\n",
        "        0.56,  0.08,  0.38,  0.27,  0.17,  0.14,  0.22,  0.09,  0.27,\n",
        "        0.21,  0.14,  0.31,  0.27,  0.32,  0.16,  0.41,  0.33,  0.18,\n",
        "        0.06,  0.07,  0.12,  0.09,  0.05,  0.06,  0.06,  0.11,  0.11,\n",
        "        0.13,  0.02,  0.01,  0.03,  0.05,  0.03,  0.22,  0.13,  0.14,\n",
        "        0.06,  0.02,  0.16,  0.01,  0.03,  0.07,  0.02,  0.02,  0.02,\n",
        "        0.01,  0.06,  0.02,  0.04,  0.05,  0.01,  0.01,  0.01,  0.13,\n",
        "        0.04,  0.12,  0.03,  0.07,  0.18,  0.08,  0.11,  0.05,  0.16,\n",
        "        0.1 ,  0.19,  0.11,  0.01,  0.22,  0.07,  0.1 ,  0.2 ,  0.04,\n",
        "        0.03,  0.02,  0.04,  0.04,  0.06,  0.05,  0.04,  0.09,  0.08,\n",
        "        0.1 ,  0.03,  0.07,  0.02,  0.05,  0.05,  0.05,  0.1 ,  0.08,\n",
        "        0.2 ,  0.06,  0.01,  0.01,  0.06,  0.07,  0.19,  0.09,  0.05,\n",
        "        0.06,  0.04,  0.03,  0.12,  0.1 ,  0.09,  0.07,  0.06,  0.1 ,\n",
        "        0.17,  0.08,  0.15,  0.06,  0.13,  0.03,  0.17,  0.12,  0.12,\n",
        "        0.05,  0.04,  0.05,  0.04,  0.18,  0.09,  0.14,  0.06,  0.06,\n",
        "        0.25,  0.32,  0.06,  0.35,  0.25,  0.3 ,  0.34,  0.12,  0.27,\n",
        "        0.18,  0.46,  0.35,  0.19,  0.28,  0.28,  0.09,  0.36,  0.32,\n",
        "        0.02,  0.12,  0.17,  0.03,  0.27,  0.34,  0.12,  0.22,  0.14,\n",
        "        0.03,  0.15,  0.31,  0.07,  0.17,  0.08,  0.32,  0.1 ,  0.2 ,\n",
        "        0.29,  0.14,  0.23,  0.38,  0.25,  0.45,  0.32,  0.27,  0.36,\n",
        "        0.38,  0.23,  0.16,  0.08,  0.13,  0.18,  0.07,  0.02,  0.03,\n",
        "        0.04,  0.03,  0.21,  0.1 ,  0.07,  0.2 ,  0.09,  0.11,  0.28,\n",
        "        0.21,  0.14,  0.2 ,  0.1 ,  0.17,  0.27,  0.32,  0.14,  0.17,\n",
        "        0.19,  0.26,  0.19,  0.32,  0.27,  0.35,  0.12,  0.43,  0.51,\n",
        "        0.16,  0.27,  0.29,  0.32,  0.18,  0.25,  0.19,  0.26,  0.37,\n",
        "        0.27,  0.12,  0.34,  0.21,  0.21,  0.33,  0.33,  0.22,  0.21,\n",
        "        0.18,  0.14,  0.18,  0.16,  0.3 ,  0.23,  0.16,  0.26,  0.14,\n",
        "        0.16,  0.28,  0.18,  0.14,  0.32,  0.58,  0.57,  0.3 ,  0.19,\n",
        "        0.31,  0.46,  0.33,  0.29,  0.25,  0.16,  0.17,  0.54,  0.29,\n",
        "        0.17,  0.35,  0.15,  0.42,  0.57,  0.85,  0.74,  0.29,  0.29,\n",
        "        0.22,  0.38,  0.29,  0.38,  0.33,  0.18,  0.3 ,  0.34,  0.19,\n",
        "        0.17,  0.18,  0.06,  0.11,  0.19,  0.04,  0.19,  0.04,  0.18,\n",
        "        0.14,  0.59,  0.26,  0.37,  0.14,  0.31,  0.36,  0.08,  0.07,\n",
        "        0.59,  0.44,  0.44,  0.3 ,  0.46,  0.48,  0.38,  0.21,  0.09,\n",
        "        0.46,  0.52,  0.44,  0.4 ,  0.35,  0.22,  0.08,  0.22,  0.14,\n",
        "        0.13,  0.09,  0.17,  0.2 ,  0.06,  0.06,  0.08,  0.07,  0.09,\n",
        "        0.17,  0.09,  0.24,  0.13,  0.54,  0.16,  0.1 ,  0.07,  0.11,  0.06])"
       ]
      }
     ],
     "prompt_number": 264
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#### use the function to do it dude!\n",
      "theta_max = train_theta_max_sens_stacked(probs_big_val, labels_combined[ind_valid],\n",
      "                                             get_unstacked_predictions_from_probs_only_y,\n",
      "                                             ind_stacked=ind_windows_stacked_val, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.2  0.2  0.2  0.2  0.2  0. ]\n",
        "1\n",
        "[ 0.8      0.8      0.8      0.77778  0.77778  0.77778  0.77778  0.77778\n",
        "  0.77778  0.75556  0.75556  0.75556  0.75556  0.73333  0.73333  0.73333\n",
        "  0.73333  0.73333  0.73333  0.73333  0.73333  0.73333  0.73333  0.73333\n",
        "  0.73333  0.71111  0.71111  0.71111  0.71111  0.68889  0.68889  0.68889\n",
        "  0.68889  0.66667  0.66667  0.66667  0.66667  0.66667  0.66667  0.66667\n",
        "  0.66667  0.64444  0.64444  0.64444  0.64444  0.62222  0.62222  0.6      0.6\n",
        "  0.6      0.6      0.55556  0.55556  0.55556  0.55556  0.55556  0.55556\n",
        "  0.55556  0.55556  0.55556  0.55556  0.55556  0.55556  0.53333  0.53333\n",
        "  0.51111  0.51111  0.51111  0.51111  0.46667  0.46667  0.46667  0.46667\n",
        "  0.46667  0.46667  0.44444  0.44444  0.44444  0.44444  0.42222  0.42222\n",
        "  0.42222  0.42222  0.4      0.4      0.35556  0.35556  0.28889  0.28889\n",
        "  0.24444  0.24444  0.22222  0.22222  0.2      0.2      0.2      0.2      0.2\n",
        "  0.     ] [ 0.71068  0.72255  0.72255  0.73294  0.73294  0.73887  0.74481  0.75519\n",
        "  0.75519  0.75964  0.75964  0.78042  0.78042  0.79525  0.79525  0.80267\n",
        "  0.80267  0.81454  0.81454  0.82196  0.82196  0.83531  0.83531  0.84125\n",
        "  0.84125  0.84866  0.84866  0.85608  0.85608  0.86499  0.86499  0.8724\n",
        "  0.8724   0.88872  0.88872  0.89763  0.89763  0.90059  0.90059  0.90208\n",
        "  0.90208  0.90801  0.90801  0.91543  0.91543  0.91543  0.91543  0.91691\n",
        "  0.91691  0.91988  0.91988  0.9273   0.9273   0.92878  0.92878  0.93323\n",
        "  0.93323  0.93323  0.93323  0.93769  0.93769  0.9451   0.9451   0.95104\n",
        "  0.95104  0.95104  0.95104  0.95252  0.95252  0.95401  0.95401  0.95697\n",
        "  0.95697  0.96142  0.96142  0.96588  0.96588  0.97033  0.97033  0.97774\n",
        "  0.97774  0.98071  0.98071  0.9822   0.9822   0.98368  0.98368  0.98665\n",
        "  0.98665  0.98813  0.98813  0.98961  0.98961  0.99258  0.99258  0.99703\n",
        "  0.99703  0.99703  1.     ]\n"
       ]
      }
     ],
     "prompt_number": 265
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_any_val, list_y_preds_val = get_unstacked_predictions_from_probs(probs_big_val, ind_windows_stacked_val, theta_max)\n",
      "get_ss((confusion_matrix(labels_combined[ind_valid], y_any_val)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 267,
       "text": [
        "(0.2, 0.9925816023738873)"
       ]
      }
     ],
     "prompt_number": 267
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print theta_max_val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.989898989899\n"
       ]
      }
     ],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = get_prediction_times_all_patients(list_y_preds_val, patients_valid, time_ind, icu_combined[ind_valid])\n",
      "print 'median:', np.median(l[l>0]/3600), ', min:', np.min(l[l>0]/3600)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "median: 179.463055556 , min: 4.1725\n"
       ]
      }
     ],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind_windows_stacked_val = np.load"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.save('/root/code/xerox/probs_stacked_val', probs_stacked_val)\n",
      "del probs_stacked_val, ind_windows_stacked_val, labels_stacked_val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## MAKE WINDOW LENGTH DEPENDENT ON LENGTH OF ICU STAY"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print np.arange(y_any_valid.shape[0])[y_any_valid]  # all valid indices with at least one 1\n",
      "# find the indices at which 1 was predicted, and the label\n",
      "# i = 31\n",
      "#print np.arange(list_y_preds_val[i].shape[0])[list_y_preds_val[i][:, 0] == 1], labels_valid[i]\n",
      "#print labels_valid[y_any_valid != (l>0)]    # TRUE LABELS WHERE THE PREDICTION 1 WAS MADE AT TIME 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## others"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_y_prob_val = get_list_of_prediction_arrays(y_prob_stacked_val, ind_windows_stacked_val)\n",
      "[ind_fp_val, ind_fn_val, ind_tp_val, ind_tn_val] = get_confusion_inds(labels_valid, y_any_val)\n",
      "types_val = get_str_type(ind_fp_val, ind_tp_val, ind_fn_val, ind_tn_val)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Generate plots of mean probability and icu times of all patient time series..\n",
      "plt.ioff()\n",
      "for i, p in enumerate(patients_valid[:]):\n",
      "    f = figure()\n",
      "    #for j in xrange(n_train_splits):\n",
      "        #print probs.shape\n",
      "    plot(probs_list[i][:, -1], 'g.')    #plot the last col - the mean prob\n",
      "    plot(2 * probs_list[i][:, -1] - 1, 'b.')    # difference between prob of living and dying\n",
      "    ylim((-1, 2))\n",
      "    hlines([theta_max], 0, probs_list[i].shape[0])\n",
      "    plot(icu_combined[ind_valid][i] * 3 - 1, 'ro')\n",
      "\n",
      "    tit = str(i) + '_' + types_val[i] \n",
      "    title(tit)\n",
      "#         plot(prob_mod[:, 1])\n",
      "    f.savefig('plots/'+tit +'.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# LOAD VALIDATION DATA!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "df_age_valid = pd.read_csv('validation/id_age_val.csv')\n",
      "df_vitals_valid = pd.read_csv('validation/id_time_vitals_val.csv')\n",
      "df_labs_valid = pd.read_csv('validation/id_time_labs_val.csv')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[patients_combined_val, age_combined_val, icu_combined_val] = get_norm_patients_from_df(df_vitals_valid, df_labs_valid,\n",
      "                                                                                         df_age_valid, x_range, W, path)\n",
      "icu = np.array(df_vitals_valid.TIME[df_vitals_valid.ICU==1])\n",
      "icu = icu.reshape((icu.shape[0], 1))"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "np.save('/root/code/xerox/patients_combined_val.npy', patients_combined_val)\n",
      "np.save('/root/code/xerox/icu_combined_val.npy', icu_combined_val)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_labels_valid = pd.read_csv('/root/Downloads/id_label_val.csv', header=False)\n",
      "age_combined_val = np.array(df_age_valid.AGE)\n",
      "age_combined_val = np.array([norm_transform(x, x_range_age, W_age) for x in age_combined_val]).reshape((age_combined_val.shape[0],1))\n",
      "patients_combined_val = np.load('/root/code/xerox/patients_combined_val.npy')\n",
      "icu_combined_val = np.load('/root/code/xerox/icu_combined_val.npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 286
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### TO write final predictions\n",
      "y_preds_stacked = np.vstack(list_y_preds_valid)\n",
      "y_preds_stacked = y_preds_stacked.reshape((y_preds_stacked.shape[0], 1))\n",
      "final_pred_arr = np.hstack((np.array(df_vitals_valid.ID[df_vitals_valid.ICU==1]).reshape((icu.shape[0], 1)),\n",
      "                            icu, y_preds_stacked))\n",
      "final_pred_arr = np.array(final_pred_arr, dtype=int)\n",
      "np.savetxt('/root/output2.csv', final_pred_arr, delimiter=',', fmt='%d')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test on valiataion data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get stacked windows from the patients\n",
      "windows_stacked_test, ind_stacked_test = get_stacked_windows_from_ts(patients_combined_val, n_windows, stats,\n",
      "                                                                     time=time_ind, list_of_icu=icu_combined_val, cols=cols_feat,\n",
      "                                                                     window_size = window_size)\n",
      "np.save('/root/code/xerox/windows_stacked_test.npy', windows_stacked_test)\n",
      "np.save('/root/code/xerox/ind_stacked_test.npy', ind_stacked_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 287
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "windows_stacked_test = np.load('/root/code/xerox/windows_stacked_test.npy')\n",
      "ind_stacked_test = np.load('/root/code/xerox/ind_stacked_test.npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "windows_stacked_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 364,
       "text": [
        "(161121, 217)"
       ]
      }
     ],
     "prompt_number": 364
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the probs for all the windows stacked\n",
      "probs_stacked_test = get_proba(forests_final_1, windows_stacked_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 365
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# using the nX6 array, get the prediction of the big random forest\n",
      "probs_big_test = forest_big.predict_proba(probs_stacked_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 366
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# using a threshold, find\n",
      "y_any_test, list_y_preds_test = get_unstacked_predictions_from_probs(probs_big_test, ind_stacked_test, theta_max)\n",
      "get_ss(confusion_matrix(df_labels_valid.label, y_any_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 367,
       "text": [
        "(0.1951219512195122, 0.9955197132616488)"
       ]
      }
     ],
     "prompt_number": 367
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pred_times_valid = get_prediction_times_all_patients(list_y_preds_valid, patients_combined_val, time_ind=time_ind, list_of_icu_times=icu_combined_val)\n",
      "pred_times_actual = pred_times_valid.copy()\n",
      "for i in xrange(pred_times_actual.shape[0]):\n",
      "    if(df_labels_valid.label[i] == 0):\n",
      "        pred_times_actual[i]=-1\n",
      "    if(df_labels_valid.label[i]==1):\n",
      "        pred_times_actual[i]=max(0, pred_times_valid[i])\n",
      "pred_times_actual[pred_times_actual>=0].shape\n",
      "np.median(pred_times_actual[pred_times_actual>=0])\n",
      "np.median(pred_times_actual[pred_times_actual>0])"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "l = get_prediction_times_all_patients(list_y_preds_val, patients_valid, time_ind, icu_combined[ind_valid])\n",
      "print 'median:', np.median(l[l>0]/3600), ', min:', np.min(l[l>0]/3600)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_y_prob_test = get_list_of_prediction_arrays(probs_stacked_test, ind_stacked_test)\n",
      "[ind_fp_test, ind_fn_test, ind_tp_test, ind_tn_test] = get_confusion_inds(df_labels_valid.label, y_any_test)\n",
      "types_test = get_str_type(ind_fp_test, ind_tp_test, ind_fn_test, ind_tn_test)\n",
      "list_y_prob_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 295,
       "text": [
        "(1198,)"
       ]
      }
     ],
     "prompt_number": 295
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_big_prob_test = get_list_of_prediction_arrays(probs_big_test, ind_stacked_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 296
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del probs_stacked_test\n",
      "del windows_stacked_test, ind_stacked_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 300
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del probs_big_test, list_y_prob_test, types_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.ioff()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_any_test[51]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 375,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 375
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Generate plots of mean probability and icu times of all patient time series..\n",
      "f = plt.figure(figsize=(50,30))\n",
      "for i, p in enumerate(patients_combined_val):\n",
      "    plt.clf()\n",
      "    bs = np.array(icu_combined_val[i], dtype=bool)\n",
      "    x = np.arange(icu_combined_val[i].shape[0])[bs]\n",
      "    for j in xrange(n_train_splits):\n",
      "        #plot(2 * probs_list[i][:, -1] - 1, 'b.')    # difference between prob of living and dying\n",
      "        plt.plot(x, list_y_prob_test[i][:, j])    # difference between prob of living and dying\n",
      "    plt.ylim((-1, 2))\n",
      "    plt.plot(x, list_big_prob_test[i][:, 1], 'rx-')\n",
      "    plt.plot(x, 2*list_big_prob_test[i][:, 1]-1, 'g')\n",
      "    plt.hlines([theta_max], 0, icu_combined_val[i].shape[0])\n",
      "    plt.plot(3*icu_combined_val[i]-1,  'ro', markersize=30)\n",
      "\n",
      "    tit = str(i) + '_' + types_test[i] \n",
      "    plt.title(tit)\n",
      "#         plot(prob_mod[:, 1])\n",
      "    f.savefig('plots/' + types_test[i] + '/valid_'+tit +'.png')\n",
      "\n",
      "plt.close(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 349
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_y_preds_test[51]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 376,
       "text": [
        "array([[False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False],\n",
        "       [False]], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 376
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print y_any_test[5], df_labels_valid.label[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "False 1\n"
       ]
      }
     ],
     "prompt_number": 352
    }
   ],
   "metadata": {}
  }
 ]
}